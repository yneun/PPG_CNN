{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/__main__.py\", line 22, in <module>\n",
      "    from pip._internal.cli.main import main as _main\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/_internal/cli/main.py\", line 11, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
      "    from pip._internal.cli.main_parser import create_main_parser\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
      "    from pip._internal.build_env import get_runnable_pip\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/_internal/build_env.py\", line 18, in <module>\n",
      "    from pip._internal.cli.spinners import open_spinner\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
      "    from pip._internal.utils.logging import get_indentation\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/_internal/utils/logging.py\", line 22, in <module>\n",
      "    from pip._vendor.rich.logging import RichHandler\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/_vendor/rich/logging.py\", line 15, in <module>\n",
      "    from .traceback import Traceback\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/_vendor/rich/traceback.py\", line 23, in <module>\n",
      "    from pip._vendor.pygments.lexers import guess_lexer_for_filename\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/__init__.py\", line 19, in <module>\n",
      "    from pip._vendor.pygments.plugin import find_plugin_lexers\n",
      "  File \"/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/plugin.py\", line 35, in <module>\n",
      "    from importlib.metadata import entry_points\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 991, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1087, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1187, in get_data\n",
      "KeyboardInterrupt\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./.venv/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./.venv/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.venv/lib/python3.12/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.67.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in ./.venv/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./.venv/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.9.3)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras\n",
    "%pip install tensorflow\n",
    "%pip install numpy pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 10:43:44.015362: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### Feature Data Shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Data Load\n",
    "ppg_041 = pd.read_csv('../Data/ppg_features_041.csv')\n",
    "ppg_427 = pd.read_csv('../Data/ppg_features_427.csv')\n",
    "ppg_212 = pd.read_csv('../Data/ppg_features_212.csv')\n",
    "ppg_224 = pd.read_csv('../Data/ppg_features_224.csv')\n",
    "ppg_237 = pd.read_csv('../Data/ppg_features_237.csv')\n",
    "ppg_240 = pd.read_csv('../Data/ppg_features_240.csv')\n",
    "ppg_414 = pd.read_csv('../Data/ppg_features_414.csv')\n",
    "\n",
    "# SBP Data Load\n",
    "sbp_041 = pd.read_csv('../Data/sbp_041.csv')\n",
    "sbp_427 = pd.read_csv('../Data/sbp_427.csv')\n",
    "sbp_212 = pd.read_csv('../Data/sbp_212.csv')\n",
    "sbp_224 = pd.read_csv('../Data/sbp_224.csv')\n",
    "sbp_237 = pd.read_csv('../Data/sbp_237.csv')\n",
    "sbp_240 = pd.read_csv('../Data/sbp_240.csv')\n",
    "sbp_414 = pd.read_csv('../Data/sbp_414.csv')\n",
    "\n",
    "# DBP Data Load\n",
    "dbp_041 = pd.read_csv('../Data/dbp_041.csv')\n",
    "dbp_427 = pd.read_csv('../Data/dbp_427.csv')\n",
    "dbp_212 = pd.read_csv('../Data/dbp_212.csv')\n",
    "dbp_224 = pd.read_csv('../Data/dbp_224.csv')\n",
    "dbp_237 = pd.read_csv('../Data/dbp_237.csv')\n",
    "dbp_240 = pd.read_csv('../Data/dbp_240.csv')\n",
    "dbp_414 = pd.read_csv('../Data/dbp_414.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_combined shape: (5975, 26)\n",
      "X_test_combined shape: (1496, 26)\n",
      "SBP_Y_train_combined shape: (5975, 1)\n",
      "SBP_Y_test_combined shape: (1496, 1)\n",
      "DBP_Y_train_combined shape: (5975, 1)\n",
      "DBP_Y_test_combined shape: (1496, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of datasets\n",
    "feature_data = [ppg_041,ppg_212,ppg_224,ppg_237,ppg_240,ppg_414,ppg_427]\n",
    "sbp_data = [sbp_041,sbp_212,sbp_224,sbp_237,sbp_240,sbp_414,sbp_427]\n",
    "dbp_data = [dbp_041,dbp_212,dbp_224,dbp_237,dbp_240,dbp_414,dbp_427]\n",
    "\n",
    "# List for saving training set and test set\n",
    "X_train_set = []\n",
    "X_test_set = []\n",
    "SBP_y_train_set =[]\n",
    "SBP_y_test_set = []\n",
    "DBP_y_train_set =[]\n",
    "DBP_y_test_set = []\n",
    "\n",
    "# For every datasets execute train_test_split\n",
    "for i in range(len(feature_data)):\n",
    "    X_train, X_test, SBP_Y_train, SBP_Y_test = train_test_split(feature_data[i], sbp_data[i], test_size=0.2, random_state=42)\n",
    "    _, _, DBP_Y_train, DBP_Y_test = train_test_split(feature_data[i], dbp_data[i], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Save training set and test set\n",
    "    X_train_set.append(X_train)\n",
    "    X_test_set.append(X_test)\n",
    "    SBP_y_train_set.append(SBP_Y_train)\n",
    "    SBP_y_test_set.append(SBP_Y_test)\n",
    "    DBP_y_train_set.append(DBP_Y_train)\n",
    "    DBP_y_test_set.append(DBP_Y_test)\n",
    "\n",
    "# Save the combined traning set and test set\n",
    "X_train_combined = pd.concat(X_train_set, axis=0)\n",
    "X_test_combined = pd.concat(X_test_set, axis=0)\n",
    "SBP_Y_train_combined = pd.concat(SBP_y_train_set, axis=0)\n",
    "SBP_Y_test_combined = pd.concat(SBP_y_test_set, axis=0)\n",
    "DBP_Y_train_combined = pd.concat(DBP_y_train_set, axis=0)\n",
    "DBP_Y_test_combined = pd.concat(DBP_y_test_set, axis=0)\n",
    "\n",
    "# Change the dimension\n",
    "# X_train_combined = X_train_combined.values.reshape(-1, X_train_combined.shape[1], 1)\n",
    "# X_test_combined = X_test_combined.values.reshape(-1, X_test_combined.shape[1], 1)\n",
    "# SBP_Y_train_combined = SBP_Y_train_combined.values.reshape(-1, SBP_Y_train_combined.shape[1],1)\n",
    "# SBP_Y_test_combined = SBP_Y_test_combined.values.reshape(-1, SBP_Y_test_combined.shape[1], 1)\n",
    "# DBP_Y_train_combined = DBP_Y_train_combined.values.reshape(-1, DBP_Y_train_combined[1], 1)\n",
    "# DBP_Y_test_combined = DBP_Y_test_combined.values.reshape(-1, DBP_Y_test_combined[1], 1)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"X_train_combined shape:\", X_train_combined.shape)\n",
    "print(\"X_test_combined shape:\", X_test_combined.shape)\n",
    "print(\"SBP_Y_train_combined shape:\", SBP_Y_train_combined.shape)\n",
    "print(\"SBP_Y_test_combined shape:\", SBP_Y_test_combined.shape)\n",
    "print(\"DBP_Y_train_combined shape:\", DBP_Y_train_combined.shape)\n",
    "print(\"DBP_Y_test_combined shape:\", DBP_Y_test_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_combined shape: (5975, 26)\n",
      "SBP_Y_train_combined shape: (5975, 1)\n",
      "DBP_Y_train_combined shape: (5975, 1)\n",
      "X_test_combined shape: (1496, 26)\n",
      "SBP_Y_test_combined shape: (1496, 1)\n",
      "DBP_Y_test_combined shape: (1496, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data shuffle\n",
    "# 인덱스를 생성하여 섞기\n",
    "n_train = X_train_combined.shape[0]  # 훈련 데이터의 샘플 수\n",
    "n_test = X_test_combined.shape[0]      # 테스트 데이터의 샘플 수\n",
    "\n",
    "# 훈련 세트와 테스트 세트의 인덱스 생성\n",
    "train_indices = shuffle(range(n_train), random_state=42)\n",
    "test_indices = shuffle(range(n_test), random_state=42)\n",
    "\n",
    "# 섞인 인덱스를 사용하여 데이터셋 재배열\n",
    "X_train_combined = X_train_combined.iloc[train_indices].reset_index(drop=True)\n",
    "SBP_Y_train_combined = SBP_Y_train_combined.iloc[train_indices].reset_index(drop=True)\n",
    "DBP_Y_train_combined = DBP_Y_train_combined.iloc[train_indices].reset_index(drop=True)\n",
    "\n",
    "X_test_combined = X_test_combined.iloc[test_indices].reset_index(drop=True)\n",
    "SBP_Y_test_combined = SBP_Y_test_combined.iloc[test_indices].reset_index(drop=True)\n",
    "DBP_Y_test_combined = DBP_Y_test_combined.iloc[test_indices].reset_index(drop=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"X_train_combined shape:\", X_train_combined.shape)\n",
    "print(\"SBP_Y_train_combined shape:\", SBP_Y_train_combined.shape)\n",
    "print(\"DBP_Y_train_combined shape:\", DBP_Y_train_combined.shape)\n",
    "print(\"X_test_combined shape:\", X_test_combined.shape)\n",
    "print(\"SBP_Y_test_combined shape:\", SBP_Y_test_combined.shape)\n",
    "print(\"DBP_Y_test_combined shape:\", DBP_Y_test_combined.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = X_train_combined.values.reshape(-1, X_train_combined.shape[1], 1)\n",
    "X_test_combined = X_test_combined.values.reshape(-1, X_test_combined.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_combined shape: (5975, 26, 1)\n",
      "X_test_combined shape: (1496, 26, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_combined shape:\", X_train_combined.shape)\n",
    "print(\"X_test_combined shape:\", X_test_combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 1D CNN 모델 정의 (회귀용)\n",
    "sbp_model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "])\n",
    "\n",
    "sbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 1D CNN 모델 정의 (회귀용)\n",
    "sbp1_model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 26)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "])\n",
    "\n",
    "sbp1_model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN for SBP\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch = 50, batch-size = 32\n",
    "- Patience 40: Loss = 130.7982, MAE = 8.3416\n",
    "- Patience 30: Loss = 133.9735, MAE = 8.5733\n",
    "- Patience 20: Loss = 133.4155, MAE = 8.3988, Early Stopping Epoch: 45\n",
    "- Patience 10: Loss = 135.6743, MAE = 8.6578\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch = 60, bach-size = 32\n",
    "- Patience 40: Loss = 132.0500, MAE = 8.4166\n",
    "- Patience 30: Loss = 131.8998, MAE = 8.3849\n",
    "- Patience 20: Loss = 130.9753, MAE = 8.3171\n",
    "- Patience 10: Loss = 133.8357, MAE = 8.4918, Early Stopping Epoch: 49\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch = 100, batch-size = 32\n",
    "- Patience 40: Loss = 125.8191, MAE = 8.2690\n",
    "- Patience 30: Loss = 128.9418, MAE = 8.3847\n",
    "- Patience 20: Loss = 130.0474, MAE = 8.3904, Early Stopping Epoch: 85\n",
    "- Patience 10: Loss = 136.6824, MAE = 8.7105, Early Stopping Epoch: 32\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 150, batch-size = 32\n",
    "- Patience 40: Loss = 119.9662, MAE = 7.9446\n",
    "- Patience 30: Loss = 120.1098, MAE = 7.9087\n",
    "- Patience 20: Loss = 128.5647, MAE = 8.3220, Early Stopping Epoch: 56\n",
    "- Patience 10: Loss = 131.9538, MAE = 8.3988, Early Stopping Epoch: 56\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 150, batch-size = 16\n",
    "- Patience 40: Loss = 118.5138, MAE = 8.0349\n",
    "- Patience 30: Loss = 116.7564, MAE = 7.8032\n",
    "- Patience 20: Loss = 113.8299, MAE = 7.6948, Early Stopping Epoch: 141\n",
    "- Patience 10: Loss = 138.4038, MAE = 8.6944, Early Stopping Epoch: 25\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 200, batch-size = 16\n",
    "- Patience 40: Loss = 117.5314, MAE = 7.9175\n",
    "- Patience 30: Loss = 119.4077, MAE = 7.9994, Early Stopping Epoch: 144\n",
    "- Patience 20: Loss = 125.5098, MAE = 8.2240, Early Stopping Epoch: 105\n",
    "- Patience 10: Loss = 135.0204, MAE = 8.4157, Early Stopping Epoch: 33\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 200, batch-size = 32\n",
    "- Patience 40: Loss = 117.0957, MAE = 7.9254\n",
    "- Patience 30: Loss = 124.4492, MAE = 8.1072, Early Stopping Epoch: 93\n",
    "- Patience 20: Loss = 123.5643, MAE = 8.1035, Early Stopping Epoch: 112\n",
    "- Patience 10: Loss = 132.8055, MAE = 8.4746, Early Stopping Epoch: 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 3517.5842 - mae: 43.2344 - val_loss: 311.4554 - val_mae: 13.8524\n",
      "Epoch 2/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 758.9298 - mae: 21.5173 - val_loss: 315.1459 - val_mae: 13.7151\n",
      "Epoch 3/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 694.5419 - mae: 20.8257 - val_loss: 271.6381 - val_mae: 13.6766\n",
      "Epoch 4/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 689.0380 - mae: 20.5735 - val_loss: 263.9403 - val_mae: 12.3393\n",
      "Epoch 5/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 607.6951 - mae: 19.3215 - val_loss: 226.7682 - val_mae: 11.4221\n",
      "Epoch 6/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 588.8388 - mae: 19.0323 - val_loss: 209.4503 - val_mae: 10.9761\n",
      "Epoch 7/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 538.7501 - mae: 18.2556 - val_loss: 181.4183 - val_mae: 10.2804\n",
      "Epoch 8/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 543.0579 - mae: 18.1814 - val_loss: 164.2315 - val_mae: 9.7285\n",
      "Epoch 9/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 524.0566 - mae: 17.7609 - val_loss: 165.2060 - val_mae: 9.7932\n",
      "Epoch 10/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 519.1104 - mae: 17.8368 - val_loss: 168.8636 - val_mae: 9.7364\n",
      "Epoch 11/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 519.0533 - mae: 17.6806 - val_loss: 160.8397 - val_mae: 9.7253\n",
      "Epoch 12/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 539.6943 - mae: 17.9371 - val_loss: 201.0706 - val_mae: 11.2350\n",
      "Epoch 13/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 537.3171 - mae: 18.0088 - val_loss: 278.1693 - val_mae: 13.8604\n",
      "Epoch 14/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 500.6953 - mae: 17.5348 - val_loss: 203.7632 - val_mae: 11.0731\n",
      "Epoch 15/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 505.9249 - mae: 17.5571 - val_loss: 148.0137 - val_mae: 9.1854\n",
      "Epoch 16/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 509.8264 - mae: 17.6156 - val_loss: 155.0232 - val_mae: 9.3437\n",
      "Epoch 17/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 483.1230 - mae: 17.1353 - val_loss: 148.3573 - val_mae: 9.0604\n",
      "Epoch 18/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 523.0771 - mae: 18.0308 - val_loss: 157.8011 - val_mae: 9.7340\n",
      "Epoch 19/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 477.7614 - mae: 17.0844 - val_loss: 156.6567 - val_mae: 9.6303\n",
      "Epoch 20/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 507.7180 - mae: 17.7115 - val_loss: 170.6393 - val_mae: 10.2069\n",
      "Epoch 21/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 491.7669 - mae: 17.4312 - val_loss: 142.6250 - val_mae: 8.8037\n",
      "Epoch 22/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 498.7362 - mae: 17.4442 - val_loss: 169.2759 - val_mae: 10.1165\n",
      "Epoch 23/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 495.3297 - mae: 17.2635 - val_loss: 147.7985 - val_mae: 8.9748\n",
      "Epoch 24/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 481.1290 - mae: 17.2987 - val_loss: 151.3513 - val_mae: 9.1483\n",
      "Epoch 25/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 479.2375 - mae: 17.2735 - val_loss: 143.0502 - val_mae: 8.9202\n",
      "Epoch 26/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 480.6606 - mae: 17.2255 - val_loss: 161.8761 - val_mae: 9.3110\n",
      "Epoch 27/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 471.1841 - mae: 16.8356 - val_loss: 139.9642 - val_mae: 8.8442\n",
      "Epoch 28/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 490.7964 - mae: 17.2437 - val_loss: 183.9299 - val_mae: 10.6567\n",
      "Epoch 29/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 464.9563 - mae: 16.8537 - val_loss: 145.5583 - val_mae: 9.1820\n",
      "Epoch 30/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 467.1554 - mae: 16.7623 - val_loss: 137.8044 - val_mae: 8.7639\n",
      "Epoch 31/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 489.3488 - mae: 17.3084 - val_loss: 140.1283 - val_mae: 8.9119\n",
      "Epoch 32/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 461.4789 - mae: 16.8135 - val_loss: 147.9095 - val_mae: 9.2055\n",
      "Epoch 33/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 451.7332 - mae: 16.7512 - val_loss: 144.4010 - val_mae: 9.0628\n",
      "Epoch 34/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 503.2399 - mae: 17.4129 - val_loss: 137.3693 - val_mae: 8.7204\n",
      "Epoch 35/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 461.5427 - mae: 16.6406 - val_loss: 162.9056 - val_mae: 9.9324\n",
      "Epoch 36/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 452.5853 - mae: 16.7236 - val_loss: 160.1475 - val_mae: 9.8045\n",
      "Epoch 37/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 446.9400 - mae: 16.5168 - val_loss: 170.2950 - val_mae: 10.1353\n",
      "Epoch 38/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 448.0857 - mae: 16.3325 - val_loss: 132.6284 - val_mae: 8.4374\n",
      "Epoch 39/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 464.4279 - mae: 16.8308 - val_loss: 135.6825 - val_mae: 8.5547\n",
      "Epoch 40/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 471.6992 - mae: 16.9440 - val_loss: 179.1000 - val_mae: 10.6088\n",
      "Epoch 41/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 463.0824 - mae: 16.8547 - val_loss: 152.2914 - val_mae: 9.2832\n",
      "Epoch 42/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 481.3757 - mae: 17.0804 - val_loss: 145.1573 - val_mae: 9.1258\n",
      "Epoch 43/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 479.9130 - mae: 16.9579 - val_loss: 169.7449 - val_mae: 10.1748\n",
      "Epoch 44/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 436.8710 - mae: 16.1336 - val_loss: 139.1254 - val_mae: 8.7415\n",
      "Epoch 45/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 449.7208 - mae: 16.3870 - val_loss: 162.1240 - val_mae: 9.9136\n",
      "Epoch 46/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 440.9857 - mae: 16.3583 - val_loss: 155.7442 - val_mae: 9.6022\n",
      "Epoch 47/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 458.4667 - mae: 16.6880 - val_loss: 135.2271 - val_mae: 8.6088\n",
      "Epoch 48/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 418.9276 - mae: 16.0275 - val_loss: 130.7982 - val_mae: 8.3416\n",
      "Epoch 49/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 423.2838 - mae: 16.0345 - val_loss: 155.0336 - val_mae: 9.6484\n",
      "Epoch 50/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 428.5045 - mae: 16.2310 - val_loss: 133.9749 - val_mae: 8.5796\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.2530 - mae: 8.3021\n",
      "Patience 40: Validation MAE: 8.34\n",
      "Patience 40: Validation Loss: 130.80\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2419.7424 - mae: 34.8230 - val_loss: 350.6844 - val_mae: 14.1472\n",
      "Epoch 2/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 708.0203 - mae: 20.8876 - val_loss: 296.8989 - val_mae: 13.3631\n",
      "Epoch 3/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 640.0282 - mae: 19.9401 - val_loss: 238.2248 - val_mae: 12.5231\n",
      "Epoch 4/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 575.3383 - mae: 18.8250 - val_loss: 230.9375 - val_mae: 11.5566\n",
      "Epoch 5/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 575.3060 - mae: 18.7779 - val_loss: 186.1961 - val_mae: 10.4516\n",
      "Epoch 6/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 538.0847 - mae: 18.1670 - val_loss: 166.7232 - val_mae: 9.9230\n",
      "Epoch 7/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 509.6489 - mae: 17.6535 - val_loss: 167.0418 - val_mae: 9.9662\n",
      "Epoch 8/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 510.9900 - mae: 17.5577 - val_loss: 198.6626 - val_mae: 11.1548\n",
      "Epoch 9/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 479.4839 - mae: 17.1609 - val_loss: 149.6427 - val_mae: 9.2002\n",
      "Epoch 10/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 499.0534 - mae: 17.5466 - val_loss: 249.3615 - val_mae: 12.7275\n",
      "Epoch 11/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 507.4964 - mae: 17.7375 - val_loss: 170.4883 - val_mae: 10.0205\n",
      "Epoch 12/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 472.7091 - mae: 16.8723 - val_loss: 272.5798 - val_mae: 13.6499\n",
      "Epoch 13/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 502.1084 - mae: 17.3198 - val_loss: 189.8028 - val_mae: 10.8075\n",
      "Epoch 14/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 523.2434 - mae: 17.7441 - val_loss: 165.2465 - val_mae: 9.8681\n",
      "Epoch 15/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 495.5465 - mae: 17.4502 - val_loss: 208.7095 - val_mae: 11.5331\n",
      "Epoch 16/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 489.6333 - mae: 17.4868 - val_loss: 159.1553 - val_mae: 9.7071\n",
      "Epoch 17/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 487.6765 - mae: 17.1242 - val_loss: 161.1941 - val_mae: 9.4639\n",
      "Epoch 18/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 496.6221 - mae: 17.4671 - val_loss: 183.4390 - val_mae: 10.4656\n",
      "Epoch 19/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 470.7159 - mae: 16.8133 - val_loss: 166.2516 - val_mae: 9.7986\n",
      "Epoch 20/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 473.0381 - mae: 16.7100 - val_loss: 157.4076 - val_mae: 9.6103\n",
      "Epoch 21/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 472.9196 - mae: 16.8887 - val_loss: 171.9946 - val_mae: 9.9880\n",
      "Epoch 22/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 487.1214 - mae: 17.3452 - val_loss: 151.9307 - val_mae: 9.2088\n",
      "Epoch 23/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 460.2263 - mae: 16.5551 - val_loss: 195.9381 - val_mae: 11.1978\n",
      "Epoch 24/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 485.2632 - mae: 16.9694 - val_loss: 151.9728 - val_mae: 9.2511\n",
      "Epoch 25/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 445.8522 - mae: 16.4061 - val_loss: 139.7704 - val_mae: 8.8241\n",
      "Epoch 26/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 471.5224 - mae: 16.8479 - val_loss: 203.4772 - val_mae: 11.3884\n",
      "Epoch 27/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 453.8285 - mae: 16.6461 - val_loss: 141.4760 - val_mae: 8.9004\n",
      "Epoch 28/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 476.5985 - mae: 16.7358 - val_loss: 147.4204 - val_mae: 9.1195\n",
      "Epoch 29/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 457.6451 - mae: 16.5974 - val_loss: 152.0695 - val_mae: 9.3018\n",
      "Epoch 30/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 478.6713 - mae: 17.1305 - val_loss: 168.2444 - val_mae: 10.1345\n",
      "Epoch 31/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 439.4317 - mae: 16.3140 - val_loss: 146.1737 - val_mae: 8.8331\n",
      "Epoch 32/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 465.1873 - mae: 16.6924 - val_loss: 146.1897 - val_mae: 9.1439\n",
      "Epoch 33/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 452.6017 - mae: 16.4473 - val_loss: 137.8153 - val_mae: 8.6246\n",
      "Epoch 34/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 454.6064 - mae: 16.6434 - val_loss: 149.3743 - val_mae: 9.3082\n",
      "Epoch 35/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 465.3248 - mae: 16.9320 - val_loss: 139.4934 - val_mae: 8.8331\n",
      "Epoch 36/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 465.9275 - mae: 17.0317 - val_loss: 159.7645 - val_mae: 9.5362\n",
      "Epoch 37/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 440.8542 - mae: 16.4026 - val_loss: 176.9902 - val_mae: 10.3424\n",
      "Epoch 38/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 439.6360 - mae: 16.4181 - val_loss: 162.7427 - val_mae: 9.9850\n",
      "Epoch 39/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 455.2954 - mae: 16.5851 - val_loss: 135.2572 - val_mae: 8.4775\n",
      "Epoch 40/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 428.6354 - mae: 16.0723 - val_loss: 157.4639 - val_mae: 9.5766\n",
      "Epoch 41/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 453.9682 - mae: 16.4998 - val_loss: 168.8269 - val_mae: 10.0241\n",
      "Epoch 42/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 432.7511 - mae: 16.3058 - val_loss: 134.9024 - val_mae: 8.4991\n",
      "Epoch 43/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 423.0454 - mae: 15.9727 - val_loss: 193.0497 - val_mae: 10.7860\n",
      "Epoch 44/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 453.8455 - mae: 16.4212 - val_loss: 136.6651 - val_mae: 8.7241\n",
      "Epoch 45/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 427.9469 - mae: 15.9880 - val_loss: 141.1512 - val_mae: 8.9550\n",
      "Epoch 46/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 441.5439 - mae: 16.3889 - val_loss: 133.9735 - val_mae: 8.5733\n",
      "Epoch 47/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 423.8247 - mae: 16.0768 - val_loss: 137.3149 - val_mae: 8.8084\n",
      "Epoch 48/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 429.4963 - mae: 16.1231 - val_loss: 137.8114 - val_mae: 8.7553\n",
      "Epoch 49/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 431.9190 - mae: 16.2678 - val_loss: 141.7447 - val_mae: 8.8313\n",
      "Epoch 50/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 429.4232 - mae: 16.2039 - val_loss: 143.8412 - val_mae: 8.8256\n",
      "Patience 30: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.5207 - mae: 8.5710\n",
      "Patience 30: Validation MAE: 8.57\n",
      "Patience 30: Validation Loss: 133.97\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 2428.4746 - mae: 35.2584 - val_loss: 324.1107 - val_mae: 13.7421\n",
      "Epoch 2/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 612.7612 - mae: 19.5084 - val_loss: 257.9901 - val_mae: 12.1817\n",
      "Epoch 3/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 545.3333 - mae: 18.2720 - val_loss: 284.8916 - val_mae: 13.8317\n",
      "Epoch 4/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 508.0552 - mae: 17.6649 - val_loss: 220.3966 - val_mae: 11.8133\n",
      "Epoch 5/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 489.5115 - mae: 17.1767 - val_loss: 175.3313 - val_mae: 10.1250\n",
      "Epoch 6/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 475.3370 - mae: 17.0900 - val_loss: 201.1241 - val_mae: 10.7385\n",
      "Epoch 7/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 442.0176 - mae: 16.4104 - val_loss: 184.6477 - val_mae: 10.3499\n",
      "Epoch 8/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 438.6997 - mae: 16.3250 - val_loss: 169.0602 - val_mae: 9.9727\n",
      "Epoch 9/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 417.2876 - mae: 16.0191 - val_loss: 210.4513 - val_mae: 11.2734\n",
      "Epoch 10/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 441.9949 - mae: 16.2589 - val_loss: 150.5996 - val_mae: 9.1056\n",
      "Epoch 11/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 476.0310 - mae: 16.8764 - val_loss: 159.5365 - val_mae: 9.5314\n",
      "Epoch 12/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 469.2548 - mae: 16.7763 - val_loss: 165.2312 - val_mae: 9.8061\n",
      "Epoch 13/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 420.2363 - mae: 16.0229 - val_loss: 146.4626 - val_mae: 8.9399\n",
      "Epoch 14/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 425.4282 - mae: 16.1014 - val_loss: 142.2248 - val_mae: 8.8861\n",
      "Epoch 15/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 420.3291 - mae: 15.9354 - val_loss: 142.7594 - val_mae: 8.8275\n",
      "Epoch 16/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 410.9137 - mae: 15.7000 - val_loss: 142.3611 - val_mae: 8.9357\n",
      "Epoch 17/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 420.5355 - mae: 15.8988 - val_loss: 153.6612 - val_mae: 9.3209\n",
      "Epoch 18/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 430.5938 - mae: 15.8484 - val_loss: 151.0654 - val_mae: 9.2187\n",
      "Epoch 19/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 423.2353 - mae: 15.9530 - val_loss: 141.0808 - val_mae: 8.9013\n",
      "Epoch 20/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 417.8491 - mae: 15.7299 - val_loss: 160.9868 - val_mae: 9.8651\n",
      "Epoch 21/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 413.7009 - mae: 15.6623 - val_loss: 356.1165 - val_mae: 16.0101\n",
      "Epoch 22/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 429.1403 - mae: 16.1375 - val_loss: 144.5032 - val_mae: 9.0241\n",
      "Epoch 23/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.1381 - mae: 15.9572 - val_loss: 171.3418 - val_mae: 10.1494\n",
      "Epoch 24/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 396.9343 - mae: 15.3212 - val_loss: 137.0042 - val_mae: 8.5542\n",
      "Epoch 25/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 392.6204 - mae: 15.1860 - val_loss: 183.2994 - val_mae: 10.4002\n",
      "Epoch 26/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 429.9815 - mae: 16.0926 - val_loss: 133.4155 - val_mae: 8.3988\n",
      "Epoch 27/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 382.6478 - mae: 15.2567 - val_loss: 159.6830 - val_mae: 9.7070\n",
      "Epoch 28/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 398.8280 - mae: 15.5459 - val_loss: 142.8119 - val_mae: 8.9190\n",
      "Epoch 29/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 426.5234 - mae: 16.0173 - val_loss: 143.4542 - val_mae: 8.8547\n",
      "Epoch 30/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 408.2688 - mae: 15.6435 - val_loss: 137.6924 - val_mae: 8.5766\n",
      "Epoch 31/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 395.9072 - mae: 15.4008 - val_loss: 163.1412 - val_mae: 9.5655\n",
      "Epoch 32/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 413.4628 - mae: 15.6935 - val_loss: 135.7048 - val_mae: 8.6310\n",
      "Epoch 33/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 385.9420 - mae: 15.0995 - val_loss: 168.1879 - val_mae: 10.1032\n",
      "Epoch 34/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 411.0444 - mae: 15.7242 - val_loss: 151.2813 - val_mae: 9.2923\n",
      "Epoch 35/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 398.2323 - mae: 15.3190 - val_loss: 155.9373 - val_mae: 9.6015\n",
      "Epoch 36/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 386.0669 - mae: 15.4331 - val_loss: 153.9450 - val_mae: 9.3887\n",
      "Epoch 37/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 417.6076 - mae: 15.8811 - val_loss: 152.9898 - val_mae: 9.2326\n",
      "Epoch 38/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387.4651 - mae: 15.2942 - val_loss: 140.0897 - val_mae: 8.7924\n",
      "Epoch 39/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 377.3827 - mae: 15.2289 - val_loss: 151.9808 - val_mae: 9.3029\n",
      "Epoch 40/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 400.0546 - mae: 15.3921 - val_loss: 136.2985 - val_mae: 8.5668\n",
      "Epoch 41/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 386.9962 - mae: 15.2469 - val_loss: 147.8616 - val_mae: 8.9490\n",
      "Epoch 42/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 402.5565 - mae: 15.4538 - val_loss: 137.9561 - val_mae: 8.7553\n",
      "Epoch 43/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 382.2437 - mae: 15.1835 - val_loss: 139.6674 - val_mae: 8.8621\n",
      "Epoch 44/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 385.3475 - mae: 15.1634 - val_loss: 212.2094 - val_mae: 11.6241\n",
      "Epoch 45/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 396.5975 - mae: 15.4574 - val_loss: 151.8696 - val_mae: 9.2985\n",
      "Epoch 46/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 400.0270 - mae: 15.4438 - val_loss: 157.0215 - val_mae: 9.2259\n",
      "Patience 20: Early stopping occurred at epoch 45\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.4909 - mae: 8.4362\n",
      "Patience 20: Validation MAE: 8.40\n",
      "Patience 20: Validation Loss: 133.42\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1876.5601 - mae: 30.3172 - val_loss: 328.4549 - val_mae: 14.5168\n",
      "Epoch 2/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 671.6064 - mae: 20.4208 - val_loss: 293.7720 - val_mae: 13.0784\n",
      "Epoch 3/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 606.8690 - mae: 19.2498 - val_loss: 347.1566 - val_mae: 14.1798\n",
      "Epoch 4/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 544.9440 - mae: 18.2622 - val_loss: 223.7978 - val_mae: 11.8923\n",
      "Epoch 5/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 519.5793 - mae: 17.7409 - val_loss: 259.0520 - val_mae: 12.3858\n",
      "Epoch 6/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 493.7301 - mae: 17.3603 - val_loss: 208.7189 - val_mae: 11.0041\n",
      "Epoch 7/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 493.1809 - mae: 17.2587 - val_loss: 276.5468 - val_mae: 13.4983\n",
      "Epoch 8/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 460.2725 - mae: 16.7019 - val_loss: 168.4876 - val_mae: 9.7897\n",
      "Epoch 9/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 466.6610 - mae: 16.9273 - val_loss: 170.0601 - val_mae: 9.8898\n",
      "Epoch 10/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 447.0085 - mae: 16.5833 - val_loss: 180.5689 - val_mae: 10.1336\n",
      "Epoch 11/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 460.1442 - mae: 16.6325 - val_loss: 192.5314 - val_mae: 10.7196\n",
      "Epoch 12/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 471.4512 - mae: 17.0658 - val_loss: 159.2727 - val_mae: 9.3928\n",
      "Epoch 13/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 458.6371 - mae: 16.7586 - val_loss: 160.1331 - val_mae: 9.3996\n",
      "Epoch 14/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 433.8326 - mae: 16.2378 - val_loss: 155.9528 - val_mae: 9.2943\n",
      "Epoch 15/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 486.7468 - mae: 17.0197 - val_loss: 195.5507 - val_mae: 10.7553\n",
      "Epoch 16/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 439.1693 - mae: 16.4271 - val_loss: 182.5858 - val_mae: 10.4388\n",
      "Epoch 17/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 446.0137 - mae: 16.1805 - val_loss: 174.7616 - val_mae: 10.0199\n",
      "Epoch 18/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 436.2945 - mae: 16.4455 - val_loss: 202.0095 - val_mae: 11.1063\n",
      "Epoch 19/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 453.6308 - mae: 16.6591 - val_loss: 164.8039 - val_mae: 9.7807\n",
      "Epoch 20/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 428.8948 - mae: 16.0719 - val_loss: 202.6975 - val_mae: 11.1567\n",
      "Epoch 21/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 456.9152 - mae: 16.5567 - val_loss: 150.5917 - val_mae: 9.2083\n",
      "Epoch 22/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 443.8362 - mae: 16.2484 - val_loss: 147.0726 - val_mae: 9.0463\n",
      "Epoch 23/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 427.4656 - mae: 16.1466 - val_loss: 155.2071 - val_mae: 9.2346\n",
      "Epoch 24/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 447.5207 - mae: 16.4508 - val_loss: 162.8329 - val_mae: 9.6650\n",
      "Epoch 25/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 455.4213 - mae: 16.6723 - val_loss: 146.7185 - val_mae: 8.9193\n",
      "Epoch 26/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 455.7001 - mae: 16.5356 - val_loss: 172.5134 - val_mae: 9.8477\n",
      "Epoch 27/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 438.4791 - mae: 16.2605 - val_loss: 158.1586 - val_mae: 9.4608\n",
      "Epoch 28/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 446.5114 - mae: 16.4192 - val_loss: 154.0538 - val_mae: 9.2926\n",
      "Epoch 29/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 422.7297 - mae: 16.0228 - val_loss: 146.9285 - val_mae: 9.0458\n",
      "Epoch 30/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 430.3157 - mae: 16.1705 - val_loss: 143.0230 - val_mae: 8.9421\n",
      "Epoch 31/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 424.0391 - mae: 15.8943 - val_loss: 152.5992 - val_mae: 9.2251\n",
      "Epoch 32/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 417.2874 - mae: 15.7923 - val_loss: 143.9108 - val_mae: 8.8606\n",
      "Epoch 33/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 401.5063 - mae: 15.5316 - val_loss: 186.6109 - val_mae: 10.6414\n",
      "Epoch 34/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 433.5901 - mae: 16.1732 - val_loss: 138.7881 - val_mae: 8.6966\n",
      "Epoch 35/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 425.6619 - mae: 15.9148 - val_loss: 141.1846 - val_mae: 8.7913\n",
      "Epoch 36/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 405.5999 - mae: 15.4822 - val_loss: 199.0434 - val_mae: 11.2899\n",
      "Epoch 37/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 398.7405 - mae: 15.4243 - val_loss: 162.0474 - val_mae: 9.4346\n",
      "Epoch 38/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 422.6030 - mae: 15.9628 - val_loss: 148.4414 - val_mae: 9.0246\n",
      "Epoch 39/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 403.6439 - mae: 15.5385 - val_loss: 136.8692 - val_mae: 8.7121\n",
      "Epoch 40/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 413.0171 - mae: 15.7164 - val_loss: 161.7954 - val_mae: 9.6659\n",
      "Epoch 41/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 439.0762 - mae: 16.1023 - val_loss: 196.5447 - val_mae: 11.1335\n",
      "Epoch 42/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 420.7040 - mae: 15.8761 - val_loss: 145.3280 - val_mae: 9.0048\n",
      "Epoch 43/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 392.1508 - mae: 15.2926 - val_loss: 138.3463 - val_mae: 8.7020\n",
      "Epoch 44/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 399.5063 - mae: 15.4530 - val_loss: 281.4823 - val_mae: 14.0220\n",
      "Epoch 45/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 420.0604 - mae: 15.9995 - val_loss: 178.1369 - val_mae: 10.4380\n",
      "Epoch 46/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 426.6408 - mae: 16.0306 - val_loss: 138.0244 - val_mae: 8.6614\n",
      "Epoch 47/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.5359 - mae: 15.7256 - val_loss: 143.1637 - val_mae: 8.8268\n",
      "Epoch 48/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 426.7022 - mae: 16.1492 - val_loss: 153.9459 - val_mae: 9.2447\n",
      "Epoch 49/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 405.8043 - mae: 15.7179 - val_loss: 135.6743 - val_mae: 8.6578\n",
      "Epoch 50/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 386.4642 - mae: 15.1678 - val_loss: 136.9572 - val_mae: 8.6944\n",
      "Patience 10: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.9898 - mae: 8.6946\n",
      "Patience 10: Validation MAE: 8.66\n",
      "Patience 10: Validation Loss: 135.67\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 130.7982, MAE = 8.3416, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 133.9735, MAE = 8.5733, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 20: Loss = 133.4155, MAE = 8.3988, Early Stopping Occurred: True, Early Stopping Epoch: 45\n",
      "Patience 10: Loss = 135.6743, MAE = 8.6578, Early Stopping Occurred: False, Early Stopping Epoch: None\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "results = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    sbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    sbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_{}.keras'.format(patience), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = sbp_model.fit(\n",
    "        X_train_combined, SBP_Y_train_combined,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_combined, SBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = sbp_model.evaluate(X_test_combined, SBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    results.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in results:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 2660.0659 - mae: 37.6102 - val_loss: 335.8769 - val_mae: 14.5281\n",
      "Epoch 2/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 726.2780 - mae: 21.1000 - val_loss: 279.9557 - val_mae: 13.2839\n",
      "Epoch 3/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 659.7251 - mae: 20.3383 - val_loss: 348.3882 - val_mae: 14.1439\n",
      "Epoch 4/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 627.9362 - mae: 19.4981 - val_loss: 344.6612 - val_mae: 14.3677\n",
      "Epoch 5/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 607.0952 - mae: 19.3225 - val_loss: 272.5487 - val_mae: 12.8472\n",
      "Epoch 6/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 563.4960 - mae: 18.3688 - val_loss: 228.4538 - val_mae: 11.6982\n",
      "Epoch 7/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 515.2777 - mae: 17.9654 - val_loss: 160.4819 - val_mae: 9.6217\n",
      "Epoch 8/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 468.4193 - mae: 16.9073 - val_loss: 192.8147 - val_mae: 10.8068\n",
      "Epoch 9/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 483.3150 - mae: 17.0126 - val_loss: 151.4621 - val_mae: 9.3065\n",
      "Epoch 10/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 490.1847 - mae: 17.3823 - val_loss: 152.3705 - val_mae: 9.3957\n",
      "Epoch 11/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 465.3393 - mae: 16.8972 - val_loss: 154.5885 - val_mae: 9.2646\n",
      "Epoch 12/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 460.0537 - mae: 16.6254 - val_loss: 155.8893 - val_mae: 9.3730\n",
      "Epoch 13/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 451.2543 - mae: 16.5462 - val_loss: 163.4556 - val_mae: 9.8018\n",
      "Epoch 14/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 460.4170 - mae: 16.5188 - val_loss: 148.1637 - val_mae: 9.1881\n",
      "Epoch 15/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 437.4397 - mae: 16.2363 - val_loss: 231.5526 - val_mae: 12.0192\n",
      "Epoch 16/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 476.0968 - mae: 17.0288 - val_loss: 141.4871 - val_mae: 8.9299\n",
      "Epoch 17/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 413.2765 - mae: 15.8793 - val_loss: 215.2008 - val_mae: 11.8578\n",
      "Epoch 18/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 430.2403 - mae: 16.1822 - val_loss: 152.8475 - val_mae: 9.3151\n",
      "Epoch 19/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 438.8949 - mae: 16.3238 - val_loss: 142.0887 - val_mae: 8.9194\n",
      "Epoch 20/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 418.1823 - mae: 15.9561 - val_loss: 139.4304 - val_mae: 8.9083\n",
      "Epoch 21/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 444.8976 - mae: 16.3506 - val_loss: 143.5409 - val_mae: 8.8799\n",
      "Epoch 22/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 441.4450 - mae: 16.3867 - val_loss: 136.3548 - val_mae: 8.6486\n",
      "Epoch 23/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 431.1597 - mae: 16.0285 - val_loss: 183.0245 - val_mae: 10.3511\n",
      "Epoch 24/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 449.9811 - mae: 16.4646 - val_loss: 171.4244 - val_mae: 10.1958\n",
      "Epoch 25/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 449.1093 - mae: 16.4646 - val_loss: 140.0929 - val_mae: 8.8516\n",
      "Epoch 26/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 428.2607 - mae: 16.1953 - val_loss: 135.2880 - val_mae: 8.6183\n",
      "Epoch 27/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 431.1826 - mae: 16.1436 - val_loss: 179.2994 - val_mae: 10.4941\n",
      "Epoch 28/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 437.0338 - mae: 16.2122 - val_loss: 136.4565 - val_mae: 8.7776\n",
      "Epoch 29/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.3106 - mae: 15.7662 - val_loss: 148.9687 - val_mae: 9.2104\n",
      "Epoch 30/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 419.1017 - mae: 15.8979 - val_loss: 155.9819 - val_mae: 9.4388\n",
      "Epoch 31/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 438.1626 - mae: 16.1288 - val_loss: 228.2869 - val_mae: 12.3206\n",
      "Epoch 32/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.7101 - mae: 15.9886 - val_loss: 165.5505 - val_mae: 10.0334\n",
      "Epoch 33/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.8214 - mae: 16.0886 - val_loss: 174.7869 - val_mae: 10.3662\n",
      "Epoch 34/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 412.5168 - mae: 15.7164 - val_loss: 134.9238 - val_mae: 8.7031\n",
      "Epoch 35/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.8074 - mae: 15.5844 - val_loss: 150.5951 - val_mae: 9.3057\n",
      "Epoch 36/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 437.8864 - mae: 16.0948 - val_loss: 187.8601 - val_mae: 10.8974\n",
      "Epoch 37/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 422.7375 - mae: 16.1721 - val_loss: 138.7018 - val_mae: 8.5566\n",
      "Epoch 38/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.5538 - mae: 16.0657 - val_loss: 168.8447 - val_mae: 10.1100\n",
      "Epoch 39/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 437.6763 - mae: 16.0559 - val_loss: 139.7021 - val_mae: 8.6570\n",
      "Epoch 40/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.7436 - mae: 15.6967 - val_loss: 136.3745 - val_mae: 8.5666\n",
      "Epoch 41/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410.3430 - mae: 15.7715 - val_loss: 143.1480 - val_mae: 9.0563\n",
      "Epoch 42/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.9352 - mae: 15.7542 - val_loss: 135.7089 - val_mae: 8.6309\n",
      "Epoch 43/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409.0623 - mae: 15.5490 - val_loss: 149.1076 - val_mae: 9.3309\n",
      "Epoch 44/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.8426 - mae: 15.6429 - val_loss: 147.7508 - val_mae: 9.1201\n",
      "Epoch 45/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 401.4901 - mae: 15.5334 - val_loss: 133.5136 - val_mae: 8.5846\n",
      "Epoch 46/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 415.7755 - mae: 15.9857 - val_loss: 132.2613 - val_mae: 8.4391\n",
      "Epoch 47/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 390.5515 - mae: 15.3244 - val_loss: 152.2507 - val_mae: 9.3981\n",
      "Epoch 48/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 407.3169 - mae: 15.7352 - val_loss: 133.5829 - val_mae: 8.4948\n",
      "Epoch 49/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 389.0600 - mae: 15.1648 - val_loss: 132.6063 - val_mae: 8.5447\n",
      "Epoch 50/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 410.8595 - mae: 15.7210 - val_loss: 161.8401 - val_mae: 9.7255\n",
      "Epoch 51/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 396.1154 - mae: 15.4567 - val_loss: 148.1476 - val_mae: 9.3186\n",
      "Epoch 52/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 416.5235 - mae: 15.8706 - val_loss: 132.0500 - val_mae: 8.4166\n",
      "Epoch 53/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.2862 - mae: 15.2021 - val_loss: 137.5664 - val_mae: 8.6979\n",
      "Epoch 54/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.8506 - mae: 15.1885 - val_loss: 149.5080 - val_mae: 9.3545\n",
      "Epoch 55/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.9772 - mae: 15.2532 - val_loss: 147.8922 - val_mae: 9.2643\n",
      "Epoch 56/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 390.9232 - mae: 15.2027 - val_loss: 139.4400 - val_mae: 8.7771\n",
      "Epoch 57/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.1109 - mae: 15.1989 - val_loss: 187.5301 - val_mae: 10.7464\n",
      "Epoch 58/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 402.6260 - mae: 15.5512 - val_loss: 153.7974 - val_mae: 9.5910\n",
      "Epoch 59/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.6037 - mae: 15.3562 - val_loss: 135.9491 - val_mae: 8.4706\n",
      "Epoch 60/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 380.1596 - mae: 15.1636 - val_loss: 147.9901 - val_mae: 9.1698\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 145.1888 - mae: 8.4778\n",
      "Patience 40: Validation MAE: 8.42\n",
      "Patience 40: Validation Loss: 132.05\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2263.5962 - mae: 34.3710 - val_loss: 329.3357 - val_mae: 13.8312\n",
      "Epoch 2/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 690.0195 - mae: 20.7915 - val_loss: 356.2259 - val_mae: 14.1067\n",
      "Epoch 3/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 653.4977 - mae: 19.9672 - val_loss: 243.5459 - val_mae: 11.8363\n",
      "Epoch 4/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 619.2867 - mae: 19.5941 - val_loss: 201.8539 - val_mae: 11.0936\n",
      "Epoch 5/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 559.6918 - mae: 18.4084 - val_loss: 209.9557 - val_mae: 11.0194\n",
      "Epoch 6/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 519.1502 - mae: 17.8664 - val_loss: 214.0099 - val_mae: 11.4900\n",
      "Epoch 7/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 548.3091 - mae: 18.1344 - val_loss: 173.8268 - val_mae: 9.9549\n",
      "Epoch 8/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 515.6169 - mae: 17.5552 - val_loss: 194.8403 - val_mae: 10.7918\n",
      "Epoch 9/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 515.5239 - mae: 17.7696 - val_loss: 218.1378 - val_mae: 11.5973\n",
      "Epoch 10/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 483.6926 - mae: 17.1849 - val_loss: 161.5678 - val_mae: 9.5376\n",
      "Epoch 11/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 503.2522 - mae: 17.3634 - val_loss: 164.9354 - val_mae: 9.7236\n",
      "Epoch 12/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 514.6376 - mae: 17.6030 - val_loss: 191.3623 - val_mae: 10.7218\n",
      "Epoch 13/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 496.1332 - mae: 17.2724 - val_loss: 154.3738 - val_mae: 9.2764\n",
      "Epoch 14/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 461.7185 - mae: 16.6953 - val_loss: 192.3707 - val_mae: 10.7578\n",
      "Epoch 15/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 514.9461 - mae: 17.6983 - val_loss: 156.0429 - val_mae: 9.3011\n",
      "Epoch 16/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.7282 - mae: 16.5584 - val_loss: 164.6390 - val_mae: 9.7370\n",
      "Epoch 17/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 473.8463 - mae: 17.0112 - val_loss: 157.8824 - val_mae: 9.4299\n",
      "Epoch 18/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 476.9471 - mae: 16.9631 - val_loss: 147.7316 - val_mae: 9.0845\n",
      "Epoch 19/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 485.5040 - mae: 17.0900 - val_loss: 145.8657 - val_mae: 8.9602\n",
      "Epoch 20/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 504.2747 - mae: 17.3223 - val_loss: 203.5091 - val_mae: 11.1069\n",
      "Epoch 21/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 476.7126 - mae: 17.1156 - val_loss: 145.6716 - val_mae: 8.9306\n",
      "Epoch 22/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 466.4188 - mae: 16.8476 - val_loss: 150.3495 - val_mae: 9.0430\n",
      "Epoch 23/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 474.5447 - mae: 16.9322 - val_loss: 155.2527 - val_mae: 9.3962\n",
      "Epoch 24/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 440.3417 - mae: 16.3871 - val_loss: 179.3648 - val_mae: 10.4937\n",
      "Epoch 25/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 481.2783 - mae: 17.1031 - val_loss: 189.3825 - val_mae: 10.8030\n",
      "Epoch 26/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 451.9505 - mae: 16.6815 - val_loss: 160.2605 - val_mae: 9.7256\n",
      "Epoch 27/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 451.1339 - mae: 16.4793 - val_loss: 142.4675 - val_mae: 8.8522\n",
      "Epoch 28/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 465.7598 - mae: 16.6386 - val_loss: 137.6548 - val_mae: 8.6094\n",
      "Epoch 29/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 470.2625 - mae: 16.7842 - val_loss: 144.1099 - val_mae: 9.0518\n",
      "Epoch 30/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.9893 - mae: 16.7929 - val_loss: 153.2514 - val_mae: 9.3242\n",
      "Epoch 31/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 475.6709 - mae: 16.9315 - val_loss: 158.6419 - val_mae: 9.5466\n",
      "Epoch 32/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450.9160 - mae: 16.7492 - val_loss: 137.8288 - val_mae: 8.6739\n",
      "Epoch 33/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 469.9873 - mae: 16.8880 - val_loss: 154.2703 - val_mae: 9.5304\n",
      "Epoch 34/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.4547 - mae: 16.6100 - val_loss: 141.4053 - val_mae: 8.9133\n",
      "Epoch 35/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 445.3969 - mae: 16.3304 - val_loss: 144.0557 - val_mae: 9.0596\n",
      "Epoch 36/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 448.3385 - mae: 16.4290 - val_loss: 161.0040 - val_mae: 9.7033\n",
      "Epoch 37/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.2758 - mae: 16.7054 - val_loss: 140.1021 - val_mae: 8.6987\n",
      "Epoch 38/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.2376 - mae: 16.7270 - val_loss: 163.7388 - val_mae: 9.6958\n",
      "Epoch 39/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 438.0239 - mae: 16.4381 - val_loss: 147.3174 - val_mae: 9.1739\n",
      "Epoch 40/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 460.1616 - mae: 16.5927 - val_loss: 171.4860 - val_mae: 9.8034\n",
      "Epoch 41/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 452.0936 - mae: 16.7945 - val_loss: 148.3730 - val_mae: 8.9334\n",
      "Epoch 42/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 446.8086 - mae: 16.5199 - val_loss: 140.5166 - val_mae: 8.7626\n",
      "Epoch 43/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 455.2011 - mae: 16.5379 - val_loss: 209.3752 - val_mae: 11.5490\n",
      "Epoch 44/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 456.6767 - mae: 16.5177 - val_loss: 146.0249 - val_mae: 8.8650\n",
      "Epoch 45/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 435.9745 - mae: 16.2150 - val_loss: 140.2038 - val_mae: 8.8139\n",
      "Epoch 46/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.2110 - mae: 15.8299 - val_loss: 178.0069 - val_mae: 10.4679\n",
      "Epoch 47/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 442.8555 - mae: 16.3754 - val_loss: 131.8998 - val_mae: 8.3849\n",
      "Epoch 48/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 443.2411 - mae: 16.2677 - val_loss: 152.6261 - val_mae: 9.4237\n",
      "Epoch 49/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.2281 - mae: 16.2584 - val_loss: 133.3598 - val_mae: 8.5454\n",
      "Epoch 50/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 440.0178 - mae: 16.2383 - val_loss: 139.1847 - val_mae: 8.6619\n",
      "Epoch 51/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 450.4219 - mae: 16.2292 - val_loss: 141.0110 - val_mae: 8.9161\n",
      "Epoch 52/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 426.5585 - mae: 15.8861 - val_loss: 134.0851 - val_mae: 8.4037\n",
      "Epoch 53/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 428.3416 - mae: 16.0052 - val_loss: 137.3273 - val_mae: 8.6664\n",
      "Epoch 54/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 440.2193 - mae: 16.2780 - val_loss: 141.3403 - val_mae: 9.0009\n",
      "Epoch 55/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 401.3595 - mae: 15.5939 - val_loss: 178.7913 - val_mae: 10.5768\n",
      "Epoch 56/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434.9600 - mae: 16.1941 - val_loss: 135.3928 - val_mae: 8.5879\n",
      "Epoch 57/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 428.9623 - mae: 16.2453 - val_loss: 218.4741 - val_mae: 11.9709\n",
      "Epoch 58/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441.6256 - mae: 16.4816 - val_loss: 152.2943 - val_mae: 9.3648\n",
      "Epoch 59/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 448.5402 - mae: 16.4555 - val_loss: 136.8833 - val_mae: 8.7461\n",
      "Epoch 60/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.7785 - mae: 16.1807 - val_loss: 132.8251 - val_mae: 8.3304\n",
      "Patience 30: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 142.0912 - mae: 8.3742\n",
      "Patience 30: Validation MAE: 8.38\n",
      "Patience 30: Validation Loss: 131.90\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2732.9758 - mae: 38.0946 - val_loss: 402.0098 - val_mae: 14.6549\n",
      "Epoch 2/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 833.7571 - mae: 22.5558 - val_loss: 313.3476 - val_mae: 13.7728\n",
      "Epoch 3/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 723.6130 - mae: 21.3552 - val_loss: 282.1398 - val_mae: 13.8364\n",
      "Epoch 4/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 695.4171 - mae: 20.8609 - val_loss: 343.3621 - val_mae: 13.8204\n",
      "Epoch 5/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 704.8497 - mae: 20.8189 - val_loss: 279.2776 - val_mae: 12.5618\n",
      "Epoch 6/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 639.2498 - mae: 19.7997 - val_loss: 211.6243 - val_mae: 11.1519\n",
      "Epoch 7/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 639.1559 - mae: 19.7792 - val_loss: 211.2061 - val_mae: 10.9277\n",
      "Epoch 8/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 603.6703 - mae: 19.1811 - val_loss: 252.6437 - val_mae: 12.3303\n",
      "Epoch 9/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 568.4765 - mae: 18.5540 - val_loss: 177.6004 - val_mae: 9.9902\n",
      "Epoch 10/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 552.4600 - mae: 18.3063 - val_loss: 165.3858 - val_mae: 9.7526\n",
      "Epoch 11/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 536.9853 - mae: 18.1855 - val_loss: 177.3826 - val_mae: 10.0659\n",
      "Epoch 12/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 610.0781 - mae: 19.1168 - val_loss: 320.6609 - val_mae: 14.9489\n",
      "Epoch 13/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 599.4617 - mae: 19.0866 - val_loss: 156.4242 - val_mae: 9.4038\n",
      "Epoch 14/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 541.1232 - mae: 18.2182 - val_loss: 180.9256 - val_mae: 10.1576\n",
      "Epoch 15/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 548.5617 - mae: 18.2348 - val_loss: 147.5146 - val_mae: 9.0760\n",
      "Epoch 16/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 561.1891 - mae: 18.5300 - val_loss: 155.9036 - val_mae: 9.4288\n",
      "Epoch 17/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 570.4290 - mae: 18.5966 - val_loss: 158.4074 - val_mae: 9.5525\n",
      "Epoch 18/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 580.7650 - mae: 18.7131 - val_loss: 248.1810 - val_mae: 12.8464\n",
      "Epoch 19/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 554.1266 - mae: 18.4719 - val_loss: 216.1864 - val_mae: 11.3990\n",
      "Epoch 20/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 515.8087 - mae: 17.8651 - val_loss: 147.2901 - val_mae: 9.0611\n",
      "Epoch 21/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 518.3688 - mae: 17.9283 - val_loss: 146.8351 - val_mae: 9.0091\n",
      "Epoch 22/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 555.4662 - mae: 18.2745 - val_loss: 153.2569 - val_mae: 9.2445\n",
      "Epoch 23/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 560.6456 - mae: 18.6297 - val_loss: 144.0482 - val_mae: 8.8785\n",
      "Epoch 24/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 535.1727 - mae: 18.0099 - val_loss: 144.7291 - val_mae: 8.8571\n",
      "Epoch 25/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 550.5142 - mae: 18.2794 - val_loss: 148.2502 - val_mae: 9.0246\n",
      "Epoch 26/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 532.0961 - mae: 18.0588 - val_loss: 158.8018 - val_mae: 9.5370\n",
      "Epoch 27/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 502.1414 - mae: 17.5701 - val_loss: 175.2673 - val_mae: 10.1594\n",
      "Epoch 28/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 508.3799 - mae: 17.6238 - val_loss: 138.7439 - val_mae: 8.6811\n",
      "Epoch 29/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 506.6600 - mae: 17.7167 - val_loss: 220.4596 - val_mae: 11.5884\n",
      "Epoch 30/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 545.6775 - mae: 18.2904 - val_loss: 158.5434 - val_mae: 9.5803\n",
      "Epoch 31/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 500.4286 - mae: 17.4709 - val_loss: 156.5195 - val_mae: 9.2642\n",
      "Epoch 32/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 520.6822 - mae: 17.6567 - val_loss: 163.5577 - val_mae: 9.7148\n",
      "Epoch 33/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 502.7265 - mae: 17.5970 - val_loss: 133.1646 - val_mae: 8.4377\n",
      "Epoch 34/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 504.3677 - mae: 17.5170 - val_loss: 136.0211 - val_mae: 8.6312\n",
      "Epoch 35/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 495.6391 - mae: 17.2230 - val_loss: 139.8829 - val_mae: 8.7141\n",
      "Epoch 36/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 489.0756 - mae: 17.3207 - val_loss: 170.9985 - val_mae: 9.9236\n",
      "Epoch 37/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 491.1229 - mae: 17.3647 - val_loss: 137.5718 - val_mae: 8.6907\n",
      "Epoch 38/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 484.3297 - mae: 17.2483 - val_loss: 159.7872 - val_mae: 9.3424\n",
      "Epoch 39/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 481.4989 - mae: 17.1307 - val_loss: 151.6057 - val_mae: 9.1190\n",
      "Epoch 40/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 521.2386 - mae: 17.6926 - val_loss: 187.5217 - val_mae: 10.4501\n",
      "Epoch 41/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461.9874 - mae: 16.8999 - val_loss: 152.9880 - val_mae: 9.4310\n",
      "Epoch 42/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 484.8371 - mae: 17.0449 - val_loss: 193.9336 - val_mae: 11.0647\n",
      "Epoch 43/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 496.2596 - mae: 17.3509 - val_loss: 132.8492 - val_mae: 8.4264\n",
      "Epoch 44/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 489.1385 - mae: 17.3545 - val_loss: 149.7353 - val_mae: 9.3215\n",
      "Epoch 45/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450.5102 - mae: 16.8357 - val_loss: 153.0172 - val_mae: 9.3047\n",
      "Epoch 46/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 470.9638 - mae: 16.9324 - val_loss: 144.1632 - val_mae: 8.7229\n",
      "Epoch 47/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.8997 - mae: 17.0053 - val_loss: 142.1997 - val_mae: 8.9302\n",
      "Epoch 48/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459.9100 - mae: 16.6792 - val_loss: 149.9599 - val_mae: 9.2636\n",
      "Epoch 49/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 479.9606 - mae: 17.1525 - val_loss: 167.2610 - val_mae: 9.8142\n",
      "Epoch 50/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 463.2240 - mae: 16.7198 - val_loss: 132.2028 - val_mae: 8.4935\n",
      "Epoch 51/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461.2342 - mae: 16.6431 - val_loss: 138.2715 - val_mae: 8.6618\n",
      "Epoch 52/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 492.6050 - mae: 17.3183 - val_loss: 130.9753 - val_mae: 8.3171\n",
      "Epoch 53/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 477.8329 - mae: 16.9924 - val_loss: 147.1512 - val_mae: 9.1684\n",
      "Epoch 54/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436.9755 - mae: 16.4027 - val_loss: 193.0925 - val_mae: 10.8622\n",
      "Epoch 55/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 480.6357 - mae: 16.9935 - val_loss: 149.8505 - val_mae: 9.1720\n",
      "Epoch 56/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 447.3636 - mae: 16.5592 - val_loss: 131.6232 - val_mae: 8.4888\n",
      "Epoch 57/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 472.4994 - mae: 16.9273 - val_loss: 149.2261 - val_mae: 9.2066\n",
      "Epoch 58/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.2849 - mae: 16.7812 - val_loss: 134.1223 - val_mae: 8.4991\n",
      "Epoch 59/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 456.5357 - mae: 16.7473 - val_loss: 135.0110 - val_mae: 8.6092\n",
      "Epoch 60/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 445.0871 - mae: 16.3855 - val_loss: 145.1645 - val_mae: 9.0165\n",
      "Patience 20: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 145.5004 - mae: 8.4302\n",
      "Patience 20: Validation MAE: 8.32\n",
      "Patience 20: Validation Loss: 130.98\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3432.1438 - mae: 38.8284 - val_loss: 315.6544 - val_mae: 13.8290\n",
      "Epoch 2/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 716.4574 - mae: 20.8001 - val_loss: 264.9380 - val_mae: 12.8015\n",
      "Epoch 3/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 633.2377 - mae: 20.0573 - val_loss: 243.8321 - val_mae: 11.9650\n",
      "Epoch 4/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 568.5576 - mae: 18.8311 - val_loss: 201.5931 - val_mae: 11.0293\n",
      "Epoch 5/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 570.8619 - mae: 18.5736 - val_loss: 195.8046 - val_mae: 10.8537\n",
      "Epoch 6/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 540.1967 - mae: 18.1806 - val_loss: 222.4901 - val_mae: 11.7061\n",
      "Epoch 7/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 500.0784 - mae: 17.4001 - val_loss: 159.5271 - val_mae: 9.5562\n",
      "Epoch 8/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 475.0110 - mae: 17.2439 - val_loss: 193.8619 - val_mae: 10.6928\n",
      "Epoch 9/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 497.6473 - mae: 17.1898 - val_loss: 151.3315 - val_mae: 9.2516\n",
      "Epoch 10/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.9648 - mae: 16.8824 - val_loss: 211.5049 - val_mae: 11.1422\n",
      "Epoch 11/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 473.8357 - mae: 16.8920 - val_loss: 154.4598 - val_mae: 9.3602\n",
      "Epoch 12/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.2079 - mae: 16.8260 - val_loss: 165.5616 - val_mae: 9.6184\n",
      "Epoch 13/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 449.5642 - mae: 16.4520 - val_loss: 178.6131 - val_mae: 10.3284\n",
      "Epoch 14/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 448.3039 - mae: 16.5383 - val_loss: 143.8835 - val_mae: 8.9248\n",
      "Epoch 15/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 442.9149 - mae: 16.4904 - val_loss: 174.1659 - val_mae: 9.9603\n",
      "Epoch 16/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 453.2764 - mae: 16.7493 - val_loss: 140.2142 - val_mae: 8.8127\n",
      "Epoch 17/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 456.1904 - mae: 16.6562 - val_loss: 153.8204 - val_mae: 9.1995\n",
      "Epoch 18/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 452.7164 - mae: 16.4917 - val_loss: 174.8765 - val_mae: 10.3681\n",
      "Epoch 19/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 447.2944 - mae: 16.4626 - val_loss: 147.4940 - val_mae: 9.0271\n",
      "Epoch 20/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450.8369 - mae: 16.3234 - val_loss: 157.1741 - val_mae: 9.2324\n",
      "Epoch 21/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431.1079 - mae: 16.2359 - val_loss: 150.6167 - val_mae: 9.3001\n",
      "Epoch 22/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 451.3082 - mae: 16.2961 - val_loss: 150.1362 - val_mae: 9.1798\n",
      "Epoch 23/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428.1443 - mae: 16.0511 - val_loss: 169.6069 - val_mae: 10.0506\n",
      "Epoch 24/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 432.7828 - mae: 16.2768 - val_loss: 136.9683 - val_mae: 8.5729\n",
      "Epoch 25/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.5708 - mae: 16.1934 - val_loss: 142.5622 - val_mae: 8.9007\n",
      "Epoch 26/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.6017 - mae: 15.7205 - val_loss: 152.0175 - val_mae: 9.3544\n",
      "Epoch 27/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428.7100 - mae: 16.0131 - val_loss: 149.7207 - val_mae: 8.9774\n",
      "Epoch 28/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 465.8178 - mae: 16.6993 - val_loss: 151.3754 - val_mae: 9.1074\n",
      "Epoch 29/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.7185 - mae: 16.1087 - val_loss: 142.7219 - val_mae: 8.9173\n",
      "Epoch 30/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 423.6629 - mae: 16.1535 - val_loss: 168.4927 - val_mae: 9.6066\n",
      "Epoch 31/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441.9429 - mae: 16.2453 - val_loss: 134.2643 - val_mae: 8.5144\n",
      "Epoch 32/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.7225 - mae: 15.7946 - val_loss: 142.3448 - val_mae: 8.8462\n",
      "Epoch 33/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.3477 - mae: 15.7123 - val_loss: 141.9995 - val_mae: 8.8478\n",
      "Epoch 34/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 452.0950 - mae: 16.4762 - val_loss: 135.3893 - val_mae: 8.5559\n",
      "Epoch 35/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.7404 - mae: 15.9858 - val_loss: 138.4906 - val_mae: 8.7157\n",
      "Epoch 36/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.8236 - mae: 15.1191 - val_loss: 185.4985 - val_mae: 10.2392\n",
      "Epoch 37/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 425.0376 - mae: 15.9979 - val_loss: 138.1659 - val_mae: 8.7744\n",
      "Epoch 38/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 408.8012 - mae: 15.6059 - val_loss: 140.8367 - val_mae: 8.7730\n",
      "Epoch 39/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.6088 - mae: 15.8342 - val_loss: 146.7848 - val_mae: 9.1863\n",
      "Epoch 40/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 412.7041 - mae: 15.7688 - val_loss: 133.8357 - val_mae: 8.4918\n",
      "Epoch 41/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.3130 - mae: 15.8986 - val_loss: 138.3859 - val_mae: 8.5026\n",
      "Epoch 42/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.3064 - mae: 15.8140 - val_loss: 140.3355 - val_mae: 8.8519\n",
      "Epoch 43/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.2805 - mae: 15.4107 - val_loss: 139.2371 - val_mae: 8.8317\n",
      "Epoch 44/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385.4476 - mae: 15.0470 - val_loss: 158.0092 - val_mae: 9.4744\n",
      "Epoch 45/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.4556 - mae: 15.6850 - val_loss: 142.3647 - val_mae: 8.7449\n",
      "Epoch 46/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.9048 - mae: 15.6782 - val_loss: 218.3295 - val_mae: 11.8288\n",
      "Epoch 47/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.0383 - mae: 15.4826 - val_loss: 133.8416 - val_mae: 8.6310\n",
      "Epoch 48/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.6218 - mae: 15.4851 - val_loss: 145.6611 - val_mae: 8.8919\n",
      "Epoch 49/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.8138 - mae: 15.9211 - val_loss: 136.9196 - val_mae: 8.5466\n",
      "Epoch 50/60\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.1682 - mae: 15.2770 - val_loss: 143.9404 - val_mae: 9.1164\n",
      "Patience 10: Early stopping occurred at epoch 49\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.6518 - mae: 8.5349\n",
      "Patience 10: Validation MAE: 8.49\n",
      "Patience 10: Validation Loss: 133.84\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 132.0500, MAE = 8.4166, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 131.8998, MAE = 8.3849, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 20: Loss = 130.9753, MAE = 8.3171, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 10: Loss = 133.8357, MAE = 8.4918, Early Stopping Occurred: True, Early Stopping Epoch: 49\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "results = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    sbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    sbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_{}.keras'.format(patience), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = sbp_model.fit(\n",
    "        X_train_combined, SBP_Y_train_combined,\n",
    "        epochs=60,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_combined, SBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = sbp_model.evaluate(X_test_combined, SBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    results.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in results:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(patience), monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43msbp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSBP_Y_train_combined\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSBP_Y_test_combined\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Early stopping 여부와 발생한 epoch 저장\u001b[39;00m\n\u001b[1;32m     37\u001b[0m early_stopping_occurred \u001b[38;5;241m=\u001b[39m early_stopping\u001b[38;5;241m.\u001b[39mstopped_epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:889\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    888\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 889\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:339\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[1;32m    338\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph artifact\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools\u001b[38;5;241m.\u001b[39mpartial):\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:121\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m--> 121\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    125\u001b[0m     outputs,\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    127\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    128\u001b[0m )\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1669\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1672\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3263\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:4061\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4060\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:889\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    888\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 889\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:339\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[1;32m    338\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph artifact\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools\u001b[38;5;241m.\u001b[39mpartial):\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:108\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:73\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     70\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, trainable_weights)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model does not have any trainable weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:344\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    343\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterations\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:409\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    406\u001b[0m     grads \u001b[38;5;241m=\u001b[39m [g \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m g \u001b[38;5;241m/\u001b[39m scale \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:472\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# Run udpate step.\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_update_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_variables_moving_average(\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables\n\u001b[1;32m    479\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/optimizer.py:122\u001b[0m, in \u001b[0;36mTFOptimizer._backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    120\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[1;32m    121\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_reduce_sum_gradients(grads_and_vars)\n\u001b[0;32m--> 122\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_tf_update_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/optimizer.py:136\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(grad, var, learning_rate)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m--> 136\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3007\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3007\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_replica_ctx_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3008\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:2886\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_fn\u001b[39m(_, \u001b[38;5;241m*\u001b[39mmerged_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerged_kwargs):\n\u001b[1;32m   2884\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(var, fn, merged_args, merged_kwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n\u001b[0;32m-> 2886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreplica_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3478\u001b[0m, in \u001b[0;36mReplicaContextBase.merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3476\u001b[0m merge_fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3477\u001b[0m     merge_fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 3478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3485\u001b[0m, in \u001b[0;36mReplicaContextBase._merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m _push_per_thread_mode(  \u001b[38;5;66;03m# thread-local, so not needed with multiple threads\u001b[39;00m\n\u001b[1;32m   3483\u001b[0m     _CrossReplicaThreadMode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3485\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3487\u001b[0m   _pop_per_thread_mode()\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:2884\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update.<locals>.merge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_fn\u001b[39m(_, \u001b[38;5;241m*\u001b[39mmerged_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerged_kwargs):\n\u001b[0;32m-> 2884\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3005\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3002\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3003\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3004\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3007\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3008\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:4075\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4073\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4074\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4075\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:4081\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4078\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4079\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4081\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   4083\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/optimizer.py:133\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad, learning_rate):\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/optimizers/adam.py:147\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign(v_hat, ops\u001b[38;5;241m.\u001b[39mmaximum(v_hat, v))\n\u001b[1;32m    144\u001b[0m     v \u001b[38;5;241m=\u001b[39m v_hat\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_sub(\n\u001b[1;32m    146\u001b[0m     variable,\n\u001b[0;32m--> 147\u001b[0m     \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivide\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    150\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/ops/numpy.py:5874\u001b[0m, in \u001b[0;36mdivide\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   5861\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.ops.divide\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.ops.numpy.divide\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdivide\u001b[39m(x1, x2):\n\u001b[1;32m   5863\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Divide arguments element-wise.\u001b[39;00m\n\u001b[1;32m   5864\u001b[0m \n\u001b[1;32m   5865\u001b[0m \u001b[38;5;124;03m    `keras.ops.true_divide` is an alias for this function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5872\u001b[0m \u001b[38;5;124;03m        Output tensor, the quotient `x1/x2`, element-wise.\u001b[39;00m\n\u001b[1;32m   5873\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43many_symbolic_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   5875\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Divide()\u001b[38;5;241m.\u001b[39msymbolic_call(x1, x2)\n\u001b[1;32m   5876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mdivide(x1, x2)\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/backend/common/keras_tensor.py:349\u001b[0m, in \u001b[0;36many_symbolic_tensors\u001b[0;34m(args, kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;129;01mor\u001b[39;00m ()\n\u001b[1;32m    348\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, KerasTensor):\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/tree/tree_api.py:121\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.tree.flatten\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(structure):\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Flattens a possibly nested structure into a list.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    In the case of dict instances, the sequence consists of the values,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m        A list, the flattened version of the input `structure`.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/tree/optree_impl.py:66\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(structure):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# optree.tree_flatten returns a pair (leaves, treespec) where the first\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# element is a list of leaf values and the second element is a treespec\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# representing the structure of the pytree.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     leaves, _ \u001b[38;5;241m=\u001b[39m \u001b[43moptree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_flatten\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnone_is_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leaves\n",
      "File \u001b[0;32m~/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/optree/ops.py:187\u001b[0m, in \u001b[0;36mtree_flatten\u001b[0;34m(tree, is_leaf, none_is_leaf, namespace)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_flatten\u001b[39m(\n\u001b[1;32m    123\u001b[0m     tree: PyTree[T],\n\u001b[1;32m    124\u001b[0m     is_leaf: Callable[[T], \u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     namespace: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    128\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[T], PyTreeSpec]:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Flatten a pytree.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    See also :func:`tree_flatten_with_path` and :func:`tree_unflatten`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m        second element is a treespec representing the structure of the pytree.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnone_is_leaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "results100 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    sbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    sbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_{}.keras'.format(patience), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = sbp_model.fit(\n",
    "        X_train_combined, SBP_Y_train_combined,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_combined, SBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = sbp_model.evaluate(X_test_combined, SBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    results100.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in results100:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2756.9397 - mae: 38.2122 - val_loss: 329.1886 - val_mae: 14.0466\n",
      "Epoch 2/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 806.1430 - mae: 22.5894 - val_loss: 451.5830 - val_mae: 15.7330\n",
      "Epoch 3/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 796.3928 - mae: 22.3537 - val_loss: 256.7690 - val_mae: 12.7578\n",
      "Epoch 4/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 738.3734 - mae: 21.4442 - val_loss: 246.1388 - val_mae: 12.0865\n",
      "Epoch 5/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 703.0992 - mae: 20.7352 - val_loss: 266.7650 - val_mae: 12.3916\n",
      "Epoch 6/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 604.6635 - mae: 19.4570 - val_loss: 281.0506 - val_mae: 12.6886\n",
      "Epoch 7/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 638.8754 - mae: 19.7918 - val_loss: 192.2794 - val_mae: 10.4928\n",
      "Epoch 8/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 597.9529 - mae: 19.1211 - val_loss: 200.7738 - val_mae: 10.8518\n",
      "Epoch 9/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 564.5402 - mae: 18.3868 - val_loss: 233.0644 - val_mae: 11.7699\n",
      "Epoch 10/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 580.4249 - mae: 18.9301 - val_loss: 161.7012 - val_mae: 9.6505\n",
      "Epoch 11/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 560.4315 - mae: 18.5006 - val_loss: 176.0886 - val_mae: 10.0412\n",
      "Epoch 12/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 591.0107 - mae: 18.9924 - val_loss: 181.7211 - val_mae: 10.4395\n",
      "Epoch 13/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 536.5961 - mae: 18.1714 - val_loss: 227.0120 - val_mae: 11.8906\n",
      "Epoch 14/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 541.1385 - mae: 18.2925 - val_loss: 150.5560 - val_mae: 9.1410\n",
      "Epoch 15/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 567.7482 - mae: 18.5663 - val_loss: 174.3555 - val_mae: 10.1304\n",
      "Epoch 16/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 514.8917 - mae: 17.9215 - val_loss: 149.0420 - val_mae: 9.0979\n",
      "Epoch 17/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 529.2588 - mae: 17.8328 - val_loss: 210.0218 - val_mae: 11.5641\n",
      "Epoch 18/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 531.6822 - mae: 17.9812 - val_loss: 172.3974 - val_mae: 10.1674\n",
      "Epoch 19/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 553.9191 - mae: 18.3363 - val_loss: 149.9832 - val_mae: 9.0253\n",
      "Epoch 20/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 526.5874 - mae: 17.8391 - val_loss: 160.2681 - val_mae: 9.6465\n",
      "Epoch 21/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 510.4176 - mae: 17.8204 - val_loss: 155.1354 - val_mae: 9.3572\n",
      "Epoch 22/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 528.0837 - mae: 17.8067 - val_loss: 153.4171 - val_mae: 9.3262\n",
      "Epoch 23/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 519.1475 - mae: 17.7052 - val_loss: 151.0406 - val_mae: 9.0703\n",
      "Epoch 24/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 499.0023 - mae: 17.6577 - val_loss: 150.7661 - val_mae: 9.2369\n",
      "Epoch 25/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 526.6425 - mae: 17.8406 - val_loss: 140.8350 - val_mae: 8.8443\n",
      "Epoch 26/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 505.9211 - mae: 17.8125 - val_loss: 202.7620 - val_mae: 11.1818\n",
      "Epoch 27/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 505.5055 - mae: 17.6919 - val_loss: 140.9699 - val_mae: 8.8578\n",
      "Epoch 28/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 514.7952 - mae: 17.4749 - val_loss: 170.9611 - val_mae: 9.8392\n",
      "Epoch 29/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 497.7488 - mae: 17.4260 - val_loss: 151.0309 - val_mae: 9.1894\n",
      "Epoch 30/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 492.4112 - mae: 17.4897 - val_loss: 140.4619 - val_mae: 8.6864\n",
      "Epoch 31/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 477.8652 - mae: 17.0357 - val_loss: 146.7111 - val_mae: 9.0756\n",
      "Epoch 32/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 460.7508 - mae: 16.7624 - val_loss: 146.8329 - val_mae: 9.0764\n",
      "Epoch 33/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 488.8318 - mae: 17.1338 - val_loss: 134.8612 - val_mae: 8.6046\n",
      "Epoch 34/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 464.5632 - mae: 16.7004 - val_loss: 179.7674 - val_mae: 10.5373\n",
      "Epoch 35/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 474.1991 - mae: 16.6676 - val_loss: 144.0928 - val_mae: 8.9778\n",
      "Epoch 36/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 417.0252 - mae: 16.0329 - val_loss: 164.2869 - val_mae: 9.6802\n",
      "Epoch 37/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 469.9141 - mae: 16.8996 - val_loss: 136.0935 - val_mae: 8.6576\n",
      "Epoch 38/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 442.5217 - mae: 16.2502 - val_loss: 159.2411 - val_mae: 9.6325\n",
      "Epoch 39/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 446.5647 - mae: 16.5864 - val_loss: 151.3610 - val_mae: 9.3668\n",
      "Epoch 40/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459.1931 - mae: 16.8614 - val_loss: 163.5373 - val_mae: 9.7729\n",
      "Epoch 41/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 443.4066 - mae: 16.4516 - val_loss: 139.5856 - val_mae: 8.7467\n",
      "Epoch 42/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 472.1110 - mae: 16.8407 - val_loss: 141.7706 - val_mae: 8.8478\n",
      "Epoch 43/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 446.1970 - mae: 16.2445 - val_loss: 148.1345 - val_mae: 9.1158\n",
      "Epoch 44/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 436.8633 - mae: 16.2183 - val_loss: 143.7144 - val_mae: 8.9873\n",
      "Epoch 45/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.6343 - mae: 16.7776 - val_loss: 181.4806 - val_mae: 10.5539\n",
      "Epoch 46/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450.5703 - mae: 16.6204 - val_loss: 138.0635 - val_mae: 8.6742\n",
      "Epoch 47/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 452.3533 - mae: 16.4917 - val_loss: 148.6188 - val_mae: 9.1243\n",
      "Epoch 48/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 450.5308 - mae: 16.4232 - val_loss: 134.8748 - val_mae: 8.5712\n",
      "Epoch 49/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 468.4124 - mae: 16.8142 - val_loss: 135.9461 - val_mae: 8.4590\n",
      "Epoch 50/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 410.0880 - mae: 15.7255 - val_loss: 161.1986 - val_mae: 9.8638\n",
      "Epoch 51/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 466.4716 - mae: 16.9033 - val_loss: 211.0051 - val_mae: 11.6364\n",
      "Epoch 52/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 439.6172 - mae: 16.1846 - val_loss: 218.0132 - val_mae: 11.6481\n",
      "Epoch 53/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 436.1795 - mae: 16.2258 - val_loss: 140.0247 - val_mae: 8.7722\n",
      "Epoch 54/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434.1779 - mae: 16.2220 - val_loss: 156.1861 - val_mae: 9.3396\n",
      "Epoch 55/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 423.1512 - mae: 15.9083 - val_loss: 134.5745 - val_mae: 8.5595\n",
      "Epoch 56/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 430.3154 - mae: 15.9838 - val_loss: 131.4623 - val_mae: 8.4784\n",
      "Epoch 57/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 453.6685 - mae: 16.4710 - val_loss: 128.7321 - val_mae: 8.3941\n",
      "Epoch 58/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.8644 - mae: 15.9893 - val_loss: 151.6088 - val_mae: 9.1158\n",
      "Epoch 59/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 410.7896 - mae: 15.6141 - val_loss: 142.4995 - val_mae: 8.9588\n",
      "Epoch 60/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 445.4103 - mae: 16.2114 - val_loss: 136.0871 - val_mae: 8.6303\n",
      "Epoch 61/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 416.1898 - mae: 15.8495 - val_loss: 127.5356 - val_mae: 8.2218\n",
      "Epoch 62/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 429.3178 - mae: 16.1398 - val_loss: 128.8340 - val_mae: 8.2585\n",
      "Epoch 63/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 424.3250 - mae: 16.0547 - val_loss: 145.1235 - val_mae: 9.1479\n",
      "Epoch 64/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.5635 - mae: 16.3414 - val_loss: 127.6261 - val_mae: 8.2127\n",
      "Epoch 65/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 414.5354 - mae: 15.8482 - val_loss: 138.3277 - val_mae: 8.6642\n",
      "Epoch 66/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 434.1604 - mae: 16.2958 - val_loss: 134.9268 - val_mae: 8.5451\n",
      "Epoch 67/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 428.7602 - mae: 16.1361 - val_loss: 128.9251 - val_mae: 8.4016\n",
      "Epoch 68/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 426.4989 - mae: 16.1727 - val_loss: 155.6139 - val_mae: 9.6504\n",
      "Epoch 69/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 417.7359 - mae: 15.7528 - val_loss: 138.4010 - val_mae: 8.7185\n",
      "Epoch 70/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 430.7330 - mae: 15.9802 - val_loss: 141.0663 - val_mae: 8.9452\n",
      "Epoch 71/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 405.1386 - mae: 15.4951 - val_loss: 133.4330 - val_mae: 8.6010\n",
      "Epoch 72/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 420.5604 - mae: 15.6646 - val_loss: 146.9232 - val_mae: 9.0724\n",
      "Epoch 73/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 418.2838 - mae: 15.8151 - val_loss: 137.1144 - val_mae: 8.8205\n",
      "Epoch 74/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410.5893 - mae: 15.8081 - val_loss: 141.7283 - val_mae: 8.8272\n",
      "Epoch 75/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 427.8412 - mae: 16.0309 - val_loss: 136.3516 - val_mae: 8.5465\n",
      "Epoch 76/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 410.3970 - mae: 15.7432 - val_loss: 130.3438 - val_mae: 8.4671\n",
      "Epoch 77/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 402.7624 - mae: 15.5359 - val_loss: 130.6267 - val_mae: 8.3882\n",
      "Epoch 78/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 389.1145 - mae: 15.3873 - val_loss: 134.9497 - val_mae: 8.5724\n",
      "Epoch 79/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 409.3500 - mae: 15.6452 - val_loss: 138.8662 - val_mae: 8.8662\n",
      "Epoch 80/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.7286 - mae: 15.4315 - val_loss: 129.6614 - val_mae: 8.4293\n",
      "Epoch 81/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 394.1704 - mae: 15.5606 - val_loss: 134.0032 - val_mae: 8.5560\n",
      "Epoch 82/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.3971 - mae: 15.7607 - val_loss: 148.2672 - val_mae: 9.0823\n",
      "Epoch 83/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.0879 - mae: 15.3342 - val_loss: 145.8680 - val_mae: 8.9860\n",
      "Epoch 84/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 423.7622 - mae: 15.7453 - val_loss: 133.6152 - val_mae: 8.6093\n",
      "Epoch 85/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 412.0956 - mae: 15.6031 - val_loss: 130.4369 - val_mae: 8.4866\n",
      "Epoch 86/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.7018 - mae: 15.7996 - val_loss: 159.6569 - val_mae: 9.8547\n",
      "Epoch 87/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 390.3359 - mae: 15.2223 - val_loss: 180.9621 - val_mae: 10.7087\n",
      "Epoch 88/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 415.8492 - mae: 15.7111 - val_loss: 185.2417 - val_mae: 10.5916\n",
      "Epoch 89/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 420.8855 - mae: 15.8145 - val_loss: 168.9441 - val_mae: 10.0245\n",
      "Epoch 90/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 409.9183 - mae: 15.7979 - val_loss: 126.7734 - val_mae: 8.3291\n",
      "Epoch 91/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 402.5594 - mae: 15.6624 - val_loss: 145.1259 - val_mae: 9.2140\n",
      "Epoch 92/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 428.4008 - mae: 15.7999 - val_loss: 125.9094 - val_mae: 8.2486\n",
      "Epoch 93/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 415.3684 - mae: 15.9036 - val_loss: 133.0225 - val_mae: 8.5474\n",
      "Epoch 94/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 397.6920 - mae: 15.4626 - val_loss: 125.8234 - val_mae: 8.0862\n",
      "Epoch 95/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 390.6071 - mae: 15.4066 - val_loss: 151.1157 - val_mae: 9.1996\n",
      "Epoch 96/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 409.6493 - mae: 15.6886 - val_loss: 127.3361 - val_mae: 8.3756\n",
      "Epoch 97/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 399.0687 - mae: 15.4432 - val_loss: 153.9456 - val_mae: 9.2606\n",
      "Epoch 98/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 411.2937 - mae: 15.5516 - val_loss: 174.3591 - val_mae: 10.3340\n",
      "Epoch 99/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 395.0641 - mae: 15.3329 - val_loss: 125.7940 - val_mae: 8.1885\n",
      "Epoch 100/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 400.4096 - mae: 15.4037 - val_loss: 138.6558 - val_mae: 8.7306\n",
      "Epoch 101/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 391.2869 - mae: 15.3412 - val_loss: 157.1072 - val_mae: 9.5638\n",
      "Epoch 102/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 393.3071 - mae: 15.2935 - val_loss: 132.1823 - val_mae: 8.3422\n",
      "Epoch 103/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 407.4430 - mae: 15.6098 - val_loss: 130.6640 - val_mae: 8.3795\n",
      "Epoch 104/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 404.6925 - mae: 15.5537 - val_loss: 132.2017 - val_mae: 8.4160\n",
      "Epoch 105/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 402.7303 - mae: 15.4972 - val_loss: 123.3293 - val_mae: 8.1679\n",
      "Epoch 106/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385.8771 - mae: 15.1642 - val_loss: 123.9542 - val_mae: 8.0948\n",
      "Epoch 107/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.8133 - mae: 15.0654 - val_loss: 156.4637 - val_mae: 9.4588\n",
      "Epoch 108/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 365.6046 - mae: 14.6863 - val_loss: 123.0096 - val_mae: 8.0717\n",
      "Epoch 109/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 404.1360 - mae: 15.4819 - val_loss: 124.2502 - val_mae: 8.1981\n",
      "Epoch 110/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.0876 - mae: 15.2789 - val_loss: 130.6026 - val_mae: 8.3157\n",
      "Epoch 111/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 398.7978 - mae: 15.5781 - val_loss: 135.7202 - val_mae: 8.5031\n",
      "Epoch 112/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 383.4156 - mae: 15.1885 - val_loss: 140.9646 - val_mae: 8.8346\n",
      "Epoch 113/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.1257 - mae: 14.8870 - val_loss: 123.4502 - val_mae: 8.0726\n",
      "Epoch 114/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.5122 - mae: 15.2326 - val_loss: 125.8081 - val_mae: 8.2276\n",
      "Epoch 115/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387.9836 - mae: 15.2933 - val_loss: 130.1168 - val_mae: 8.3556\n",
      "Epoch 116/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 378.8071 - mae: 15.0765 - val_loss: 126.3320 - val_mae: 8.1549\n",
      "Epoch 117/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.6802 - mae: 15.3034 - val_loss: 122.5318 - val_mae: 8.0966\n",
      "Epoch 118/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.2130 - mae: 15.0285 - val_loss: 130.8547 - val_mae: 8.4280\n",
      "Epoch 119/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 351.1941 - mae: 14.4770 - val_loss: 122.2263 - val_mae: 8.0266\n",
      "Epoch 120/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 359.6518 - mae: 14.6478 - val_loss: 121.2742 - val_mae: 8.0510\n",
      "Epoch 121/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 392.0074 - mae: 15.4114 - val_loss: 121.3321 - val_mae: 7.9977\n",
      "Epoch 122/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.0152 - mae: 14.7819 - val_loss: 134.3126 - val_mae: 8.5488\n",
      "Epoch 123/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 383.2614 - mae: 14.9996 - val_loss: 131.2574 - val_mae: 8.4627\n",
      "Epoch 124/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 385.7127 - mae: 15.0450 - val_loss: 129.8471 - val_mae: 8.5244\n",
      "Epoch 125/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.2870 - mae: 14.9630 - val_loss: 149.6671 - val_mae: 9.0831\n",
      "Epoch 126/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 392.5755 - mae: 15.3708 - val_loss: 125.5593 - val_mae: 8.2641\n",
      "Epoch 127/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 357.1184 - mae: 14.6597 - val_loss: 131.9347 - val_mae: 8.5210\n",
      "Epoch 128/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.9030 - mae: 14.8409 - val_loss: 145.9297 - val_mae: 9.0585\n",
      "Epoch 129/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.2904 - mae: 14.7154 - val_loss: 132.2258 - val_mae: 8.4388\n",
      "Epoch 130/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.3585 - mae: 15.1259 - val_loss: 128.0254 - val_mae: 8.1804\n",
      "Epoch 131/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 358.4636 - mae: 14.6483 - val_loss: 129.1672 - val_mae: 8.3638\n",
      "Epoch 132/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.7812 - mae: 15.2329 - val_loss: 123.4006 - val_mae: 8.0274\n",
      "Epoch 133/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.7046 - mae: 15.0769 - val_loss: 138.5312 - val_mae: 8.8013\n",
      "Epoch 134/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 357.4679 - mae: 14.6293 - val_loss: 135.9012 - val_mae: 8.5208\n",
      "Epoch 135/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.3853 - mae: 14.5076 - val_loss: 123.8761 - val_mae: 8.0563\n",
      "Epoch 136/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361.1385 - mae: 14.7321 - val_loss: 121.3671 - val_mae: 8.1152\n",
      "Epoch 137/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.7673 - mae: 14.8933 - val_loss: 123.0576 - val_mae: 8.1490\n",
      "Epoch 138/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.8049 - mae: 14.8876 - val_loss: 139.6159 - val_mae: 8.7765\n",
      "Epoch 139/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361.8176 - mae: 14.7105 - val_loss: 140.0916 - val_mae: 8.8286\n",
      "Epoch 140/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.9935 - mae: 14.9986 - val_loss: 131.0080 - val_mae: 8.5120\n",
      "Epoch 141/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.0311 - mae: 14.7071 - val_loss: 123.9528 - val_mae: 8.0754\n",
      "Epoch 142/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.1142 - mae: 14.8062 - val_loss: 119.9662 - val_mae: 7.9446\n",
      "Epoch 143/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.0751 - mae: 15.0050 - val_loss: 122.0495 - val_mae: 8.0561\n",
      "Epoch 144/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 355.9967 - mae: 14.5907 - val_loss: 124.2624 - val_mae: 8.2050\n",
      "Epoch 145/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 359.3748 - mae: 14.5617 - val_loss: 131.1226 - val_mae: 8.6027\n",
      "Epoch 146/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 378.5377 - mae: 15.0145 - val_loss: 120.4818 - val_mae: 7.9895\n",
      "Epoch 147/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.3991 - mae: 14.8482 - val_loss: 123.1459 - val_mae: 8.1831\n",
      "Epoch 148/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 354.6794 - mae: 14.4016 - val_loss: 124.4427 - val_mae: 8.0842\n",
      "Epoch 149/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361.5694 - mae: 14.8109 - val_loss: 143.9040 - val_mae: 8.9015\n",
      "Epoch 150/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 359.0217 - mae: 14.7477 - val_loss: 121.7298 - val_mae: 8.0187\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 133.8536 - mae: 8.0257\n",
      "Patience 40: Validation MAE: 7.94\n",
      "Patience 40: Validation Loss: 119.97\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1996.4650 - mae: 31.8157 - val_loss: 364.2774 - val_mae: 14.1729\n",
      "Epoch 2/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 741.8480 - mae: 21.3002 - val_loss: 348.9017 - val_mae: 13.9510\n",
      "Epoch 3/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 670.7995 - mae: 20.4676 - val_loss: 282.8304 - val_mae: 12.9814\n",
      "Epoch 4/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 686.8431 - mae: 20.7395 - val_loss: 255.1359 - val_mae: 12.4298\n",
      "Epoch 5/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 622.7385 - mae: 19.5032 - val_loss: 229.6870 - val_mae: 12.0597\n",
      "Epoch 6/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 598.5514 - mae: 19.1937 - val_loss: 211.0381 - val_mae: 11.1211\n",
      "Epoch 7/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 553.7930 - mae: 18.4924 - val_loss: 211.2867 - val_mae: 11.1181\n",
      "Epoch 8/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 538.0899 - mae: 18.0431 - val_loss: 204.9325 - val_mae: 11.1351\n",
      "Epoch 9/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 552.2841 - mae: 18.3300 - val_loss: 180.1221 - val_mae: 10.2909\n",
      "Epoch 10/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 495.1545 - mae: 17.3197 - val_loss: 184.2512 - val_mae: 10.6072\n",
      "Epoch 11/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 511.0404 - mae: 17.7635 - val_loss: 167.1700 - val_mae: 9.7490\n",
      "Epoch 12/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 483.9828 - mae: 17.2533 - val_loss: 170.8500 - val_mae: 9.8196\n",
      "Epoch 13/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 471.3288 - mae: 16.9238 - val_loss: 222.3209 - val_mae: 11.9857\n",
      "Epoch 14/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 471.8712 - mae: 17.0698 - val_loss: 169.5858 - val_mae: 10.0037\n",
      "Epoch 15/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 462.5469 - mae: 16.6492 - val_loss: 167.6837 - val_mae: 9.8671\n",
      "Epoch 16/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 466.8847 - mae: 16.8725 - val_loss: 153.1922 - val_mae: 9.2581\n",
      "Epoch 17/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.1953 - mae: 16.8525 - val_loss: 162.1389 - val_mae: 9.4282\n",
      "Epoch 18/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 510.2518 - mae: 17.4406 - val_loss: 210.6100 - val_mae: 11.6721\n",
      "Epoch 19/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 478.8303 - mae: 17.1119 - val_loss: 159.3143 - val_mae: 9.4254\n",
      "Epoch 20/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441.4097 - mae: 16.5456 - val_loss: 163.9090 - val_mae: 9.5953\n",
      "Epoch 21/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 491.4584 - mae: 17.0388 - val_loss: 155.6242 - val_mae: 9.3158\n",
      "Epoch 22/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434.2693 - mae: 16.3102 - val_loss: 149.5117 - val_mae: 9.0378\n",
      "Epoch 23/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 445.6398 - mae: 16.4893 - val_loss: 169.7596 - val_mae: 10.0065\n",
      "Epoch 24/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 480.8787 - mae: 17.1025 - val_loss: 161.6308 - val_mae: 9.7293\n",
      "Epoch 25/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 475.6708 - mae: 16.8666 - val_loss: 146.4991 - val_mae: 8.9598\n",
      "Epoch 26/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 449.2683 - mae: 16.4870 - val_loss: 164.6984 - val_mae: 9.8778\n",
      "Epoch 27/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 483.9217 - mae: 16.9738 - val_loss: 198.9403 - val_mae: 11.0674\n",
      "Epoch 28/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 460.3862 - mae: 16.7403 - val_loss: 151.1450 - val_mae: 9.2129\n",
      "Epoch 29/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.5246 - mae: 16.3900 - val_loss: 165.9258 - val_mae: 9.9627\n",
      "Epoch 30/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 443.1651 - mae: 16.5210 - val_loss: 144.9785 - val_mae: 8.7482\n",
      "Epoch 31/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.5904 - mae: 16.2806 - val_loss: 148.6108 - val_mae: 9.0505\n",
      "Epoch 32/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.7606 - mae: 16.5032 - val_loss: 150.4554 - val_mae: 9.1553\n",
      "Epoch 33/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 451.2690 - mae: 16.5496 - val_loss: 143.7680 - val_mae: 8.8135\n",
      "Epoch 34/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 404.8044 - mae: 15.8000 - val_loss: 145.1326 - val_mae: 8.9466\n",
      "Epoch 35/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 439.7686 - mae: 16.2585 - val_loss: 153.5143 - val_mae: 8.9966\n",
      "Epoch 36/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 462.7183 - mae: 16.6629 - val_loss: 185.6002 - val_mae: 10.6942\n",
      "Epoch 37/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 423.5651 - mae: 16.1512 - val_loss: 145.4224 - val_mae: 9.0606\n",
      "Epoch 38/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 420.0828 - mae: 16.0688 - val_loss: 143.4129 - val_mae: 8.6361\n",
      "Epoch 39/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 447.7666 - mae: 16.2521 - val_loss: 165.4293 - val_mae: 9.7750\n",
      "Epoch 40/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 449.6407 - mae: 16.1962 - val_loss: 183.7041 - val_mae: 10.6846\n",
      "Epoch 41/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 427.2451 - mae: 16.2154 - val_loss: 220.5962 - val_mae: 11.6398\n",
      "Epoch 42/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.7397 - mae: 16.3626 - val_loss: 154.7800 - val_mae: 9.3932\n",
      "Epoch 43/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441.5829 - mae: 16.3448 - val_loss: 138.5831 - val_mae: 8.6308\n",
      "Epoch 44/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433.2896 - mae: 16.2925 - val_loss: 154.4519 - val_mae: 9.1630\n",
      "Epoch 45/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.9956 - mae: 16.1534 - val_loss: 155.5959 - val_mae: 9.4634\n",
      "Epoch 46/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.9749 - mae: 15.9004 - val_loss: 147.0970 - val_mae: 8.9998\n",
      "Epoch 47/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 446.2421 - mae: 16.5029 - val_loss: 140.9241 - val_mae: 8.7562\n",
      "Epoch 48/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 439.0747 - mae: 16.2935 - val_loss: 160.3433 - val_mae: 9.4483\n",
      "Epoch 49/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.9080 - mae: 16.1428 - val_loss: 205.0970 - val_mae: 11.3471\n",
      "Epoch 50/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 418.0785 - mae: 15.8265 - val_loss: 140.5587 - val_mae: 8.8354\n",
      "Epoch 51/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.3073 - mae: 15.6375 - val_loss: 142.1321 - val_mae: 8.7969\n",
      "Epoch 52/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 412.2514 - mae: 15.9352 - val_loss: 140.6045 - val_mae: 8.7405\n",
      "Epoch 53/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394.6971 - mae: 15.3935 - val_loss: 142.5577 - val_mae: 8.8025\n",
      "Epoch 54/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.4926 - mae: 15.6924 - val_loss: 138.1674 - val_mae: 8.6998\n",
      "Epoch 55/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 400.6936 - mae: 15.3658 - val_loss: 142.4783 - val_mae: 8.6100\n",
      "Epoch 56/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.6298 - mae: 15.3965 - val_loss: 186.9052 - val_mae: 10.7078\n",
      "Epoch 57/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.0885 - mae: 15.7520 - val_loss: 137.0615 - val_mae: 8.5270\n",
      "Epoch 58/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.3547 - mae: 15.6543 - val_loss: 138.8598 - val_mae: 8.6181\n",
      "Epoch 59/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 384.7444 - mae: 15.2213 - val_loss: 140.7487 - val_mae: 8.5976\n",
      "Epoch 60/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394.7928 - mae: 15.5071 - val_loss: 136.8352 - val_mae: 8.5390\n",
      "Epoch 61/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.4984 - mae: 15.7179 - val_loss: 139.2780 - val_mae: 8.7134\n",
      "Epoch 62/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 415.5698 - mae: 15.6587 - val_loss: 145.8724 - val_mae: 9.0589\n",
      "Epoch 63/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 404.1801 - mae: 15.7159 - val_loss: 135.8533 - val_mae: 8.4895\n",
      "Epoch 64/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 400.9888 - mae: 15.3489 - val_loss: 133.4383 - val_mae: 8.4978\n",
      "Epoch 65/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.7899 - mae: 15.4334 - val_loss: 153.5031 - val_mae: 9.4383\n",
      "Epoch 66/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.4636 - mae: 15.9042 - val_loss: 169.0551 - val_mae: 9.7114\n",
      "Epoch 67/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.6137 - mae: 15.6759 - val_loss: 142.8823 - val_mae: 8.8636\n",
      "Epoch 68/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 415.3421 - mae: 15.7553 - val_loss: 134.7867 - val_mae: 8.5275\n",
      "Epoch 69/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 411.6523 - mae: 15.5659 - val_loss: 143.9956 - val_mae: 9.0497\n",
      "Epoch 70/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 398.7927 - mae: 15.4819 - val_loss: 137.9100 - val_mae: 8.7562\n",
      "Epoch 71/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 408.8570 - mae: 15.4907 - val_loss: 153.9894 - val_mae: 9.4352\n",
      "Epoch 72/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.9528 - mae: 15.5128 - val_loss: 133.9743 - val_mae: 8.4232\n",
      "Epoch 73/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 398.3064 - mae: 15.4013 - val_loss: 134.5019 - val_mae: 8.5624\n",
      "Epoch 74/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.0814 - mae: 15.0554 - val_loss: 163.5895 - val_mae: 9.9606\n",
      "Epoch 75/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391.4771 - mae: 15.3551 - val_loss: 133.6362 - val_mae: 8.5033\n",
      "Epoch 76/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 383.5811 - mae: 15.1630 - val_loss: 136.6005 - val_mae: 8.7292\n",
      "Epoch 77/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 411.5862 - mae: 15.7230 - val_loss: 155.6789 - val_mae: 9.4894\n",
      "Epoch 78/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 374.8535 - mae: 14.9431 - val_loss: 185.5152 - val_mae: 10.7209\n",
      "Epoch 79/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.1108 - mae: 15.3647 - val_loss: 143.1608 - val_mae: 8.7591\n",
      "Epoch 80/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.8961 - mae: 15.1961 - val_loss: 149.7685 - val_mae: 9.2804\n",
      "Epoch 81/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.7213 - mae: 15.4826 - val_loss: 135.3582 - val_mae: 8.6268\n",
      "Epoch 82/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 385.7344 - mae: 15.1197 - val_loss: 162.5425 - val_mae: 9.7735\n",
      "Epoch 83/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.7831 - mae: 15.3012 - val_loss: 163.2262 - val_mae: 9.9238\n",
      "Epoch 84/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.1199 - mae: 14.9374 - val_loss: 129.8304 - val_mae: 8.3410\n",
      "Epoch 85/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385.4323 - mae: 15.2477 - val_loss: 139.9495 - val_mae: 8.8282\n",
      "Epoch 86/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.3850 - mae: 14.9746 - val_loss: 141.2397 - val_mae: 8.7903\n",
      "Epoch 87/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.9091 - mae: 15.3347 - val_loss: 136.9135 - val_mae: 8.6711\n",
      "Epoch 88/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.0797 - mae: 15.0606 - val_loss: 130.4619 - val_mae: 8.3068\n",
      "Epoch 89/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.0767 - mae: 15.4544 - val_loss: 160.1160 - val_mae: 9.7341\n",
      "Epoch 90/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.5501 - mae: 15.1316 - val_loss: 145.3667 - val_mae: 9.1060\n",
      "Epoch 91/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.7359 - mae: 14.9202 - val_loss: 143.5642 - val_mae: 9.0641\n",
      "Epoch 92/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.7056 - mae: 14.9821 - val_loss: 129.8873 - val_mae: 8.3316\n",
      "Epoch 93/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386.5454 - mae: 15.0528 - val_loss: 165.7663 - val_mae: 10.1097\n",
      "Epoch 94/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 396.1375 - mae: 15.3499 - val_loss: 129.2158 - val_mae: 8.3841\n",
      "Epoch 95/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385.2774 - mae: 15.1958 - val_loss: 132.7692 - val_mae: 8.5857\n",
      "Epoch 96/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 383.4687 - mae: 15.0491 - val_loss: 146.4503 - val_mae: 9.0334\n",
      "Epoch 97/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361.8060 - mae: 14.7841 - val_loss: 172.8449 - val_mae: 10.2647\n",
      "Epoch 98/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 360.9770 - mae: 14.8587 - val_loss: 136.3207 - val_mae: 8.5987\n",
      "Epoch 99/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389.1835 - mae: 15.2715 - val_loss: 130.3409 - val_mae: 8.4608\n",
      "Epoch 100/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.0482 - mae: 15.0610 - val_loss: 141.1846 - val_mae: 8.8994\n",
      "Epoch 101/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.0763 - mae: 14.9697 - val_loss: 178.9805 - val_mae: 10.2732\n",
      "Epoch 102/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.5644 - mae: 14.8737 - val_loss: 168.3774 - val_mae: 10.0938\n",
      "Epoch 103/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 370.8089 - mae: 15.0940 - val_loss: 136.5124 - val_mae: 8.6987\n",
      "Epoch 104/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.6281 - mae: 15.0378 - val_loss: 135.0365 - val_mae: 8.4565\n",
      "Epoch 105/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.5756 - mae: 14.9260 - val_loss: 149.1531 - val_mae: 9.3594\n",
      "Epoch 106/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 398.2092 - mae: 15.2904 - val_loss: 133.4029 - val_mae: 8.4704\n",
      "Epoch 107/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 389.7914 - mae: 15.2691 - val_loss: 141.6656 - val_mae: 9.0548\n",
      "Epoch 108/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.3265 - mae: 14.8727 - val_loss: 125.5932 - val_mae: 8.2180\n",
      "Epoch 109/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 378.8171 - mae: 14.9168 - val_loss: 126.2410 - val_mae: 8.2989\n",
      "Epoch 110/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.5085 - mae: 14.9330 - val_loss: 126.0994 - val_mae: 8.2299\n",
      "Epoch 111/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.7712 - mae: 14.8987 - val_loss: 127.0912 - val_mae: 8.2931\n",
      "Epoch 112/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.6872 - mae: 15.0587 - val_loss: 124.6704 - val_mae: 8.1607\n",
      "Epoch 113/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.2444 - mae: 14.9280 - val_loss: 129.8116 - val_mae: 8.3638\n",
      "Epoch 114/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 363.1486 - mae: 14.6551 - val_loss: 130.0674 - val_mae: 8.2529\n",
      "Epoch 115/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 372.5013 - mae: 14.7022 - val_loss: 130.2823 - val_mae: 8.5310\n",
      "Epoch 116/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.0461 - mae: 14.8494 - val_loss: 130.4818 - val_mae: 8.4731\n",
      "Epoch 117/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 392.8365 - mae: 14.9523 - val_loss: 138.1903 - val_mae: 8.9135\n",
      "Epoch 118/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.4125 - mae: 14.9566 - val_loss: 151.8731 - val_mae: 9.5491\n",
      "Epoch 119/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.9166 - mae: 14.8717 - val_loss: 141.6804 - val_mae: 9.0715\n",
      "Epoch 120/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.2376 - mae: 14.8667 - val_loss: 124.2125 - val_mae: 8.1570\n",
      "Epoch 121/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.1719 - mae: 14.8740 - val_loss: 123.2426 - val_mae: 8.1962\n",
      "Epoch 122/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.9641 - mae: 15.0488 - val_loss: 126.1786 - val_mae: 8.1510\n",
      "Epoch 123/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.6888 - mae: 14.7675 - val_loss: 121.7110 - val_mae: 8.0564\n",
      "Epoch 124/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 370.5422 - mae: 14.9878 - val_loss: 125.0903 - val_mae: 8.2333\n",
      "Epoch 125/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 348.7212 - mae: 14.5345 - val_loss: 155.0273 - val_mae: 9.7205\n",
      "Epoch 126/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.2230 - mae: 14.8989 - val_loss: 122.6488 - val_mae: 8.1654\n",
      "Epoch 127/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 357.4607 - mae: 14.6921 - val_loss: 131.9281 - val_mae: 8.5625\n",
      "Epoch 128/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.8641 - mae: 14.7976 - val_loss: 129.3937 - val_mae: 8.4947\n",
      "Epoch 129/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 374.7671 - mae: 14.8421 - val_loss: 129.0147 - val_mae: 8.2977\n",
      "Epoch 130/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.3342 - mae: 15.0493 - val_loss: 132.5344 - val_mae: 8.5382\n",
      "Epoch 131/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 358.7796 - mae: 14.8029 - val_loss: 124.3846 - val_mae: 8.2794\n",
      "Epoch 132/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.8911 - mae: 14.7883 - val_loss: 121.0778 - val_mae: 8.0708\n",
      "Epoch 133/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 352.7049 - mae: 14.5493 - val_loss: 123.0990 - val_mae: 8.1006\n",
      "Epoch 134/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.7809 - mae: 14.7375 - val_loss: 127.9690 - val_mae: 8.2961\n",
      "Epoch 135/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.4778 - mae: 14.8999 - val_loss: 121.6659 - val_mae: 8.0479\n",
      "Epoch 136/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.6252 - mae: 15.0241 - val_loss: 123.0686 - val_mae: 8.0659\n",
      "Epoch 137/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 343.3531 - mae: 14.2999 - val_loss: 153.1158 - val_mae: 9.4769\n",
      "Epoch 138/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.6420 - mae: 15.0939 - val_loss: 129.8186 - val_mae: 8.3526\n",
      "Epoch 139/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 358.5370 - mae: 14.5479 - val_loss: 130.5989 - val_mae: 8.5762\n",
      "Epoch 140/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 347.5115 - mae: 14.5256 - val_loss: 126.5273 - val_mae: 8.3473\n",
      "Epoch 141/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 341.1882 - mae: 14.3319 - val_loss: 144.9790 - val_mae: 9.3354\n",
      "Epoch 142/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 359.5317 - mae: 14.7278 - val_loss: 142.0973 - val_mae: 9.0729\n",
      "Epoch 143/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 372.0277 - mae: 15.0206 - val_loss: 132.0905 - val_mae: 8.5927\n",
      "Epoch 144/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 354.4991 - mae: 14.6671 - val_loss: 132.0467 - val_mae: 8.6232\n",
      "Epoch 145/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 345.1621 - mae: 14.5076 - val_loss: 123.7842 - val_mae: 8.1932\n",
      "Epoch 146/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.7442 - mae: 14.4664 - val_loss: 124.3422 - val_mae: 8.1172\n",
      "Epoch 147/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 345.9201 - mae: 14.2813 - val_loss: 120.1098 - val_mae: 7.9087\n",
      "Epoch 148/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.9339 - mae: 14.5720 - val_loss: 126.3717 - val_mae: 8.3154\n",
      "Epoch 149/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.0659 - mae: 14.7987 - val_loss: 120.1545 - val_mae: 8.0201\n",
      "Epoch 150/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 351.1522 - mae: 14.2760 - val_loss: 128.2087 - val_mae: 8.3000\n",
      "Patience 30: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 131.4409 - mae: 7.9000\n",
      "Patience 30: Validation MAE: 7.91\n",
      "Patience 30: Validation Loss: 120.11\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2270.8442 - mae: 34.7161 - val_loss: 298.6106 - val_mae: 13.8206\n",
      "Epoch 2/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 658.2018 - mae: 20.2466 - val_loss: 262.2358 - val_mae: 12.6016\n",
      "Epoch 3/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 616.2172 - mae: 19.5871 - val_loss: 233.5873 - val_mae: 11.9562\n",
      "Epoch 4/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 598.6838 - mae: 19.2509 - val_loss: 244.2139 - val_mae: 11.8372\n",
      "Epoch 5/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 564.4626 - mae: 18.6023 - val_loss: 196.7499 - val_mae: 10.6995\n",
      "Epoch 6/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 516.9261 - mae: 17.8958 - val_loss: 179.5727 - val_mae: 10.2567\n",
      "Epoch 7/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 519.1746 - mae: 17.6901 - val_loss: 176.8366 - val_mae: 10.1207\n",
      "Epoch 8/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 531.0649 - mae: 17.9190 - val_loss: 166.0804 - val_mae: 9.8060\n",
      "Epoch 9/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 525.6837 - mae: 17.8573 - val_loss: 174.4777 - val_mae: 10.1764\n",
      "Epoch 10/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461.2599 - mae: 16.6681 - val_loss: 190.0916 - val_mae: 10.4910\n",
      "Epoch 11/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 500.6597 - mae: 17.6224 - val_loss: 244.7901 - val_mae: 12.6102\n",
      "Epoch 12/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.8857 - mae: 17.2012 - val_loss: 144.5676 - val_mae: 8.9475\n",
      "Epoch 13/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.4892 - mae: 16.8149 - val_loss: 137.6413 - val_mae: 8.7267\n",
      "Epoch 14/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459.7213 - mae: 16.8682 - val_loss: 150.4176 - val_mae: 9.2446\n",
      "Epoch 15/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 480.6469 - mae: 16.9872 - val_loss: 137.4075 - val_mae: 8.6668\n",
      "Epoch 16/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 467.9584 - mae: 16.6738 - val_loss: 155.4335 - val_mae: 9.5091\n",
      "Epoch 17/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 485.4182 - mae: 17.1266 - val_loss: 146.7518 - val_mae: 9.1230\n",
      "Epoch 18/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 455.1380 - mae: 16.5329 - val_loss: 155.0596 - val_mae: 9.2831\n",
      "Epoch 19/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.7691 - mae: 16.7043 - val_loss: 140.6383 - val_mae: 8.8387\n",
      "Epoch 20/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.2647 - mae: 16.6599 - val_loss: 154.0095 - val_mae: 9.1699\n",
      "Epoch 21/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 454.0583 - mae: 16.4331 - val_loss: 164.8178 - val_mae: 9.7631\n",
      "Epoch 22/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 477.7605 - mae: 16.9710 - val_loss: 138.2619 - val_mae: 8.6866\n",
      "Epoch 23/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 457.8719 - mae: 16.6443 - val_loss: 146.0125 - val_mae: 9.0784\n",
      "Epoch 24/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 462.8821 - mae: 16.8648 - val_loss: 152.1880 - val_mae: 8.9956\n",
      "Epoch 25/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 454.5637 - mae: 16.5958 - val_loss: 237.6693 - val_mae: 12.3574\n",
      "Epoch 26/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.3645 - mae: 15.9859 - val_loss: 189.6010 - val_mae: 10.9534\n",
      "Epoch 27/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.7437 - mae: 16.4372 - val_loss: 140.4800 - val_mae: 8.9162\n",
      "Epoch 28/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 465.2165 - mae: 16.8301 - val_loss: 132.7951 - val_mae: 8.4109\n",
      "Epoch 29/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 438.9464 - mae: 16.4512 - val_loss: 139.1000 - val_mae: 8.8957\n",
      "Epoch 30/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.5363 - mae: 16.2937 - val_loss: 184.1791 - val_mae: 10.6122\n",
      "Epoch 31/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.9539 - mae: 16.3606 - val_loss: 160.4355 - val_mae: 9.6892\n",
      "Epoch 32/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 412.3785 - mae: 16.0096 - val_loss: 149.4897 - val_mae: 9.3151\n",
      "Epoch 33/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.4325 - mae: 16.0754 - val_loss: 133.4620 - val_mae: 8.4283\n",
      "Epoch 34/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.8578 - mae: 16.0264 - val_loss: 152.7849 - val_mae: 9.4558\n",
      "Epoch 35/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 446.4721 - mae: 16.5328 - val_loss: 136.2130 - val_mae: 8.5895\n",
      "Epoch 36/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434.2315 - mae: 16.1562 - val_loss: 171.2670 - val_mae: 10.2883\n",
      "Epoch 37/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433.7247 - mae: 16.2051 - val_loss: 128.5647 - val_mae: 8.3220\n",
      "Epoch 38/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 432.4653 - mae: 16.3029 - val_loss: 217.3076 - val_mae: 11.9758\n",
      "Epoch 39/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 449.6799 - mae: 16.3119 - val_loss: 158.4609 - val_mae: 9.6672\n",
      "Epoch 40/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.3176 - mae: 16.3952 - val_loss: 151.4353 - val_mae: 9.4021\n",
      "Epoch 41/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 425.5673 - mae: 15.9412 - val_loss: 156.2423 - val_mae: 9.5099\n",
      "Epoch 42/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 424.2550 - mae: 15.8765 - val_loss: 183.8068 - val_mae: 10.6543\n",
      "Epoch 43/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.5289 - mae: 16.0033 - val_loss: 135.7896 - val_mae: 8.4920\n",
      "Epoch 44/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.4281 - mae: 16.1358 - val_loss: 140.4146 - val_mae: 8.8671\n",
      "Epoch 45/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.7181 - mae: 15.8607 - val_loss: 165.7083 - val_mae: 10.0026\n",
      "Epoch 46/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.1889 - mae: 15.8373 - val_loss: 134.8840 - val_mae: 8.5790\n",
      "Epoch 47/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417.5813 - mae: 15.8476 - val_loss: 130.5714 - val_mae: 8.3329\n",
      "Epoch 48/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 415.7281 - mae: 15.8461 - val_loss: 130.8004 - val_mae: 8.4240\n",
      "Epoch 49/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399.5252 - mae: 15.5196 - val_loss: 140.7326 - val_mae: 8.8819\n",
      "Epoch 50/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409.5982 - mae: 15.6139 - val_loss: 132.6913 - val_mae: 8.6288\n",
      "Epoch 51/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.8448 - mae: 15.3601 - val_loss: 137.7533 - val_mae: 8.6151\n",
      "Epoch 52/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.7593 - mae: 15.8578 - val_loss: 130.2432 - val_mae: 8.4131\n",
      "Epoch 53/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.0414 - mae: 15.5116 - val_loss: 132.2447 - val_mae: 8.5156\n",
      "Epoch 54/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417.7620 - mae: 15.7682 - val_loss: 135.7978 - val_mae: 8.6288\n",
      "Epoch 55/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 453.6038 - mae: 16.1327 - val_loss: 140.2664 - val_mae: 8.6918\n",
      "Epoch 56/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.1016 - mae: 15.7679 - val_loss: 137.5568 - val_mae: 8.8262\n",
      "Epoch 57/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 400.9435 - mae: 15.6386 - val_loss: 159.2128 - val_mae: 9.6632\n",
      "Patience 20: Early stopping occurred at epoch 56\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 139.9923 - mae: 8.3301\n",
      "Patience 20: Validation MAE: 8.32\n",
      "Patience 20: Validation Loss: 128.56\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2280.3835 - mae: 33.4816 - val_loss: 336.9590 - val_mae: 13.7855\n",
      "Epoch 2/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 683.5784 - mae: 20.2338 - val_loss: 272.1127 - val_mae: 12.9538\n",
      "Epoch 3/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 627.8474 - mae: 19.6726 - val_loss: 338.1950 - val_mae: 13.9464\n",
      "Epoch 4/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 566.0322 - mae: 18.8622 - val_loss: 301.5197 - val_mae: 13.3926\n",
      "Epoch 5/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 573.9847 - mae: 18.8727 - val_loss: 206.1529 - val_mae: 10.9290\n",
      "Epoch 6/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 562.8149 - mae: 18.5175 - val_loss: 228.1093 - val_mae: 11.6998\n",
      "Epoch 7/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 529.4969 - mae: 17.7318 - val_loss: 234.9743 - val_mae: 12.0207\n",
      "Epoch 8/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 514.7563 - mae: 17.7181 - val_loss: 168.4517 - val_mae: 9.8892\n",
      "Epoch 9/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 525.8379 - mae: 17.7489 - val_loss: 220.3076 - val_mae: 11.3043\n",
      "Epoch 10/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 525.9796 - mae: 17.8087 - val_loss: 157.7225 - val_mae: 9.4055\n",
      "Epoch 11/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 492.7613 - mae: 17.2875 - val_loss: 171.5448 - val_mae: 9.7734\n",
      "Epoch 12/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 480.5256 - mae: 17.0743 - val_loss: 219.7228 - val_mae: 11.6911\n",
      "Epoch 13/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 485.4460 - mae: 17.2075 - val_loss: 175.4299 - val_mae: 9.9068\n",
      "Epoch 14/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 493.9156 - mae: 17.3085 - val_loss: 166.7387 - val_mae: 9.9232\n",
      "Epoch 15/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 464.6982 - mae: 16.9784 - val_loss: 158.6815 - val_mae: 9.5913\n",
      "Epoch 16/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.8587 - mae: 16.8335 - val_loss: 150.1558 - val_mae: 9.0798\n",
      "Epoch 17/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 452.9427 - mae: 16.5694 - val_loss: 155.1140 - val_mae: 9.3459\n",
      "Epoch 18/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 456.7061 - mae: 16.7946 - val_loss: 225.7189 - val_mae: 11.8360\n",
      "Epoch 19/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 486.2686 - mae: 17.1884 - val_loss: 192.6089 - val_mae: 11.0097\n",
      "Epoch 20/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 453.9243 - mae: 16.6893 - val_loss: 141.4142 - val_mae: 8.7531\n",
      "Epoch 21/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 464.1644 - mae: 16.8149 - val_loss: 163.0621 - val_mae: 9.6459\n",
      "Epoch 22/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 466.4234 - mae: 16.8482 - val_loss: 176.0543 - val_mae: 10.3832\n",
      "Epoch 23/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.6603 - mae: 16.7456 - val_loss: 157.0470 - val_mae: 9.5460\n",
      "Epoch 24/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 464.7783 - mae: 16.7074 - val_loss: 164.8071 - val_mae: 9.7587\n",
      "Epoch 25/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 451.6913 - mae: 16.4696 - val_loss: 156.5654 - val_mae: 9.4865\n",
      "Epoch 26/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417.1108 - mae: 15.9565 - val_loss: 151.1778 - val_mae: 9.0374\n",
      "Epoch 27/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 455.6371 - mae: 16.4594 - val_loss: 160.1681 - val_mae: 9.6874\n",
      "Epoch 28/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 473.1271 - mae: 16.8554 - val_loss: 142.8457 - val_mae: 8.7422\n",
      "Epoch 29/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 482.8169 - mae: 16.9646 - val_loss: 138.9121 - val_mae: 8.7065\n",
      "Epoch 30/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 435.0237 - mae: 16.2558 - val_loss: 141.2374 - val_mae: 8.6818\n",
      "Epoch 31/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 453.1456 - mae: 16.3525 - val_loss: 202.9530 - val_mae: 11.0796\n",
      "Epoch 32/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 454.8581 - mae: 16.3716 - val_loss: 140.9467 - val_mae: 8.8475\n",
      "Epoch 33/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 415.9148 - mae: 15.9821 - val_loss: 185.0800 - val_mae: 10.5558\n",
      "Epoch 34/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.2820 - mae: 16.2142 - val_loss: 144.4292 - val_mae: 9.0824\n",
      "Epoch 35/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.8194 - mae: 16.0793 - val_loss: 160.9209 - val_mae: 9.6194\n",
      "Epoch 36/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 446.3146 - mae: 16.3244 - val_loss: 144.9823 - val_mae: 9.0403\n",
      "Epoch 37/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 448.5977 - mae: 16.3118 - val_loss: 136.1290 - val_mae: 8.7339\n",
      "Epoch 38/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 432.6281 - mae: 16.0256 - val_loss: 162.9441 - val_mae: 9.7566\n",
      "Epoch 39/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 446.0005 - mae: 16.3336 - val_loss: 156.1118 - val_mae: 9.4989\n",
      "Epoch 40/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434.4507 - mae: 16.0240 - val_loss: 150.0375 - val_mae: 9.3069\n",
      "Epoch 41/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436.7936 - mae: 16.2875 - val_loss: 165.2020 - val_mae: 9.9254\n",
      "Epoch 42/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 440.0821 - mae: 16.2763 - val_loss: 139.0812 - val_mae: 8.5459\n",
      "Epoch 43/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441.3140 - mae: 16.2571 - val_loss: 138.4659 - val_mae: 8.7464\n",
      "Epoch 44/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 437.2639 - mae: 16.0831 - val_loss: 164.1970 - val_mae: 9.9242\n",
      "Epoch 45/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.3461 - mae: 15.9593 - val_loss: 179.8908 - val_mae: 10.2796\n",
      "Epoch 46/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 435.0692 - mae: 16.2441 - val_loss: 134.3821 - val_mae: 8.5894\n",
      "Epoch 47/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.3208 - mae: 16.1778 - val_loss: 131.9538 - val_mae: 8.3988\n",
      "Epoch 48/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 447.7642 - mae: 16.5138 - val_loss: 144.0142 - val_mae: 9.0431\n",
      "Epoch 49/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.2531 - mae: 15.7962 - val_loss: 156.0059 - val_mae: 9.4961\n",
      "Epoch 50/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.4049 - mae: 16.0416 - val_loss: 142.6609 - val_mae: 8.7983\n",
      "Epoch 51/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 439.4568 - mae: 16.2471 - val_loss: 158.7356 - val_mae: 9.7689\n",
      "Epoch 52/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.1747 - mae: 15.8984 - val_loss: 143.6037 - val_mae: 8.9634\n",
      "Epoch 53/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 414.9671 - mae: 15.8208 - val_loss: 137.1130 - val_mae: 8.5736\n",
      "Epoch 54/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433.4546 - mae: 16.0538 - val_loss: 132.3858 - val_mae: 8.5920\n",
      "Epoch 55/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.2757 - mae: 16.0878 - val_loss: 139.4600 - val_mae: 8.8400\n",
      "Epoch 56/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 392.2778 - mae: 15.2380 - val_loss: 160.2407 - val_mae: 9.6700\n",
      "Epoch 57/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.6259 - mae: 15.6751 - val_loss: 177.4221 - val_mae: 10.4373\n",
      "Patience 10: Early stopping occurred at epoch 56\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 142.2644 - mae: 8.4011\n",
      "Patience 10: Validation MAE: 8.40\n",
      "Patience 10: Validation Loss: 131.95\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 119.9662, MAE = 7.9446, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 120.1098, MAE = 7.9087, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 20: Loss = 128.5647, MAE = 8.3220, Early Stopping Occurred: True, Early Stopping Epoch: 56\n",
      "Patience 10: Loss = 131.9538, MAE = 8.3988, Early Stopping Occurred: True, Early Stopping Epoch: 56\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "results150 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    sbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    sbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_{}.keras'.format(patience), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = sbp_model.fit(\n",
    "        X_train_combined, SBP_Y_train_combined,\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_combined, SBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = sbp_model.evaluate(X_test_combined, SBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    results150.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in results150:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1783.2426 - mae: 30.0372 - val_loss: 307.6395 - val_mae: 14.7511\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 717.7123 - mae: 21.0698 - val_loss: 385.7057 - val_mae: 14.8461\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 660.7838 - mae: 20.1344 - val_loss: 212.2049 - val_mae: 11.1180\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 595.6188 - mae: 19.2446 - val_loss: 240.2461 - val_mae: 12.0973\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 581.9901 - mae: 18.8914 - val_loss: 174.8908 - val_mae: 9.9472\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 519.4290 - mae: 17.9616 - val_loss: 231.6575 - val_mae: 12.0339\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 494.0663 - mae: 17.2581 - val_loss: 157.1337 - val_mae: 9.4042\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 521.9522 - mae: 17.6945 - val_loss: 188.7162 - val_mae: 10.6471\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 515.5641 - mae: 17.8119 - val_loss: 150.6274 - val_mae: 9.1423\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 499.2885 - mae: 17.4418 - val_loss: 160.1027 - val_mae: 9.4471\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 492.2475 - mae: 17.2887 - val_loss: 153.4560 - val_mae: 9.2738\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 494.3760 - mae: 17.4005 - val_loss: 155.5543 - val_mae: 9.3906\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 478.9155 - mae: 17.2086 - val_loss: 156.7542 - val_mae: 9.3569\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 469.2623 - mae: 17.0971 - val_loss: 176.1407 - val_mae: 10.2718\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 483.6221 - mae: 17.0848 - val_loss: 188.7141 - val_mae: 10.4225\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 476.6018 - mae: 16.8879 - val_loss: 143.3525 - val_mae: 8.9022\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 509.3820 - mae: 17.6605 - val_loss: 232.1095 - val_mae: 12.0634\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 488.7864 - mae: 17.1325 - val_loss: 152.0136 - val_mae: 9.2449\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 466.4794 - mae: 16.8154 - val_loss: 159.2265 - val_mae: 9.6361\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 462.7981 - mae: 16.6457 - val_loss: 145.4165 - val_mae: 8.8919\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 457.5011 - mae: 16.7631 - val_loss: 145.2143 - val_mae: 9.0022\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 458.3731 - mae: 16.7178 - val_loss: 146.0458 - val_mae: 8.8466\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 447.4492 - mae: 16.2624 - val_loss: 195.2080 - val_mae: 10.6071\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 442.6411 - mae: 16.3064 - val_loss: 193.5369 - val_mae: 10.9422\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 454.9729 - mae: 16.6133 - val_loss: 219.5272 - val_mae: 11.7473\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 460.8402 - mae: 16.5055 - val_loss: 226.6474 - val_mae: 12.0810\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 458.1722 - mae: 16.5372 - val_loss: 224.4468 - val_mae: 11.8229\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 448.0230 - mae: 16.6701 - val_loss: 181.4353 - val_mae: 10.3048\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 473.4061 - mae: 16.8770 - val_loss: 134.7711 - val_mae: 8.4830\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 475.4264 - mae: 16.8212 - val_loss: 240.4612 - val_mae: 12.4663\n",
      "Epoch 31/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 448.2950 - mae: 16.4434 - val_loss: 227.1843 - val_mae: 11.9950\n",
      "Epoch 32/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 444.7892 - mae: 16.4099 - val_loss: 137.8687 - val_mae: 8.6193\n",
      "Epoch 33/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 469.6585 - mae: 16.7174 - val_loss: 149.0014 - val_mae: 9.1236\n",
      "Epoch 34/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 461.9962 - mae: 16.5267 - val_loss: 152.3779 - val_mae: 9.1882\n",
      "Epoch 35/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 458.3250 - mae: 16.5741 - val_loss: 134.0081 - val_mae: 8.5527\n",
      "Epoch 36/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 434.8970 - mae: 16.1139 - val_loss: 179.9344 - val_mae: 10.3569\n",
      "Epoch 37/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 442.8872 - mae: 16.1965 - val_loss: 137.5329 - val_mae: 8.7850\n",
      "Epoch 38/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 437.1120 - mae: 16.1784 - val_loss: 166.9297 - val_mae: 9.8280\n",
      "Epoch 39/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 441.0711 - mae: 16.3242 - val_loss: 190.2151 - val_mae: 10.8445\n",
      "Epoch 40/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 436.3189 - mae: 16.1264 - val_loss: 161.5129 - val_mae: 9.7655\n",
      "Epoch 41/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 423.8154 - mae: 16.1061 - val_loss: 141.3536 - val_mae: 8.8580\n",
      "Epoch 42/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 409.5449 - mae: 15.7568 - val_loss: 182.7169 - val_mae: 10.6077\n",
      "Epoch 43/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 435.0345 - mae: 16.2903 - val_loss: 136.0234 - val_mae: 8.5966\n",
      "Epoch 44/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 447.3442 - mae: 16.0259 - val_loss: 143.4893 - val_mae: 8.9184\n",
      "Epoch 45/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 433.1150 - mae: 16.1806 - val_loss: 185.1140 - val_mae: 10.6509\n",
      "Epoch 46/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 422.2273 - mae: 16.2053 - val_loss: 141.4216 - val_mae: 8.7388\n",
      "Epoch 47/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 430.6003 - mae: 15.9202 - val_loss: 140.0282 - val_mae: 8.8543\n",
      "Epoch 48/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 435.9187 - mae: 15.9300 - val_loss: 133.7631 - val_mae: 8.3808\n",
      "Epoch 49/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 428.0557 - mae: 15.9712 - val_loss: 155.0725 - val_mae: 9.5450\n",
      "Epoch 50/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 398.5543 - mae: 15.4997 - val_loss: 139.8565 - val_mae: 8.8614\n",
      "Epoch 51/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 394.3806 - mae: 15.5665 - val_loss: 129.4068 - val_mae: 8.3952\n",
      "Epoch 52/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 418.3556 - mae: 15.9909 - val_loss: 137.8125 - val_mae: 8.4862\n",
      "Epoch 53/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 419.6511 - mae: 15.9927 - val_loss: 136.3952 - val_mae: 8.6619\n",
      "Epoch 54/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 401.5896 - mae: 15.5828 - val_loss: 142.5868 - val_mae: 8.9861\n",
      "Epoch 55/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 409.4204 - mae: 15.7249 - val_loss: 129.4783 - val_mae: 8.3815\n",
      "Epoch 56/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 415.4667 - mae: 15.6545 - val_loss: 135.7406 - val_mae: 8.5054\n",
      "Epoch 57/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 411.2016 - mae: 15.8025 - val_loss: 134.2904 - val_mae: 8.5116\n",
      "Epoch 58/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 390.7895 - mae: 15.4340 - val_loss: 131.8176 - val_mae: 8.4776\n",
      "Epoch 59/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 408.0641 - mae: 15.5402 - val_loss: 142.3188 - val_mae: 8.8855\n",
      "Epoch 60/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 414.6465 - mae: 15.7548 - val_loss: 124.7629 - val_mae: 8.1600\n",
      "Epoch 61/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 393.6714 - mae: 15.3778 - val_loss: 139.7320 - val_mae: 8.6468\n",
      "Epoch 62/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 400.4519 - mae: 15.6079 - val_loss: 129.9210 - val_mae: 8.3776\n",
      "Epoch 63/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 407.7050 - mae: 15.6734 - val_loss: 132.9793 - val_mae: 8.4728\n",
      "Epoch 64/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 378.2740 - mae: 15.1292 - val_loss: 126.0474 - val_mae: 8.3188\n",
      "Epoch 65/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 407.6667 - mae: 15.7515 - val_loss: 137.4913 - val_mae: 8.7791\n",
      "Epoch 66/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 390.8063 - mae: 15.3398 - val_loss: 132.6137 - val_mae: 8.5414\n",
      "Epoch 67/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 405.5931 - mae: 15.6775 - val_loss: 145.3847 - val_mae: 9.1146\n",
      "Epoch 68/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 401.0083 - mae: 15.6051 - val_loss: 150.6278 - val_mae: 9.3229\n",
      "Epoch 69/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 392.1771 - mae: 15.4385 - val_loss: 125.8486 - val_mae: 8.3122\n",
      "Epoch 70/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 389.0683 - mae: 15.1783 - val_loss: 135.7252 - val_mae: 8.7145\n",
      "Epoch 71/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 363.0806 - mae: 14.6828 - val_loss: 123.8125 - val_mae: 8.1209\n",
      "Epoch 72/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 388.2998 - mae: 15.2179 - val_loss: 148.4981 - val_mae: 8.9570\n",
      "Epoch 73/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 397.1628 - mae: 15.5008 - val_loss: 121.7826 - val_mae: 7.9655\n",
      "Epoch 74/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 383.5600 - mae: 15.1895 - val_loss: 172.2355 - val_mae: 10.3320\n",
      "Epoch 75/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 390.9943 - mae: 15.3988 - val_loss: 147.2938 - val_mae: 9.2233\n",
      "Epoch 76/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 368.9427 - mae: 14.7997 - val_loss: 128.3662 - val_mae: 8.3607\n",
      "Epoch 77/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 357.8539 - mae: 14.6383 - val_loss: 150.5922 - val_mae: 9.2544\n",
      "Epoch 78/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 373.6502 - mae: 15.1116 - val_loss: 178.4038 - val_mae: 10.6471\n",
      "Epoch 79/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 375.5782 - mae: 14.9826 - val_loss: 130.0104 - val_mae: 8.5499\n",
      "Epoch 80/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 391.2331 - mae: 15.3197 - val_loss: 123.4961 - val_mae: 8.1593\n",
      "Epoch 81/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 366.5562 - mae: 14.8882 - val_loss: 136.8151 - val_mae: 8.9031\n",
      "Epoch 82/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 387.1807 - mae: 15.3390 - val_loss: 136.0238 - val_mae: 8.8206\n",
      "Epoch 83/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 378.0663 - mae: 15.1936 - val_loss: 134.8231 - val_mae: 8.6762\n",
      "Epoch 84/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 373.7077 - mae: 15.1370 - val_loss: 132.2236 - val_mae: 8.5362\n",
      "Epoch 85/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 374.5515 - mae: 15.0065 - val_loss: 155.7690 - val_mae: 9.7328\n",
      "Epoch 86/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 365.1838 - mae: 14.7262 - val_loss: 124.6458 - val_mae: 8.2592\n",
      "Epoch 87/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 360.7319 - mae: 14.8164 - val_loss: 131.8038 - val_mae: 8.4587\n",
      "Epoch 88/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 363.6876 - mae: 14.8908 - val_loss: 144.6903 - val_mae: 8.9402\n",
      "Epoch 89/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 391.8308 - mae: 15.2760 - val_loss: 182.0538 - val_mae: 10.7303\n",
      "Epoch 90/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 364.9384 - mae: 14.8513 - val_loss: 128.0908 - val_mae: 8.3609\n",
      "Epoch 91/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 382.1558 - mae: 15.0570 - val_loss: 129.5034 - val_mae: 8.3553\n",
      "Epoch 92/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 360.4870 - mae: 14.7839 - val_loss: 126.5775 - val_mae: 8.2694\n",
      "Epoch 93/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 371.1259 - mae: 14.6920 - val_loss: 124.0657 - val_mae: 8.1625\n",
      "Epoch 94/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 346.4121 - mae: 14.5547 - val_loss: 132.7952 - val_mae: 8.5893\n",
      "Epoch 95/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 375.7829 - mae: 14.9887 - val_loss: 138.4563 - val_mae: 8.8469\n",
      "Epoch 96/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 358.7552 - mae: 14.6674 - val_loss: 148.1641 - val_mae: 9.2665\n",
      "Epoch 97/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 347.9232 - mae: 14.3627 - val_loss: 146.6292 - val_mae: 8.8989\n",
      "Epoch 98/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 360.5233 - mae: 14.5604 - val_loss: 127.3620 - val_mae: 8.2229\n",
      "Epoch 99/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 376.3384 - mae: 15.0515 - val_loss: 131.4510 - val_mae: 8.3500\n",
      "Epoch 100/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 363.6192 - mae: 14.7922 - val_loss: 122.9625 - val_mae: 8.1859\n",
      "Epoch 101/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 361.0719 - mae: 14.6416 - val_loss: 207.7689 - val_mae: 11.7186\n",
      "Epoch 102/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 395.7411 - mae: 15.3223 - val_loss: 128.6270 - val_mae: 8.4972\n",
      "Epoch 103/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 332.8566 - mae: 14.3352 - val_loss: 125.2825 - val_mae: 8.0950\n",
      "Epoch 104/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 367.9972 - mae: 14.9691 - val_loss: 147.8018 - val_mae: 9.1214\n",
      "Epoch 105/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 352.2557 - mae: 14.4566 - val_loss: 122.4145 - val_mae: 8.0489\n",
      "Epoch 106/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 369.7556 - mae: 14.6982 - val_loss: 152.8190 - val_mae: 9.4162\n",
      "Epoch 107/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 366.7302 - mae: 14.8966 - val_loss: 134.1317 - val_mae: 8.6851\n",
      "Epoch 108/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 356.7478 - mae: 14.4937 - val_loss: 122.0609 - val_mae: 8.1287\n",
      "Epoch 109/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 351.5523 - mae: 14.3809 - val_loss: 125.3984 - val_mae: 8.1158\n",
      "Epoch 110/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 344.3142 - mae: 14.3458 - val_loss: 149.4372 - val_mae: 9.1896\n",
      "Epoch 111/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 364.4145 - mae: 14.7049 - val_loss: 126.6234 - val_mae: 8.3721\n",
      "Epoch 112/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 359.8903 - mae: 14.6466 - val_loss: 173.0199 - val_mae: 10.3161\n",
      "Epoch 113/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 342.5828 - mae: 14.3250 - val_loss: 119.2362 - val_mae: 8.0323\n",
      "Epoch 114/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 356.8177 - mae: 14.4775 - val_loss: 126.8947 - val_mae: 8.1804\n",
      "Epoch 115/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 362.8897 - mae: 14.8766 - val_loss: 128.9028 - val_mae: 8.4106\n",
      "Epoch 116/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 353.2932 - mae: 14.5787 - val_loss: 146.0868 - val_mae: 9.2958\n",
      "Epoch 117/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 342.1090 - mae: 14.2006 - val_loss: 123.9141 - val_mae: 8.1716\n",
      "Epoch 118/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 334.9601 - mae: 14.2190 - val_loss: 125.1482 - val_mae: 8.3012\n",
      "Epoch 119/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 358.3787 - mae: 14.5196 - val_loss: 120.1179 - val_mae: 7.9447\n",
      "Epoch 120/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 359.8911 - mae: 14.5977 - val_loss: 120.6737 - val_mae: 8.0003\n",
      "Epoch 121/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 331.9922 - mae: 13.9330 - val_loss: 122.7832 - val_mae: 8.0489\n",
      "Epoch 122/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 346.6498 - mae: 14.4784 - val_loss: 132.2565 - val_mae: 8.4971\n",
      "Epoch 123/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 342.4998 - mae: 14.2149 - val_loss: 120.3023 - val_mae: 8.0252\n",
      "Epoch 124/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 354.3430 - mae: 14.4864 - val_loss: 121.6520 - val_mae: 8.0976\n",
      "Epoch 125/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 339.6327 - mae: 14.2025 - val_loss: 119.5997 - val_mae: 8.0345\n",
      "Epoch 126/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 369.1663 - mae: 14.7228 - val_loss: 121.1601 - val_mae: 8.1039\n",
      "Epoch 127/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 350.3241 - mae: 14.4325 - val_loss: 123.0972 - val_mae: 8.1139\n",
      "Epoch 128/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 341.1874 - mae: 14.1787 - val_loss: 120.3367 - val_mae: 7.8938\n",
      "Epoch 129/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 329.4579 - mae: 14.1517 - val_loss: 120.5953 - val_mae: 8.0256\n",
      "Epoch 130/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 344.5714 - mae: 14.2373 - val_loss: 119.4927 - val_mae: 7.9769\n",
      "Epoch 131/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 333.3427 - mae: 14.1234 - val_loss: 122.0745 - val_mae: 8.0931\n",
      "Epoch 132/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 360.3716 - mae: 14.3714 - val_loss: 123.6267 - val_mae: 8.0234\n",
      "Epoch 133/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 349.0771 - mae: 14.3255 - val_loss: 122.0518 - val_mae: 8.0480\n",
      "Epoch 134/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 334.0484 - mae: 13.9283 - val_loss: 129.1437 - val_mae: 8.4242\n",
      "Epoch 135/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 331.1535 - mae: 14.0813 - val_loss: 143.6362 - val_mae: 9.2490\n",
      "Epoch 136/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 359.6361 - mae: 14.6524 - val_loss: 133.4159 - val_mae: 8.5071\n",
      "Epoch 137/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328.6977 - mae: 13.9412 - val_loss: 127.8948 - val_mae: 8.3786\n",
      "Epoch 138/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 338.3159 - mae: 14.0404 - val_loss: 118.5138 - val_mae: 8.0349\n",
      "Epoch 139/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 356.5613 - mae: 14.4218 - val_loss: 141.2087 - val_mae: 8.9885\n",
      "Epoch 140/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 327.3810 - mae: 13.8987 - val_loss: 140.9644 - val_mae: 9.0640\n",
      "Epoch 141/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 334.2317 - mae: 13.9050 - val_loss: 126.8137 - val_mae: 8.2688\n",
      "Epoch 142/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 327.4779 - mae: 14.0290 - val_loss: 139.5998 - val_mae: 8.9530\n",
      "Epoch 143/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 333.6328 - mae: 13.9305 - val_loss: 127.4938 - val_mae: 8.3027\n",
      "Epoch 144/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 320.7230 - mae: 13.8616 - val_loss: 142.0304 - val_mae: 8.9973\n",
      "Epoch 145/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 329.5383 - mae: 14.0160 - val_loss: 121.5269 - val_mae: 8.1132\n",
      "Epoch 146/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 312.8065 - mae: 13.6652 - val_loss: 140.9908 - val_mae: 8.9135\n",
      "Epoch 147/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 334.7363 - mae: 14.0310 - val_loss: 126.1578 - val_mae: 8.1217\n",
      "Epoch 148/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 320.7071 - mae: 13.7154 - val_loss: 121.7876 - val_mae: 7.9940\n",
      "Epoch 149/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 320.8700 - mae: 13.6977 - val_loss: 130.3431 - val_mae: 8.5352\n",
      "Epoch 150/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 311.9487 - mae: 13.7321 - val_loss: 124.4216 - val_mae: 8.2995\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 130.5385 - mae: 8.1038\n",
      "Patience 40: Validation MAE: 8.03\n",
      "Patience 40: Validation Loss: 118.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1427.4882 - mae: 28.0325 - val_loss: 319.1409 - val_mae: 13.4995\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.1040 - mae: 19.8308 - val_loss: 300.6466 - val_mae: 13.1945\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 597.5475 - mae: 18.9296 - val_loss: 304.3677 - val_mae: 13.6102\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 493.4041 - mae: 17.3988 - val_loss: 285.2341 - val_mae: 13.3353\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 487.7473 - mae: 17.2930 - val_loss: 195.5689 - val_mae: 10.6872\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 453.4216 - mae: 16.4359 - val_loss: 191.4865 - val_mae: 10.6018\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 477.0499 - mae: 16.8368 - val_loss: 156.8180 - val_mae: 9.4541\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 427.9731 - mae: 16.1805 - val_loss: 161.8499 - val_mae: 9.6920\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 444.8625 - mae: 16.6691 - val_loss: 159.8315 - val_mae: 9.6357\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 424.5892 - mae: 15.9138 - val_loss: 172.4588 - val_mae: 9.9474\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 432.5312 - mae: 16.1663 - val_loss: 156.9512 - val_mae: 9.2150\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 424.5173 - mae: 16.0541 - val_loss: 186.7337 - val_mae: 10.2018\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 429.0810 - mae: 16.0701 - val_loss: 147.4047 - val_mae: 9.0167\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 420.7665 - mae: 16.0819 - val_loss: 142.8379 - val_mae: 8.8276\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 432.4684 - mae: 16.2318 - val_loss: 197.0879 - val_mae: 11.0062\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 407.9259 - mae: 15.5833 - val_loss: 159.6843 - val_mae: 9.7427\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 386.0240 - mae: 15.1962 - val_loss: 138.0347 - val_mae: 8.7660\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 394.0118 - mae: 15.3054 - val_loss: 159.5461 - val_mae: 9.2684\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 415.0661 - mae: 15.7808 - val_loss: 192.0400 - val_mae: 10.9467\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 412.1245 - mae: 15.6579 - val_loss: 147.9786 - val_mae: 9.2227\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 379.8953 - mae: 14.9337 - val_loss: 152.7383 - val_mae: 9.4549\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 376.9831 - mae: 15.1623 - val_loss: 178.3823 - val_mae: 10.5642\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 388.4825 - mae: 15.1880 - val_loss: 149.6936 - val_mae: 9.0694\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 364.3979 - mae: 14.8836 - val_loss: 159.2697 - val_mae: 9.6543\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 377.3103 - mae: 14.9677 - val_loss: 135.4380 - val_mae: 8.5596\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 384.8521 - mae: 15.1519 - val_loss: 155.9749 - val_mae: 9.5028\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 382.7651 - mae: 15.2593 - val_loss: 164.1981 - val_mae: 9.9486\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 397.1067 - mae: 15.3841 - val_loss: 156.6692 - val_mae: 9.6890\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 381.5196 - mae: 15.0331 - val_loss: 136.2597 - val_mae: 8.6380\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 368.6261 - mae: 14.8653 - val_loss: 130.6152 - val_mae: 8.4759\n",
      "Epoch 31/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 384.3476 - mae: 15.1497 - val_loss: 254.6076 - val_mae: 13.1872\n",
      "Epoch 32/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 378.4350 - mae: 14.9867 - val_loss: 167.3098 - val_mae: 9.8241\n",
      "Epoch 33/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 369.1262 - mae: 14.8915 - val_loss: 132.4102 - val_mae: 8.4877\n",
      "Epoch 34/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 361.6329 - mae: 14.7360 - val_loss: 135.2740 - val_mae: 8.6697\n",
      "Epoch 35/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 375.3553 - mae: 14.9675 - val_loss: 204.5853 - val_mae: 11.1683\n",
      "Epoch 36/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 376.5168 - mae: 14.9285 - val_loss: 148.1870 - val_mae: 9.2292\n",
      "Epoch 37/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 380.3914 - mae: 14.9727 - val_loss: 134.6442 - val_mae: 8.5784\n",
      "Epoch 38/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 357.0655 - mae: 14.6321 - val_loss: 132.1196 - val_mae: 8.4710\n",
      "Epoch 39/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 366.3751 - mae: 15.0224 - val_loss: 135.3452 - val_mae: 8.7227\n",
      "Epoch 40/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 369.9187 - mae: 14.9736 - val_loss: 134.9188 - val_mae: 8.5309\n",
      "Epoch 41/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 354.3570 - mae: 14.6754 - val_loss: 139.3703 - val_mae: 8.8923\n",
      "Epoch 42/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 353.5764 - mae: 14.6165 - val_loss: 148.6063 - val_mae: 8.9245\n",
      "Epoch 43/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 403.4179 - mae: 15.4250 - val_loss: 140.4754 - val_mae: 8.9484\n",
      "Epoch 44/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 389.2450 - mae: 15.1853 - val_loss: 148.6963 - val_mae: 8.9664\n",
      "Epoch 45/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 392.1844 - mae: 14.9838 - val_loss: 129.4842 - val_mae: 8.3885\n",
      "Epoch 46/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 385.0741 - mae: 14.9661 - val_loss: 156.7798 - val_mae: 9.5503\n",
      "Epoch 47/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 370.3901 - mae: 14.8862 - val_loss: 131.6565 - val_mae: 8.3823\n",
      "Epoch 48/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 374.4062 - mae: 14.9334 - val_loss: 130.4081 - val_mae: 8.3302\n",
      "Epoch 49/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 346.5117 - mae: 14.5568 - val_loss: 134.8651 - val_mae: 8.5666\n",
      "Epoch 50/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 353.1196 - mae: 14.6616 - val_loss: 130.6524 - val_mae: 8.3864\n",
      "Epoch 51/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 360.1040 - mae: 14.7771 - val_loss: 135.9043 - val_mae: 8.5917\n",
      "Epoch 52/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 353.6786 - mae: 14.4394 - val_loss: 134.3497 - val_mae: 8.4978\n",
      "Epoch 53/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 340.8350 - mae: 14.3208 - val_loss: 132.9119 - val_mae: 8.5528\n",
      "Epoch 54/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 361.6845 - mae: 14.7081 - val_loss: 179.8699 - val_mae: 10.4563\n",
      "Epoch 55/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 351.8367 - mae: 14.4989 - val_loss: 159.3022 - val_mae: 9.6449\n",
      "Epoch 56/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 381.4895 - mae: 14.7652 - val_loss: 136.8283 - val_mae: 8.7495\n",
      "Epoch 57/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 373.0409 - mae: 14.7562 - val_loss: 153.4735 - val_mae: 9.2324\n",
      "Epoch 58/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 342.1299 - mae: 14.3616 - val_loss: 163.0496 - val_mae: 9.9135\n",
      "Epoch 59/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 372.0819 - mae: 14.6652 - val_loss: 128.9347 - val_mae: 8.3574\n",
      "Epoch 60/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328.2584 - mae: 13.9743 - val_loss: 136.8803 - val_mae: 8.6956\n",
      "Epoch 61/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 363.3054 - mae: 14.6450 - val_loss: 129.3290 - val_mae: 8.3963\n",
      "Epoch 62/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 358.7896 - mae: 14.4787 - val_loss: 162.7344 - val_mae: 10.0198\n",
      "Epoch 63/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 352.5985 - mae: 14.4553 - val_loss: 132.9600 - val_mae: 8.4425\n",
      "Epoch 64/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 367.7541 - mae: 14.6729 - val_loss: 128.2819 - val_mae: 8.3537\n",
      "Epoch 65/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 368.4232 - mae: 14.8736 - val_loss: 129.1626 - val_mae: 8.3482\n",
      "Epoch 66/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 367.2383 - mae: 14.6757 - val_loss: 130.7023 - val_mae: 8.2776\n",
      "Epoch 67/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 339.4320 - mae: 14.3570 - val_loss: 130.8455 - val_mae: 8.3528\n",
      "Epoch 68/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 354.1484 - mae: 14.5260 - val_loss: 125.4087 - val_mae: 8.2250\n",
      "Epoch 69/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 346.6296 - mae: 14.3425 - val_loss: 142.0171 - val_mae: 8.8781\n",
      "Epoch 70/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 337.2650 - mae: 14.0971 - val_loss: 140.5927 - val_mae: 8.9608\n",
      "Epoch 71/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 363.3578 - mae: 14.5410 - val_loss: 126.8153 - val_mae: 8.2459\n",
      "Epoch 72/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 349.6591 - mae: 14.5550 - val_loss: 123.2588 - val_mae: 8.1853\n",
      "Epoch 73/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 355.7018 - mae: 14.6390 - val_loss: 131.1053 - val_mae: 8.3881\n",
      "Epoch 74/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 345.2649 - mae: 14.2098 - val_loss: 133.6708 - val_mae: 8.5112\n",
      "Epoch 75/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 331.2697 - mae: 13.9364 - val_loss: 132.4839 - val_mae: 8.5017\n",
      "Epoch 76/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 344.4537 - mae: 14.1994 - val_loss: 162.5846 - val_mae: 9.8661\n",
      "Epoch 77/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 331.8060 - mae: 13.8441 - val_loss: 160.2742 - val_mae: 9.6479\n",
      "Epoch 78/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 342.0065 - mae: 14.1791 - val_loss: 222.4069 - val_mae: 11.9113\n",
      "Epoch 79/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 341.2433 - mae: 14.2143 - val_loss: 124.1057 - val_mae: 8.1480\n",
      "Epoch 80/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 350.5788 - mae: 14.4379 - val_loss: 125.5647 - val_mae: 8.2821\n",
      "Epoch 81/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 322.0406 - mae: 13.8605 - val_loss: 122.2761 - val_mae: 8.0722\n",
      "Epoch 82/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 332.5792 - mae: 13.9618 - val_loss: 123.7973 - val_mae: 8.1569\n",
      "Epoch 83/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 325.2685 - mae: 13.7208 - val_loss: 168.0553 - val_mae: 10.0307\n",
      "Epoch 84/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 325.2194 - mae: 13.8519 - val_loss: 129.5076 - val_mae: 8.3882\n",
      "Epoch 85/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 326.1035 - mae: 13.9946 - val_loss: 150.5933 - val_mae: 9.3143\n",
      "Epoch 86/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 348.0742 - mae: 14.2680 - val_loss: 129.7358 - val_mae: 8.4927\n",
      "Epoch 87/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 322.8789 - mae: 13.8814 - val_loss: 133.7002 - val_mae: 8.5824\n",
      "Epoch 88/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 322.7982 - mae: 13.6499 - val_loss: 128.0783 - val_mae: 8.3650\n",
      "Epoch 89/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 312.3828 - mae: 13.4009 - val_loss: 126.9241 - val_mae: 8.2606\n",
      "Epoch 90/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 350.5263 - mae: 14.2938 - val_loss: 124.2044 - val_mae: 8.2491\n",
      "Epoch 91/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 342.9352 - mae: 14.3066 - val_loss: 135.6834 - val_mae: 8.6326\n",
      "Epoch 92/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 317.8192 - mae: 13.6876 - val_loss: 120.2453 - val_mae: 8.0233\n",
      "Epoch 93/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328.7780 - mae: 14.0479 - val_loss: 121.0811 - val_mae: 8.0156\n",
      "Epoch 94/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 296.2495 - mae: 13.3893 - val_loss: 167.2087 - val_mae: 9.9231\n",
      "Epoch 95/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 323.6882 - mae: 13.7592 - val_loss: 149.1959 - val_mae: 9.2192\n",
      "Epoch 96/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 324.7219 - mae: 13.8234 - val_loss: 150.4702 - val_mae: 9.4441\n",
      "Epoch 97/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328.8871 - mae: 13.8144 - val_loss: 141.3508 - val_mae: 8.8866\n",
      "Epoch 98/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 316.7971 - mae: 13.5479 - val_loss: 141.5731 - val_mae: 8.9780\n",
      "Epoch 99/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 323.2473 - mae: 13.8813 - val_loss: 137.3327 - val_mae: 8.6418\n",
      "Epoch 100/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328.5716 - mae: 13.9461 - val_loss: 136.1800 - val_mae: 8.7174\n",
      "Epoch 101/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 316.3734 - mae: 13.6801 - val_loss: 130.3201 - val_mae: 8.4999\n",
      "Epoch 102/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 315.7202 - mae: 13.7556 - val_loss: 123.8853 - val_mae: 8.2080\n",
      "Epoch 103/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 312.6885 - mae: 13.5072 - val_loss: 125.5423 - val_mae: 8.2148\n",
      "Epoch 104/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 312.4136 - mae: 13.6201 - val_loss: 127.0770 - val_mae: 8.2432\n",
      "Epoch 105/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 323.4758 - mae: 13.7911 - val_loss: 124.0893 - val_mae: 8.1400\n",
      "Epoch 106/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 313.0501 - mae: 13.6368 - val_loss: 122.2497 - val_mae: 8.0590\n",
      "Epoch 107/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 323.3474 - mae: 13.7915 - val_loss: 125.9174 - val_mae: 8.1504\n",
      "Epoch 108/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 331.1938 - mae: 13.8122 - val_loss: 139.6543 - val_mae: 8.9094\n",
      "Epoch 109/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 297.1617 - mae: 13.3491 - val_loss: 152.3966 - val_mae: 9.4101\n",
      "Epoch 110/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 307.9210 - mae: 13.5867 - val_loss: 150.0282 - val_mae: 9.2853\n",
      "Epoch 111/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 304.9685 - mae: 13.3808 - val_loss: 120.9098 - val_mae: 8.0443\n",
      "Epoch 112/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 319.4438 - mae: 13.5907 - val_loss: 125.4060 - val_mae: 8.1434\n",
      "Epoch 113/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 306.6827 - mae: 13.4723 - val_loss: 119.5244 - val_mae: 7.9833\n",
      "Epoch 114/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 306.7265 - mae: 13.3530 - val_loss: 191.8784 - val_mae: 11.0636\n",
      "Epoch 115/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 310.5901 - mae: 13.5048 - val_loss: 128.1481 - val_mae: 8.2650\n",
      "Epoch 116/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 339.2137 - mae: 13.9792 - val_loss: 121.8243 - val_mae: 8.0909\n",
      "Epoch 117/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 302.2534 - mae: 13.3456 - val_loss: 129.3319 - val_mae: 8.3958\n",
      "Epoch 118/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 297.2288 - mae: 13.1480 - val_loss: 118.6396 - val_mae: 7.9523\n",
      "Epoch 119/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 313.2116 - mae: 13.5985 - val_loss: 122.8719 - val_mae: 8.1195\n",
      "Epoch 120/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 294.0020 - mae: 13.1570 - val_loss: 125.1515 - val_mae: 8.2401\n",
      "Epoch 121/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 314.8601 - mae: 13.7343 - val_loss: 129.9737 - val_mae: 8.4034\n",
      "Epoch 122/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 317.7253 - mae: 13.4956 - val_loss: 134.8329 - val_mae: 8.4511\n",
      "Epoch 123/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 311.0633 - mae: 13.5225 - val_loss: 117.9651 - val_mae: 7.8787\n",
      "Epoch 124/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 320.0644 - mae: 13.6250 - val_loss: 132.8333 - val_mae: 8.5726\n",
      "Epoch 125/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 306.3899 - mae: 13.3764 - val_loss: 119.9472 - val_mae: 7.9985\n",
      "Epoch 126/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 291.5880 - mae: 13.0708 - val_loss: 126.2414 - val_mae: 8.2572\n",
      "Epoch 127/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 317.2392 - mae: 13.8146 - val_loss: 123.4574 - val_mae: 8.1214\n",
      "Epoch 128/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 311.2379 - mae: 13.4623 - val_loss: 128.3452 - val_mae: 8.3157\n",
      "Epoch 129/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 293.3524 - mae: 13.0761 - val_loss: 121.4425 - val_mae: 8.0869\n",
      "Epoch 130/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 309.1901 - mae: 13.4963 - val_loss: 124.3298 - val_mae: 8.1784\n",
      "Epoch 131/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 303.7525 - mae: 13.1855 - val_loss: 124.2094 - val_mae: 8.2551\n",
      "Epoch 132/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 316.3191 - mae: 13.6490 - val_loss: 121.9834 - val_mae: 8.0947\n",
      "Epoch 133/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 308.1259 - mae: 13.3146 - val_loss: 133.4342 - val_mae: 8.4963\n",
      "Epoch 134/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 293.8867 - mae: 13.0512 - val_loss: 123.6004 - val_mae: 8.0884\n",
      "Epoch 135/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 311.3279 - mae: 13.5862 - val_loss: 117.4073 - val_mae: 7.8914\n",
      "Epoch 136/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 289.2715 - mae: 13.0638 - val_loss: 128.5798 - val_mae: 8.2699\n",
      "Epoch 137/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 295.4450 - mae: 13.1703 - val_loss: 119.8132 - val_mae: 7.9065\n",
      "Epoch 138/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 302.5304 - mae: 13.3030 - val_loss: 172.2571 - val_mae: 9.9716\n",
      "Epoch 139/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 304.2974 - mae: 13.3370 - val_loss: 119.0939 - val_mae: 7.9448\n",
      "Epoch 140/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 292.9368 - mae: 13.2079 - val_loss: 122.6906 - val_mae: 8.1821\n",
      "Epoch 141/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 309.1915 - mae: 13.4485 - val_loss: 116.7564 - val_mae: 7.8032\n",
      "Epoch 142/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 290.2993 - mae: 13.0874 - val_loss: 124.9839 - val_mae: 8.1949\n",
      "Epoch 143/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 291.4202 - mae: 13.1126 - val_loss: 129.2345 - val_mae: 8.4344\n",
      "Epoch 144/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 293.2609 - mae: 12.9928 - val_loss: 119.9956 - val_mae: 7.9820\n",
      "Epoch 145/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 294.0228 - mae: 13.2191 - val_loss: 126.4144 - val_mae: 8.3629\n",
      "Epoch 146/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 285.3441 - mae: 12.9812 - val_loss: 119.8573 - val_mae: 7.9176\n",
      "Epoch 147/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 305.6039 - mae: 13.3913 - val_loss: 119.6028 - val_mae: 7.9492\n",
      "Epoch 148/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 292.9726 - mae: 13.0352 - val_loss: 141.9465 - val_mae: 8.8326\n",
      "Epoch 149/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 293.8805 - mae: 12.9781 - val_loss: 121.8029 - val_mae: 7.9790\n",
      "Epoch 150/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 281.1703 - mae: 12.8519 - val_loss: 120.8775 - val_mae: 8.0245\n",
      "Patience 30: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 129.1073 - mae: 7.8098\n",
      "Patience 30: Validation MAE: 7.80\n",
      "Patience 30: Validation Loss: 116.76\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1471.6700 - mae: 28.0389 - val_loss: 308.4289 - val_mae: 13.1625\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 617.3210 - mae: 19.4016 - val_loss: 267.5706 - val_mae: 12.3400\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 553.6320 - mae: 18.4227 - val_loss: 220.2511 - val_mae: 11.3087\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 477.7956 - mae: 17.2045 - val_loss: 204.9664 - val_mae: 10.9217\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 471.8857 - mae: 16.7633 - val_loss: 233.4646 - val_mae: 12.0699\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 447.8450 - mae: 16.3204 - val_loss: 186.4283 - val_mae: 10.5347\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 436.4834 - mae: 16.1831 - val_loss: 179.5678 - val_mae: 10.3069\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 459.3610 - mae: 16.4614 - val_loss: 176.7778 - val_mae: 10.1908\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 425.2841 - mae: 15.9980 - val_loss: 147.7899 - val_mae: 9.0237\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 452.9289 - mae: 16.4801 - val_loss: 177.8775 - val_mae: 10.4261\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 434.0562 - mae: 16.1673 - val_loss: 148.1068 - val_mae: 8.9165\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 432.6957 - mae: 16.1733 - val_loss: 157.9728 - val_mae: 9.4339\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 422.4599 - mae: 15.9842 - val_loss: 149.6040 - val_mae: 9.1824\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 436.9155 - mae: 15.9692 - val_loss: 145.5089 - val_mae: 9.0028\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 416.6777 - mae: 15.7532 - val_loss: 158.3147 - val_mae: 9.6623\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 397.9433 - mae: 15.5893 - val_loss: 153.2654 - val_mae: 9.1900\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 391.7726 - mae: 15.4916 - val_loss: 146.2968 - val_mae: 9.0634\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 392.9239 - mae: 15.2719 - val_loss: 145.0992 - val_mae: 8.9667\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 408.4728 - mae: 15.3650 - val_loss: 137.6636 - val_mae: 8.7447\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 401.0995 - mae: 15.5464 - val_loss: 152.6728 - val_mae: 9.3818\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 393.4983 - mae: 15.4403 - val_loss: 143.9806 - val_mae: 8.7405\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 374.4488 - mae: 15.0325 - val_loss: 142.6049 - val_mae: 8.6801\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 391.2798 - mae: 15.2265 - val_loss: 192.7352 - val_mae: 10.8261\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 383.3462 - mae: 15.0915 - val_loss: 278.9338 - val_mae: 13.2684\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 412.9580 - mae: 15.7455 - val_loss: 168.3895 - val_mae: 9.7598\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 395.8772 - mae: 15.3713 - val_loss: 139.6091 - val_mae: 8.8059\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 418.3004 - mae: 15.4864 - val_loss: 137.5340 - val_mae: 8.6006\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 370.6679 - mae: 14.9319 - val_loss: 136.3560 - val_mae: 8.6356\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 381.0195 - mae: 15.1887 - val_loss: 136.1646 - val_mae: 8.6491\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 390.7216 - mae: 15.2063 - val_loss: 131.2583 - val_mae: 8.3340\n",
      "Epoch 31/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382.1846 - mae: 15.1066 - val_loss: 131.3941 - val_mae: 8.4171\n",
      "Epoch 32/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 378.9633 - mae: 15.0420 - val_loss: 135.9688 - val_mae: 8.6205\n",
      "Epoch 33/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 377.5953 - mae: 14.9798 - val_loss: 133.4278 - val_mae: 8.5090\n",
      "Epoch 34/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 342.6017 - mae: 14.4402 - val_loss: 140.1670 - val_mae: 8.9389\n",
      "Epoch 35/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 387.9825 - mae: 15.2537 - val_loss: 226.7006 - val_mae: 12.1158\n",
      "Epoch 36/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 383.9450 - mae: 15.2567 - val_loss: 158.1714 - val_mae: 9.7474\n",
      "Epoch 37/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 392.0098 - mae: 14.9821 - val_loss: 161.9804 - val_mae: 9.8566\n",
      "Epoch 38/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 362.5991 - mae: 14.7048 - val_loss: 144.4087 - val_mae: 8.8746\n",
      "Epoch 39/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 377.6594 - mae: 14.8346 - val_loss: 136.4250 - val_mae: 8.5930\n",
      "Epoch 40/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 376.5400 - mae: 14.9476 - val_loss: 139.6354 - val_mae: 8.8165\n",
      "Epoch 41/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 361.1797 - mae: 14.6510 - val_loss: 133.2280 - val_mae: 8.5322\n",
      "Epoch 42/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 349.0013 - mae: 14.1930 - val_loss: 138.6393 - val_mae: 8.8324\n",
      "Epoch 43/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 364.9344 - mae: 14.6728 - val_loss: 146.7851 - val_mae: 9.1011\n",
      "Epoch 44/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 378.0513 - mae: 14.8998 - val_loss: 141.9092 - val_mae: 8.8763\n",
      "Epoch 45/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 363.2616 - mae: 14.6014 - val_loss: 137.5264 - val_mae: 8.6565\n",
      "Epoch 46/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 357.9808 - mae: 14.5293 - val_loss: 130.2559 - val_mae: 8.4020\n",
      "Epoch 47/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 373.9709 - mae: 14.8777 - val_loss: 124.5696 - val_mae: 8.1033\n",
      "Epoch 48/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 366.8393 - mae: 14.7305 - val_loss: 142.4549 - val_mae: 8.9444\n",
      "Epoch 49/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 362.8356 - mae: 14.7645 - val_loss: 131.9724 - val_mae: 8.3409\n",
      "Epoch 50/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 360.4851 - mae: 14.7061 - val_loss: 143.2238 - val_mae: 9.0488\n",
      "Epoch 51/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 361.2306 - mae: 14.5131 - val_loss: 135.8367 - val_mae: 8.7105\n",
      "Epoch 52/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 336.7902 - mae: 14.1797 - val_loss: 156.8853 - val_mae: 9.5477\n",
      "Epoch 53/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 340.7776 - mae: 14.3459 - val_loss: 144.8748 - val_mae: 9.0885\n",
      "Epoch 54/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 381.7855 - mae: 14.8764 - val_loss: 129.9600 - val_mae: 8.4169\n",
      "Epoch 55/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 347.3743 - mae: 14.4522 - val_loss: 139.0840 - val_mae: 8.8092\n",
      "Epoch 56/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 348.9019 - mae: 14.4605 - val_loss: 141.7174 - val_mae: 8.8072\n",
      "Epoch 57/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 359.6803 - mae: 14.6110 - val_loss: 133.7766 - val_mae: 8.5339\n",
      "Epoch 58/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 349.1072 - mae: 14.2829 - val_loss: 140.6984 - val_mae: 8.7218\n",
      "Epoch 59/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 343.7196 - mae: 14.5716 - val_loss: 124.0569 - val_mae: 8.0967\n",
      "Epoch 60/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 349.5072 - mae: 14.3511 - val_loss: 126.4203 - val_mae: 8.2029\n",
      "Epoch 61/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 344.2807 - mae: 14.3351 - val_loss: 123.1846 - val_mae: 8.0309\n",
      "Epoch 62/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 354.0649 - mae: 14.5183 - val_loss: 145.4882 - val_mae: 8.9714\n",
      "Epoch 63/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328.4777 - mae: 13.9057 - val_loss: 142.0664 - val_mae: 8.7371\n",
      "Epoch 64/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 359.2407 - mae: 14.6279 - val_loss: 159.8022 - val_mae: 9.7379\n",
      "Epoch 65/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 356.5035 - mae: 14.1781 - val_loss: 130.2515 - val_mae: 8.3088\n",
      "Epoch 66/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 337.2499 - mae: 14.1829 - val_loss: 140.3013 - val_mae: 8.7952\n",
      "Epoch 67/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 353.0971 - mae: 14.4208 - val_loss: 150.3680 - val_mae: 9.1350\n",
      "Epoch 68/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 335.1425 - mae: 13.9027 - val_loss: 136.9873 - val_mae: 8.6734\n",
      "Epoch 69/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 316.5061 - mae: 13.6496 - val_loss: 175.2631 - val_mae: 10.3637\n",
      "Epoch 70/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 345.1528 - mae: 14.3525 - val_loss: 126.6378 - val_mae: 8.2633\n",
      "Epoch 71/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 327.0042 - mae: 14.0001 - val_loss: 134.0759 - val_mae: 8.5729\n",
      "Epoch 72/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 327.1705 - mae: 13.9561 - val_loss: 120.3917 - val_mae: 7.9814\n",
      "Epoch 73/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 335.7871 - mae: 14.0599 - val_loss: 132.3532 - val_mae: 8.5356\n",
      "Epoch 74/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 343.7762 - mae: 14.2571 - val_loss: 130.2747 - val_mae: 8.3931\n",
      "Epoch 75/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 352.7327 - mae: 14.5670 - val_loss: 129.5110 - val_mae: 8.3785\n",
      "Epoch 76/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 318.0282 - mae: 13.7608 - val_loss: 130.7811 - val_mae: 8.4468\n",
      "Epoch 77/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 324.1647 - mae: 13.9277 - val_loss: 129.4011 - val_mae: 8.4756\n",
      "Epoch 78/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 350.5775 - mae: 14.3523 - val_loss: 134.8761 - val_mae: 8.6891\n",
      "Epoch 79/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 341.0100 - mae: 14.1411 - val_loss: 125.2536 - val_mae: 8.2659\n",
      "Epoch 80/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 337.4972 - mae: 14.2160 - val_loss: 144.4804 - val_mae: 9.1062\n",
      "Epoch 81/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 329.7840 - mae: 13.8776 - val_loss: 174.1380 - val_mae: 9.9712\n",
      "Epoch 82/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 320.2654 - mae: 13.9547 - val_loss: 161.5118 - val_mae: 9.5143\n",
      "Epoch 83/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 336.7793 - mae: 14.2918 - val_loss: 141.0471 - val_mae: 8.7629\n",
      "Epoch 84/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 327.2190 - mae: 14.2041 - val_loss: 122.9428 - val_mae: 8.1957\n",
      "Epoch 85/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 345.7657 - mae: 14.2899 - val_loss: 133.2898 - val_mae: 8.5588\n",
      "Epoch 86/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 314.4912 - mae: 13.8195 - val_loss: 135.3812 - val_mae: 8.6141\n",
      "Epoch 87/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 344.4320 - mae: 14.2523 - val_loss: 162.9818 - val_mae: 9.8902\n",
      "Epoch 88/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328.9421 - mae: 13.9742 - val_loss: 124.2554 - val_mae: 8.0485\n",
      "Epoch 89/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 339.0741 - mae: 13.9708 - val_loss: 142.5352 - val_mae: 8.7101\n",
      "Epoch 90/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 317.3553 - mae: 13.7295 - val_loss: 118.2741 - val_mae: 7.8830\n",
      "Epoch 91/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 306.1339 - mae: 13.4774 - val_loss: 123.1392 - val_mae: 8.0381\n",
      "Epoch 92/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 311.4084 - mae: 13.5845 - val_loss: 129.1683 - val_mae: 8.1929\n",
      "Epoch 93/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 318.6436 - mae: 13.7521 - val_loss: 121.5603 - val_mae: 8.0806\n",
      "Epoch 94/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 332.0563 - mae: 13.9493 - val_loss: 126.0528 - val_mae: 8.1470\n",
      "Epoch 95/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 336.3983 - mae: 13.9377 - val_loss: 123.0490 - val_mae: 7.9732\n",
      "Epoch 96/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 340.8674 - mae: 13.9453 - val_loss: 132.3328 - val_mae: 8.5569\n",
      "Epoch 97/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 314.0557 - mae: 13.6330 - val_loss: 132.6704 - val_mae: 8.5276\n",
      "Epoch 98/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 319.0446 - mae: 13.7129 - val_loss: 123.3717 - val_mae: 8.1136\n",
      "Epoch 99/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 311.8701 - mae: 13.6731 - val_loss: 132.8454 - val_mae: 8.6827\n",
      "Epoch 100/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 308.6864 - mae: 13.5380 - val_loss: 124.7174 - val_mae: 8.0866\n",
      "Epoch 101/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 337.2927 - mae: 14.0791 - val_loss: 125.9948 - val_mae: 8.2645\n",
      "Epoch 102/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 308.8260 - mae: 13.4232 - val_loss: 119.3610 - val_mae: 7.9496\n",
      "Epoch 103/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 299.8293 - mae: 13.3422 - val_loss: 121.0737 - val_mae: 7.9759\n",
      "Epoch 104/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 314.3617 - mae: 13.4457 - val_loss: 125.5961 - val_mae: 8.2598\n",
      "Epoch 105/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 314.1053 - mae: 13.7428 - val_loss: 117.7746 - val_mae: 7.8568\n",
      "Epoch 106/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 320.2587 - mae: 13.5720 - val_loss: 123.5295 - val_mae: 8.0506\n",
      "Epoch 107/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 300.4425 - mae: 13.4287 - val_loss: 131.1163 - val_mae: 8.3845\n",
      "Epoch 108/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 317.3726 - mae: 13.5548 - val_loss: 120.5339 - val_mae: 8.0553\n",
      "Epoch 109/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 309.0798 - mae: 13.5155 - val_loss: 120.4086 - val_mae: 7.9022\n",
      "Epoch 110/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 315.7111 - mae: 13.6763 - val_loss: 129.4475 - val_mae: 8.3942\n",
      "Epoch 111/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 338.9133 - mae: 13.8801 - val_loss: 124.7862 - val_mae: 8.2414\n",
      "Epoch 112/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 318.7978 - mae: 13.6923 - val_loss: 138.6575 - val_mae: 8.8336\n",
      "Epoch 113/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 326.0173 - mae: 13.7864 - val_loss: 124.8761 - val_mae: 8.2510\n",
      "Epoch 114/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 324.8383 - mae: 13.7483 - val_loss: 123.6259 - val_mae: 8.1228\n",
      "Epoch 115/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 311.3102 - mae: 13.6808 - val_loss: 133.7728 - val_mae: 8.5975\n",
      "Epoch 116/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 308.6004 - mae: 13.5290 - val_loss: 142.4624 - val_mae: 8.8358\n",
      "Epoch 117/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 308.7296 - mae: 13.3002 - val_loss: 127.4151 - val_mae: 8.2956\n",
      "Epoch 118/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 320.1373 - mae: 13.7515 - val_loss: 156.2567 - val_mae: 9.6653\n",
      "Epoch 119/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 307.6451 - mae: 13.5010 - val_loss: 120.7088 - val_mae: 7.9574\n",
      "Epoch 120/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 322.4432 - mae: 13.5285 - val_loss: 122.0827 - val_mae: 8.1322\n",
      "Epoch 121/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 295.8843 - mae: 13.2989 - val_loss: 116.3376 - val_mae: 7.7810\n",
      "Epoch 122/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 312.9698 - mae: 13.4961 - val_loss: 113.8300 - val_mae: 7.6948\n",
      "Epoch 123/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 299.5296 - mae: 13.2000 - val_loss: 124.3202 - val_mae: 8.2333\n",
      "Epoch 124/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 319.3374 - mae: 13.7010 - val_loss: 114.9340 - val_mae: 7.8490\n",
      "Epoch 125/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 300.6008 - mae: 13.3737 - val_loss: 122.1435 - val_mae: 8.0026\n",
      "Epoch 126/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 319.6360 - mae: 13.7124 - val_loss: 123.5996 - val_mae: 8.1416\n",
      "Epoch 127/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 312.9887 - mae: 13.4856 - val_loss: 133.0770 - val_mae: 8.3099\n",
      "Epoch 128/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 322.1335 - mae: 13.6446 - val_loss: 148.9498 - val_mae: 9.1124\n",
      "Epoch 129/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 298.6696 - mae: 13.2829 - val_loss: 119.2755 - val_mae: 8.0055\n",
      "Epoch 130/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 303.5416 - mae: 13.3491 - val_loss: 139.9199 - val_mae: 8.8166\n",
      "Epoch 131/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 315.8370 - mae: 13.6740 - val_loss: 143.6456 - val_mae: 8.8123\n",
      "Epoch 132/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 300.8272 - mae: 13.2419 - val_loss: 126.3942 - val_mae: 8.3112\n",
      "Epoch 133/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 304.8841 - mae: 13.3031 - val_loss: 121.0906 - val_mae: 8.0149\n",
      "Epoch 134/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 290.6244 - mae: 13.0649 - val_loss: 160.3404 - val_mae: 9.6080\n",
      "Epoch 135/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 301.1198 - mae: 13.5671 - val_loss: 134.2180 - val_mae: 8.6003\n",
      "Epoch 136/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 288.9705 - mae: 13.0833 - val_loss: 119.7543 - val_mae: 8.0267\n",
      "Epoch 137/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 286.4937 - mae: 13.0663 - val_loss: 132.3125 - val_mae: 8.5568\n",
      "Epoch 138/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 285.1163 - mae: 13.0787 - val_loss: 120.5286 - val_mae: 8.0368\n",
      "Epoch 139/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 295.2047 - mae: 13.1503 - val_loss: 133.4126 - val_mae: 8.6370\n",
      "Epoch 140/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 288.5464 - mae: 13.0212 - val_loss: 131.7494 - val_mae: 8.1928\n",
      "Epoch 141/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 286.6237 - mae: 12.8551 - val_loss: 113.8574 - val_mae: 7.6895\n",
      "Epoch 142/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 296.7674 - mae: 13.2922 - val_loss: 117.7130 - val_mae: 7.8214\n",
      "Patience 20: Early stopping occurred at epoch 141\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124.7009 - mae: 7.7027\n",
      "Patience 20: Validation MAE: 7.69\n",
      "Patience 20: Validation Loss: 113.83\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1876.9222 - mae: 31.4649 - val_loss: 301.3138 - val_mae: 13.9566\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 700.0141 - mae: 21.0930 - val_loss: 305.3522 - val_mae: 13.0552\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 577.7161 - mae: 18.7297 - val_loss: 209.5691 - val_mae: 11.2836\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 531.1990 - mae: 18.0633 - val_loss: 184.1343 - val_mae: 10.3073\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 507.2228 - mae: 17.4941 - val_loss: 180.7623 - val_mae: 10.2477\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 480.3583 - mae: 16.8652 - val_loss: 208.8700 - val_mae: 11.0452\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 438.1623 - mae: 16.4411 - val_loss: 147.5519 - val_mae: 8.9900\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 443.8482 - mae: 16.3388 - val_loss: 152.4628 - val_mae: 9.1495\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 419.5518 - mae: 15.9907 - val_loss: 156.7365 - val_mae: 9.5192\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 431.5641 - mae: 16.2390 - val_loss: 145.0159 - val_mae: 8.9589\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 443.7361 - mae: 16.2752 - val_loss: 150.4066 - val_mae: 9.1634\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 435.8438 - mae: 16.3061 - val_loss: 147.7105 - val_mae: 8.9189\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 427.7594 - mae: 16.0325 - val_loss: 152.4931 - val_mae: 9.4034\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 433.2174 - mae: 16.1470 - val_loss: 139.0416 - val_mae: 8.7774\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 400.2142 - mae: 15.4876 - val_loss: 161.6048 - val_mae: 9.7716\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 431.6516 - mae: 16.1009 - val_loss: 138.4038 - val_mae: 8.6944\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 415.5441 - mae: 15.8172 - val_loss: 150.1119 - val_mae: 9.1879\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 431.5996 - mae: 16.0415 - val_loss: 151.7637 - val_mae: 9.4136\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 436.8877 - mae: 16.0629 - val_loss: 141.0081 - val_mae: 8.8772\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 404.2597 - mae: 15.7131 - val_loss: 148.4195 - val_mae: 8.9727\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 411.2794 - mae: 15.8347 - val_loss: 147.2501 - val_mae: 9.1065\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 406.7170 - mae: 15.8055 - val_loss: 140.5763 - val_mae: 8.9217\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 394.1306 - mae: 15.4568 - val_loss: 171.1830 - val_mae: 9.8379\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 421.6788 - mae: 16.0920 - val_loss: 161.0085 - val_mae: 9.6727\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 410.8395 - mae: 15.6559 - val_loss: 142.1544 - val_mae: 8.8588\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 407.3271 - mae: 15.6195 - val_loss: 139.9141 - val_mae: 8.7481\n",
      "Patience 10: Early stopping occurred at epoch 25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.3358 - mae: 8.7960\n",
      "Patience 10: Validation MAE: 8.69\n",
      "Patience 10: Validation Loss: 138.40\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 118.5138, MAE = 8.0349, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 116.7564, MAE = 7.8032, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 20: Loss = 113.8299, MAE = 7.6948, Early Stopping Occurred: True, Early Stopping Epoch: 141\n",
      "Patience 10: Loss = 138.4038, MAE = 8.6944, Early Stopping Occurred: True, Early Stopping Epoch: 25\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "results150_16 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    sbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    sbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_{}.keras'.format(patience), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = sbp_model.fit(\n",
    "        X_train_combined, SBP_Y_train_combined,\n",
    "        epochs=150,\n",
    "        batch_size=16,\n",
    "        validation_data=(X_test_combined, SBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = sbp_model.evaluate(X_test_combined, SBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    results150_16.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in results150_16:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2280.1377 - mae: 33.8386 - val_loss: 333.7203 - val_mae: 14.0134\n",
      "Epoch 2/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 792.8716 - mae: 22.2560 - val_loss: 340.1787 - val_mae: 13.8134\n",
      "Epoch 3/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 768.9003 - mae: 21.5037 - val_loss: 272.3614 - val_mae: 13.1152\n",
      "Epoch 4/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 727.7990 - mae: 21.3326 - val_loss: 242.8689 - val_mae: 12.2463\n",
      "Epoch 5/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 709.6664 - mae: 20.9471 - val_loss: 231.8986 - val_mae: 12.0533\n",
      "Epoch 6/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 692.4095 - mae: 20.6968 - val_loss: 208.5451 - val_mae: 11.1042\n",
      "Epoch 7/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 667.1035 - mae: 20.3108 - val_loss: 197.4448 - val_mae: 10.7540\n",
      "Epoch 8/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 653.3976 - mae: 20.0144 - val_loss: 225.4375 - val_mae: 11.6645\n",
      "Epoch 9/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 583.3227 - mae: 19.0326 - val_loss: 174.1469 - val_mae: 9.9341\n",
      "Epoch 10/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 576.0007 - mae: 18.8713 - val_loss: 154.4599 - val_mae: 9.3927\n",
      "Epoch 11/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 589.9500 - mae: 19.0692 - val_loss: 209.9913 - val_mae: 11.6572\n",
      "Epoch 12/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 557.2850 - mae: 18.4388 - val_loss: 166.6298 - val_mae: 9.9239\n",
      "Epoch 13/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 546.8823 - mae: 18.3298 - val_loss: 153.4888 - val_mae: 9.4431\n",
      "Epoch 14/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 523.2391 - mae: 18.0828 - val_loss: 152.6237 - val_mae: 9.1789\n",
      "Epoch 15/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 556.9239 - mae: 18.3463 - val_loss: 195.5996 - val_mae: 11.2137\n",
      "Epoch 16/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 559.7215 - mae: 18.5662 - val_loss: 151.5599 - val_mae: 9.3051\n",
      "Epoch 17/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 545.7963 - mae: 18.2009 - val_loss: 210.6814 - val_mae: 11.4823\n",
      "Epoch 18/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 514.2181 - mae: 17.8397 - val_loss: 142.3555 - val_mae: 8.9215\n",
      "Epoch 19/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 536.1064 - mae: 18.1436 - val_loss: 158.8870 - val_mae: 9.7615\n",
      "Epoch 20/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 520.3006 - mae: 17.9634 - val_loss: 141.0212 - val_mae: 8.8930\n",
      "Epoch 21/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 541.5349 - mae: 18.1867 - val_loss: 196.8177 - val_mae: 11.0340\n",
      "Epoch 22/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 538.4099 - mae: 17.9145 - val_loss: 147.9227 - val_mae: 9.2059\n",
      "Epoch 23/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 519.3884 - mae: 17.8120 - val_loss: 201.6402 - val_mae: 11.3925\n",
      "Epoch 24/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 551.8745 - mae: 18.1128 - val_loss: 154.4498 - val_mae: 9.5864\n",
      "Epoch 25/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 497.1566 - mae: 17.4156 - val_loss: 139.6111 - val_mae: 8.8248\n",
      "Epoch 26/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 508.9669 - mae: 17.6251 - val_loss: 140.1853 - val_mae: 8.8171\n",
      "Epoch 27/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 482.0930 - mae: 17.1169 - val_loss: 188.3857 - val_mae: 10.9722\n",
      "Epoch 28/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 516.0260 - mae: 17.8193 - val_loss: 165.8497 - val_mae: 9.9754\n",
      "Epoch 29/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 534.5189 - mae: 17.8661 - val_loss: 184.8462 - val_mae: 10.6596\n",
      "Epoch 30/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 500.8153 - mae: 17.3104 - val_loss: 152.8574 - val_mae: 9.5872\n",
      "Epoch 31/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 491.8854 - mae: 17.3137 - val_loss: 135.7740 - val_mae: 8.6544\n",
      "Epoch 32/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 514.6869 - mae: 17.7389 - val_loss: 144.4616 - val_mae: 9.1759\n",
      "Epoch 33/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 496.6248 - mae: 17.4143 - val_loss: 132.6091 - val_mae: 8.5767\n",
      "Epoch 34/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 502.8404 - mae: 17.5016 - val_loss: 273.6699 - val_mae: 13.7427\n",
      "Epoch 35/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 494.5392 - mae: 17.2989 - val_loss: 164.0146 - val_mae: 9.9661\n",
      "Epoch 36/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 465.1809 - mae: 16.7786 - val_loss: 168.4209 - val_mae: 10.0529\n",
      "Epoch 37/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 502.4316 - mae: 17.4115 - val_loss: 139.2025 - val_mae: 8.9682\n",
      "Epoch 38/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 489.2167 - mae: 17.2847 - val_loss: 159.5295 - val_mae: 9.8139\n",
      "Epoch 39/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 491.3514 - mae: 17.2938 - val_loss: 158.3985 - val_mae: 9.7000\n",
      "Epoch 40/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 470.1932 - mae: 16.9311 - val_loss: 162.3676 - val_mae: 9.8026\n",
      "Epoch 41/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 477.0784 - mae: 16.9800 - val_loss: 146.9765 - val_mae: 9.2678\n",
      "Epoch 42/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 474.1043 - mae: 17.1525 - val_loss: 175.4935 - val_mae: 10.5016\n",
      "Epoch 43/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 480.4619 - mae: 16.9734 - val_loss: 136.7550 - val_mae: 8.7725\n",
      "Epoch 44/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 486.8416 - mae: 17.2771 - val_loss: 155.5166 - val_mae: 9.7424\n",
      "Epoch 45/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 483.4562 - mae: 17.2845 - val_loss: 161.8037 - val_mae: 9.9048\n",
      "Epoch 46/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 471.1229 - mae: 16.8483 - val_loss: 146.1729 - val_mae: 9.2215\n",
      "Epoch 47/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 470.7024 - mae: 16.9694 - val_loss: 136.3081 - val_mae: 8.8072\n",
      "Epoch 48/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 484.6247 - mae: 17.2443 - val_loss: 132.0243 - val_mae: 8.6056\n",
      "Epoch 49/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 483.5119 - mae: 17.0470 - val_loss: 143.8204 - val_mae: 9.1540\n",
      "Epoch 50/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 440.5092 - mae: 16.3598 - val_loss: 129.8629 - val_mae: 8.3289\n",
      "Epoch 51/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 466.2134 - mae: 16.9474 - val_loss: 141.1738 - val_mae: 8.9424\n",
      "Epoch 52/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 456.9102 - mae: 16.8241 - val_loss: 177.1059 - val_mae: 10.4752\n",
      "Epoch 53/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 480.4449 - mae: 16.9043 - val_loss: 134.2092 - val_mae: 8.6252\n",
      "Epoch 54/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459.9328 - mae: 16.8396 - val_loss: 152.5141 - val_mae: 9.4907\n",
      "Epoch 55/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 490.8947 - mae: 17.2851 - val_loss: 188.8198 - val_mae: 10.8560\n",
      "Epoch 56/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.1435 - mae: 16.6432 - val_loss: 129.9809 - val_mae: 8.4908\n",
      "Epoch 57/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 472.7034 - mae: 16.8836 - val_loss: 135.2529 - val_mae: 8.7286\n",
      "Epoch 58/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 437.1914 - mae: 16.3063 - val_loss: 129.1808 - val_mae: 8.3537\n",
      "Epoch 59/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 455.2135 - mae: 16.5437 - val_loss: 147.0047 - val_mae: 9.2498\n",
      "Epoch 60/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 464.4547 - mae: 16.5640 - val_loss: 132.4621 - val_mae: 8.6566\n",
      "Epoch 61/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 438.0863 - mae: 16.5224 - val_loss: 189.8640 - val_mae: 11.0841\n",
      "Epoch 62/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 436.0587 - mae: 16.1566 - val_loss: 146.6134 - val_mae: 9.3187\n",
      "Epoch 63/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 448.5214 - mae: 16.3580 - val_loss: 136.9769 - val_mae: 8.7192\n",
      "Epoch 64/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 462.3197 - mae: 16.8630 - val_loss: 137.7551 - val_mae: 8.7676\n",
      "Epoch 65/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 449.7305 - mae: 16.4533 - val_loss: 134.8857 - val_mae: 8.6939\n",
      "Epoch 66/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 447.2135 - mae: 16.2700 - val_loss: 132.2357 - val_mae: 8.5095\n",
      "Epoch 67/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 450.9247 - mae: 16.5148 - val_loss: 181.7861 - val_mae: 10.8264\n",
      "Epoch 68/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 463.4554 - mae: 16.7567 - val_loss: 126.6122 - val_mae: 8.2876\n",
      "Epoch 69/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 438.9571 - mae: 16.2979 - val_loss: 152.6922 - val_mae: 9.3727\n",
      "Epoch 70/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 447.8096 - mae: 16.3832 - val_loss: 158.3075 - val_mae: 9.3773\n",
      "Epoch 71/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 453.4268 - mae: 16.4707 - val_loss: 128.8882 - val_mae: 8.4456\n",
      "Epoch 72/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450.9498 - mae: 16.5052 - val_loss: 131.8300 - val_mae: 8.5688\n",
      "Epoch 73/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.5720 - mae: 16.0691 - val_loss: 129.6459 - val_mae: 8.5218\n",
      "Epoch 74/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.8277 - mae: 16.1195 - val_loss: 128.5623 - val_mae: 8.2629\n",
      "Epoch 75/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431.2271 - mae: 16.1292 - val_loss: 248.4795 - val_mae: 13.0394\n",
      "Epoch 76/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 465.7650 - mae: 16.6722 - val_loss: 153.8260 - val_mae: 9.5615\n",
      "Epoch 77/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.9779 - mae: 16.3137 - val_loss: 154.7847 - val_mae: 9.6074\n",
      "Epoch 78/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 432.1183 - mae: 16.3433 - val_loss: 146.5102 - val_mae: 9.2533\n",
      "Epoch 79/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 443.4382 - mae: 16.4346 - val_loss: 148.8130 - val_mae: 9.3989\n",
      "Epoch 80/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 427.0029 - mae: 16.0898 - val_loss: 132.1725 - val_mae: 8.5990\n",
      "Epoch 81/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 471.1098 - mae: 16.6688 - val_loss: 131.7565 - val_mae: 8.5851\n",
      "Epoch 82/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.9790 - mae: 16.0696 - val_loss: 127.3609 - val_mae: 8.3654\n",
      "Epoch 83/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 438.4573 - mae: 16.2626 - val_loss: 129.4771 - val_mae: 8.4910\n",
      "Epoch 84/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 432.8042 - mae: 16.1655 - val_loss: 140.9271 - val_mae: 9.0489\n",
      "Epoch 85/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 444.0395 - mae: 16.2843 - val_loss: 133.7168 - val_mae: 8.5675\n",
      "Epoch 86/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 421.9982 - mae: 16.0952 - val_loss: 136.9106 - val_mae: 8.8832\n",
      "Epoch 87/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433.1045 - mae: 16.1751 - val_loss: 130.4442 - val_mae: 8.5212\n",
      "Epoch 88/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 418.5585 - mae: 15.9931 - val_loss: 129.8140 - val_mae: 8.4899\n",
      "Epoch 89/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 442.9075 - mae: 16.3726 - val_loss: 129.7570 - val_mae: 8.4983\n",
      "Epoch 90/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 426.4318 - mae: 16.0654 - val_loss: 160.6781 - val_mae: 9.5977\n",
      "Epoch 91/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 453.2365 - mae: 16.5220 - val_loss: 126.1718 - val_mae: 8.2649\n",
      "Epoch 92/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 457.6490 - mae: 16.5076 - val_loss: 147.7948 - val_mae: 9.2006\n",
      "Epoch 93/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 423.7473 - mae: 15.8859 - val_loss: 131.7694 - val_mae: 8.6221\n",
      "Epoch 94/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410.7655 - mae: 15.7427 - val_loss: 166.1312 - val_mae: 10.0871\n",
      "Epoch 95/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.6706 - mae: 16.4832 - val_loss: 127.1599 - val_mae: 8.4108\n",
      "Epoch 96/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 405.5634 - mae: 15.8071 - val_loss: 129.8410 - val_mae: 8.5065\n",
      "Epoch 97/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 435.0314 - mae: 16.3518 - val_loss: 154.0548 - val_mae: 9.7048\n",
      "Epoch 98/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 424.2828 - mae: 16.1234 - val_loss: 130.3032 - val_mae: 8.5489\n",
      "Epoch 99/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 437.5990 - mae: 16.1009 - val_loss: 122.7126 - val_mae: 8.2430\n",
      "Epoch 100/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 426.6887 - mae: 16.1366 - val_loss: 158.1342 - val_mae: 9.8451\n",
      "Epoch 101/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 401.6237 - mae: 15.4749 - val_loss: 127.9472 - val_mae: 8.4676\n",
      "Epoch 102/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417.3278 - mae: 15.7731 - val_loss: 146.1357 - val_mae: 9.2566\n",
      "Epoch 103/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 437.5511 - mae: 16.3786 - val_loss: 198.1897 - val_mae: 11.3120\n",
      "Epoch 104/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 438.5270 - mae: 16.3032 - val_loss: 125.1189 - val_mae: 8.3199\n",
      "Epoch 105/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 426.8915 - mae: 15.8560 - val_loss: 175.4367 - val_mae: 10.5590\n",
      "Epoch 106/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 437.8232 - mae: 16.2196 - val_loss: 122.5477 - val_mae: 8.1868\n",
      "Epoch 107/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 431.9828 - mae: 16.2032 - val_loss: 135.1576 - val_mae: 8.7045\n",
      "Epoch 108/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.5522 - mae: 15.8384 - val_loss: 132.2975 - val_mae: 8.4288\n",
      "Epoch 109/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 437.0091 - mae: 16.1579 - val_loss: 138.9233 - val_mae: 8.9200\n",
      "Epoch 110/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 418.0062 - mae: 15.9094 - val_loss: 151.4591 - val_mae: 9.2971\n",
      "Epoch 111/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 405.2076 - mae: 15.6014 - val_loss: 167.2172 - val_mae: 10.2148\n",
      "Epoch 112/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.7946 - mae: 16.0316 - val_loss: 148.6095 - val_mae: 9.5152\n",
      "Epoch 113/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 415.1779 - mae: 15.8538 - val_loss: 148.3492 - val_mae: 9.2405\n",
      "Epoch 114/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 412.9646 - mae: 15.7863 - val_loss: 123.8834 - val_mae: 8.2667\n",
      "Epoch 115/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431.5856 - mae: 16.1964 - val_loss: 127.1962 - val_mae: 8.4647\n",
      "Epoch 116/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.9975 - mae: 15.6941 - val_loss: 144.7333 - val_mae: 9.2970\n",
      "Epoch 117/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.3774 - mae: 15.8859 - val_loss: 137.0566 - val_mae: 8.7893\n",
      "Epoch 118/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 412.7879 - mae: 15.7136 - val_loss: 131.4982 - val_mae: 8.6153\n",
      "Epoch 119/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.0301 - mae: 15.9880 - val_loss: 136.3848 - val_mae: 8.8153\n",
      "Epoch 120/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.7934 - mae: 15.9340 - val_loss: 138.6530 - val_mae: 8.9979\n",
      "Epoch 121/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 402.6508 - mae: 15.6630 - val_loss: 146.3952 - val_mae: 9.3552\n",
      "Epoch 122/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 419.9599 - mae: 15.7992 - val_loss: 126.0306 - val_mae: 8.3634\n",
      "Epoch 123/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.7060 - mae: 16.0122 - val_loss: 146.2124 - val_mae: 9.1346\n",
      "Epoch 124/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 411.7252 - mae: 15.7748 - val_loss: 125.4754 - val_mae: 8.2870\n",
      "Epoch 125/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.7224 - mae: 15.7763 - val_loss: 123.2318 - val_mae: 8.1645\n",
      "Epoch 126/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 411.4289 - mae: 15.7892 - val_loss: 137.0243 - val_mae: 8.8451\n",
      "Epoch 127/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 420.6984 - mae: 16.0304 - val_loss: 139.6676 - val_mae: 8.9520\n",
      "Epoch 128/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 395.8932 - mae: 15.6516 - val_loss: 148.8867 - val_mae: 9.4085\n",
      "Epoch 129/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.2374 - mae: 15.8329 - val_loss: 124.0828 - val_mae: 8.2654\n",
      "Epoch 130/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 426.4421 - mae: 16.0154 - val_loss: 138.1317 - val_mae: 8.9656\n",
      "Epoch 131/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 398.8306 - mae: 15.6166 - val_loss: 121.7834 - val_mae: 8.1794\n",
      "Epoch 132/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.7430 - mae: 15.9346 - val_loss: 129.3848 - val_mae: 8.5905\n",
      "Epoch 133/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 372.0468 - mae: 15.0522 - val_loss: 122.5517 - val_mae: 8.1530\n",
      "Epoch 134/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.8605 - mae: 15.6746 - val_loss: 139.1240 - val_mae: 8.9324\n",
      "Epoch 135/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 397.1106 - mae: 15.4926 - val_loss: 126.5254 - val_mae: 8.2752\n",
      "Epoch 136/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409.4168 - mae: 15.5283 - val_loss: 126.6109 - val_mae: 8.3238\n",
      "Epoch 137/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 399.9111 - mae: 15.6312 - val_loss: 148.9771 - val_mae: 9.3036\n",
      "Epoch 138/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.1555 - mae: 15.6405 - val_loss: 148.4648 - val_mae: 9.3432\n",
      "Epoch 139/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.1864 - mae: 15.6046 - val_loss: 182.4265 - val_mae: 10.8593\n",
      "Epoch 140/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389.4303 - mae: 15.4662 - val_loss: 123.4218 - val_mae: 8.2795\n",
      "Epoch 141/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.9547 - mae: 15.9621 - val_loss: 124.4014 - val_mae: 8.3168\n",
      "Epoch 142/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391.4699 - mae: 15.2544 - val_loss: 130.3466 - val_mae: 8.4764\n",
      "Epoch 143/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 394.1534 - mae: 15.5311 - val_loss: 127.5677 - val_mae: 8.5204\n",
      "Epoch 144/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 395.9983 - mae: 15.4905 - val_loss: 133.2059 - val_mae: 8.4242\n",
      "Epoch 145/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 412.2787 - mae: 15.4502 - val_loss: 122.6650 - val_mae: 8.1875\n",
      "Epoch 146/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.9314 - mae: 15.4658 - val_loss: 131.1512 - val_mae: 8.6048\n",
      "Epoch 147/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385.3355 - mae: 15.2551 - val_loss: 125.8372 - val_mae: 8.3156\n",
      "Epoch 148/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 408.6689 - mae: 15.5014 - val_loss: 120.1140 - val_mae: 8.0962\n",
      "Epoch 149/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.4190 - mae: 15.1843 - val_loss: 124.5907 - val_mae: 8.2884\n",
      "Epoch 150/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 415.7014 - mae: 15.7474 - val_loss: 135.8294 - val_mae: 8.8361\n",
      "Epoch 151/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.4931 - mae: 15.4417 - val_loss: 122.5344 - val_mae: 8.2046\n",
      "Epoch 152/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.3605 - mae: 15.3666 - val_loss: 127.2548 - val_mae: 8.4177\n",
      "Epoch 153/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.0177 - mae: 15.2014 - val_loss: 135.8251 - val_mae: 8.6396\n",
      "Epoch 154/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 397.9318 - mae: 15.3704 - val_loss: 126.0039 - val_mae: 8.2954\n",
      "Epoch 155/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399.0060 - mae: 15.3420 - val_loss: 126.4923 - val_mae: 8.4211\n",
      "Epoch 156/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 384.4144 - mae: 15.2000 - val_loss: 120.3719 - val_mae: 8.0814\n",
      "Epoch 157/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410.3700 - mae: 15.7576 - val_loss: 123.0068 - val_mae: 8.1771\n",
      "Epoch 158/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.9879 - mae: 14.9866 - val_loss: 147.0998 - val_mae: 9.4032\n",
      "Epoch 159/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 395.8907 - mae: 15.3500 - val_loss: 118.2974 - val_mae: 8.0003\n",
      "Epoch 160/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378.2979 - mae: 14.8567 - val_loss: 126.9590 - val_mae: 8.4480\n",
      "Epoch 161/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382.6310 - mae: 15.2114 - val_loss: 130.0893 - val_mae: 8.6174\n",
      "Epoch 162/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 385.6936 - mae: 15.1346 - val_loss: 120.0031 - val_mae: 7.9965\n",
      "Epoch 163/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380.0060 - mae: 15.0577 - val_loss: 152.1183 - val_mae: 9.6067\n",
      "Epoch 164/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387.5356 - mae: 15.0980 - val_loss: 129.6705 - val_mae: 8.5292\n",
      "Epoch 165/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 411.2201 - mae: 15.6111 - val_loss: 125.1498 - val_mae: 8.3019\n",
      "Epoch 166/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 388.7647 - mae: 15.3302 - val_loss: 125.2441 - val_mae: 8.3025\n",
      "Epoch 167/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 383.9336 - mae: 15.2225 - val_loss: 118.3425 - val_mae: 7.9851\n",
      "Epoch 168/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 393.2463 - mae: 15.1955 - val_loss: 120.5105 - val_mae: 8.0042\n",
      "Epoch 169/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 387.3157 - mae: 15.2421 - val_loss: 124.4167 - val_mae: 8.2714\n",
      "Epoch 170/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382.4422 - mae: 15.2235 - val_loss: 129.7838 - val_mae: 8.6272\n",
      "Epoch 171/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 367.1113 - mae: 15.0046 - val_loss: 122.8726 - val_mae: 8.2682\n",
      "Epoch 172/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 383.1465 - mae: 15.2278 - val_loss: 141.4322 - val_mae: 9.0677\n",
      "Epoch 173/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 403.0359 - mae: 15.5833 - val_loss: 148.0942 - val_mae: 9.4691\n",
      "Epoch 174/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 385.4721 - mae: 15.1589 - val_loss: 123.0437 - val_mae: 8.1411\n",
      "Epoch 175/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 381.1121 - mae: 15.0255 - val_loss: 126.9268 - val_mae: 8.3715\n",
      "Epoch 176/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 396.8555 - mae: 15.5121 - val_loss: 118.0102 - val_mae: 8.0235\n",
      "Epoch 177/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 379.9696 - mae: 15.0323 - val_loss: 129.6946 - val_mae: 8.5991\n",
      "Epoch 178/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375.0260 - mae: 15.0291 - val_loss: 117.3129 - val_mae: 7.9517\n",
      "Epoch 179/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 364.1320 - mae: 14.9594 - val_loss: 123.7182 - val_mae: 8.2237\n",
      "Epoch 180/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 359.2389 - mae: 14.5688 - val_loss: 142.3854 - val_mae: 9.1855\n",
      "Epoch 181/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.2764 - mae: 15.3170 - val_loss: 120.8978 - val_mae: 8.1745\n",
      "Epoch 182/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379.3549 - mae: 15.1948 - val_loss: 121.1217 - val_mae: 8.1030\n",
      "Epoch 183/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375.3688 - mae: 14.9635 - val_loss: 119.6193 - val_mae: 8.0283\n",
      "Epoch 184/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 360.8474 - mae: 14.7110 - val_loss: 127.3842 - val_mae: 8.4769\n",
      "Epoch 185/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.9551 - mae: 14.8247 - val_loss: 120.0615 - val_mae: 8.0848\n",
      "Epoch 186/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.4262 - mae: 14.6669 - val_loss: 129.4449 - val_mae: 8.5319\n",
      "Epoch 187/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376.2603 - mae: 14.8751 - val_loss: 126.8812 - val_mae: 8.4712\n",
      "Epoch 188/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377.2997 - mae: 15.0008 - val_loss: 117.0957 - val_mae: 7.9254\n",
      "Epoch 189/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 363.5094 - mae: 14.7847 - val_loss: 134.5821 - val_mae: 8.7489\n",
      "Epoch 190/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 366.3233 - mae: 14.7962 - val_loss: 118.7918 - val_mae: 8.0084\n",
      "Epoch 191/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.8891 - mae: 14.7369 - val_loss: 129.4026 - val_mae: 8.5945\n",
      "Epoch 192/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 385.6619 - mae: 15.1435 - val_loss: 118.4915 - val_mae: 7.9978\n",
      "Epoch 193/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.6956 - mae: 14.8435 - val_loss: 151.2537 - val_mae: 9.4428\n",
      "Epoch 194/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 356.4026 - mae: 14.8795 - val_loss: 127.2366 - val_mae: 8.3302\n",
      "Epoch 195/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361.0763 - mae: 14.7345 - val_loss: 127.1423 - val_mae: 8.4963\n",
      "Epoch 196/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 355.4010 - mae: 14.5397 - val_loss: 134.1554 - val_mae: 8.8288\n",
      "Epoch 197/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 404.1941 - mae: 15.2751 - val_loss: 144.2143 - val_mae: 9.0805\n",
      "Epoch 198/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.8242 - mae: 14.4833 - val_loss: 119.0621 - val_mae: 8.0442\n",
      "Epoch 199/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.7820 - mae: 14.7831 - val_loss: 131.8164 - val_mae: 8.4835\n",
      "Epoch 200/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 334.6429 - mae: 14.1185 - val_loss: 130.3653 - val_mae: 8.5017\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.0009 - mae: 8.0986\n",
      "Patience 40: Validation MAE: 7.93\n",
      "Patience 40: Validation Loss: 117.10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1780.9294 - mae: 30.0941 - val_loss: 469.2223 - val_mae: 15.9226\n",
      "Epoch 2/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 666.9417 - mae: 20.3434 - val_loss: 285.4787 - val_mae: 14.0959\n",
      "Epoch 3/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 580.7516 - mae: 19.0815 - val_loss: 253.1896 - val_mae: 12.0590\n",
      "Epoch 4/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 549.6131 - mae: 18.4212 - val_loss: 229.7599 - val_mae: 11.4688\n",
      "Epoch 5/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 528.1552 - mae: 17.9181 - val_loss: 178.8627 - val_mae: 10.0890\n",
      "Epoch 6/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 502.8707 - mae: 17.3966 - val_loss: 165.9799 - val_mae: 9.6128\n",
      "Epoch 7/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.1499 - mae: 16.7243 - val_loss: 169.5728 - val_mae: 9.8497\n",
      "Epoch 8/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 451.9594 - mae: 16.6652 - val_loss: 160.6791 - val_mae: 9.5079\n",
      "Epoch 9/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.9881 - mae: 16.1291 - val_loss: 188.9608 - val_mae: 10.4409\n",
      "Epoch 10/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 452.4848 - mae: 16.5637 - val_loss: 153.2083 - val_mae: 9.2752\n",
      "Epoch 11/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 446.4175 - mae: 16.2786 - val_loss: 155.1161 - val_mae: 9.2675\n",
      "Epoch 12/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.5762 - mae: 16.1590 - val_loss: 147.2948 - val_mae: 9.0858\n",
      "Epoch 13/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.8641 - mae: 16.3208 - val_loss: 155.1074 - val_mae: 9.3014\n",
      "Epoch 14/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.5101 - mae: 15.8333 - val_loss: 144.3426 - val_mae: 8.9323\n",
      "Epoch 15/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428.2927 - mae: 15.9536 - val_loss: 164.9262 - val_mae: 9.6175\n",
      "Epoch 16/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.3768 - mae: 16.2685 - val_loss: 151.0070 - val_mae: 9.2963\n",
      "Epoch 17/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.3507 - mae: 15.7499 - val_loss: 143.1802 - val_mae: 8.9253\n",
      "Epoch 18/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 402.8793 - mae: 15.5263 - val_loss: 135.4715 - val_mae: 8.5427\n",
      "Epoch 19/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.6943 - mae: 15.7416 - val_loss: 154.1554 - val_mae: 9.2032\n",
      "Epoch 20/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 409.7329 - mae: 15.7129 - val_loss: 182.6706 - val_mae: 10.6419\n",
      "Epoch 21/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 420.7239 - mae: 15.8506 - val_loss: 146.5188 - val_mae: 9.0123\n",
      "Epoch 22/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 401.0062 - mae: 15.5234 - val_loss: 142.0785 - val_mae: 8.9366\n",
      "Epoch 23/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 426.6323 - mae: 15.9729 - val_loss: 139.5185 - val_mae: 8.7387\n",
      "Epoch 24/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 408.7145 - mae: 15.6707 - val_loss: 145.9906 - val_mae: 8.9969\n",
      "Epoch 25/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 404.5913 - mae: 15.4185 - val_loss: 155.1239 - val_mae: 9.4381\n",
      "Epoch 26/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386.0213 - mae: 15.2932 - val_loss: 170.9254 - val_mae: 9.8371\n",
      "Epoch 27/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.9985 - mae: 14.9138 - val_loss: 145.6681 - val_mae: 8.9113\n",
      "Epoch 28/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 405.8037 - mae: 15.5297 - val_loss: 143.5390 - val_mae: 8.7697\n",
      "Epoch 29/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.9588 - mae: 15.1094 - val_loss: 135.3070 - val_mae: 8.6385\n",
      "Epoch 30/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 414.1460 - mae: 15.7615 - val_loss: 148.7635 - val_mae: 8.8770\n",
      "Epoch 31/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379.2879 - mae: 14.8669 - val_loss: 134.3332 - val_mae: 8.4874\n",
      "Epoch 32/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 385.8914 - mae: 15.0449 - val_loss: 143.1097 - val_mae: 8.8644\n",
      "Epoch 33/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 373.0636 - mae: 15.0803 - val_loss: 148.9783 - val_mae: 9.0000\n",
      "Epoch 34/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 406.3968 - mae: 15.4287 - val_loss: 135.3417 - val_mae: 8.5869\n",
      "Epoch 35/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378.9610 - mae: 15.2521 - val_loss: 144.2927 - val_mae: 8.9474\n",
      "Epoch 36/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376.6199 - mae: 15.0150 - val_loss: 134.9903 - val_mae: 8.5967\n",
      "Epoch 37/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377.8598 - mae: 14.9792 - val_loss: 150.2580 - val_mae: 9.1899\n",
      "Epoch 38/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 367.5245 - mae: 14.8587 - val_loss: 138.6163 - val_mae: 8.7575\n",
      "Epoch 39/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 392.2858 - mae: 15.4538 - val_loss: 135.2594 - val_mae: 8.5655\n",
      "Epoch 40/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 389.9826 - mae: 15.2735 - val_loss: 152.9417 - val_mae: 9.5183\n",
      "Epoch 41/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 364.9607 - mae: 14.7161 - val_loss: 130.5627 - val_mae: 8.4616\n",
      "Epoch 42/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386.8412 - mae: 15.2077 - val_loss: 132.6638 - val_mae: 8.5710\n",
      "Epoch 43/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387.5381 - mae: 15.1190 - val_loss: 143.2072 - val_mae: 9.1207\n",
      "Epoch 44/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.8455 - mae: 14.8941 - val_loss: 158.3466 - val_mae: 9.7626\n",
      "Epoch 45/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.9950 - mae: 15.4862 - val_loss: 136.4693 - val_mae: 8.7682\n",
      "Epoch 46/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.6379 - mae: 15.1360 - val_loss: 130.4892 - val_mae: 8.4702\n",
      "Epoch 47/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.8611 - mae: 15.4170 - val_loss: 130.5738 - val_mae: 8.3988\n",
      "Epoch 48/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 372.9283 - mae: 14.8871 - val_loss: 141.8905 - val_mae: 8.8793\n",
      "Epoch 49/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.1996 - mae: 15.0550 - val_loss: 154.3401 - val_mae: 9.3696\n",
      "Epoch 50/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 387.7911 - mae: 15.2996 - val_loss: 175.2824 - val_mae: 9.7657\n",
      "Epoch 51/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 392.0529 - mae: 15.3131 - val_loss: 154.8824 - val_mae: 9.3791\n",
      "Epoch 52/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.8759 - mae: 14.5745 - val_loss: 188.9818 - val_mae: 10.7093\n",
      "Epoch 53/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 364.9482 - mae: 14.7859 - val_loss: 201.7405 - val_mae: 11.2879\n",
      "Epoch 54/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379.4074 - mae: 14.9384 - val_loss: 131.1057 - val_mae: 8.2581\n",
      "Epoch 55/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376.1764 - mae: 14.9031 - val_loss: 162.1776 - val_mae: 9.6565\n",
      "Epoch 56/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 385.7140 - mae: 15.2660 - val_loss: 132.4477 - val_mae: 8.4828\n",
      "Epoch 57/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 378.1167 - mae: 15.0840 - val_loss: 141.4718 - val_mae: 8.8121\n",
      "Epoch 58/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.4601 - mae: 14.8692 - val_loss: 129.2925 - val_mae: 8.3833\n",
      "Epoch 59/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.8890 - mae: 14.9605 - val_loss: 127.6636 - val_mae: 8.3554\n",
      "Epoch 60/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.0231 - mae: 14.8253 - val_loss: 142.5769 - val_mae: 8.8585\n",
      "Epoch 61/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.5714 - mae: 14.7683 - val_loss: 135.1113 - val_mae: 8.5306\n",
      "Epoch 62/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.4261 - mae: 14.7904 - val_loss: 138.1121 - val_mae: 8.7782\n",
      "Epoch 63/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375.9306 - mae: 14.8744 - val_loss: 130.2055 - val_mae: 8.4981\n",
      "Epoch 64/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.2370 - mae: 14.7367 - val_loss: 124.4492 - val_mae: 8.1072\n",
      "Epoch 65/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.6552 - mae: 14.8601 - val_loss: 139.1937 - val_mae: 8.8679\n",
      "Epoch 66/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361.8550 - mae: 14.7532 - val_loss: 140.7145 - val_mae: 8.7389\n",
      "Epoch 67/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 367.5750 - mae: 14.8650 - val_loss: 133.6001 - val_mae: 8.4309\n",
      "Epoch 68/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 392.5273 - mae: 15.2465 - val_loss: 128.3258 - val_mae: 8.3594\n",
      "Epoch 69/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 357.5080 - mae: 14.6320 - val_loss: 124.6782 - val_mae: 8.2605\n",
      "Epoch 70/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361.1981 - mae: 14.4810 - val_loss: 127.6903 - val_mae: 8.2970\n",
      "Epoch 71/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.3719 - mae: 14.9438 - val_loss: 128.2836 - val_mae: 8.3264\n",
      "Epoch 72/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.1907 - mae: 14.8213 - val_loss: 132.2352 - val_mae: 8.5857\n",
      "Epoch 73/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.6785 - mae: 14.7044 - val_loss: 128.9063 - val_mae: 8.4437\n",
      "Epoch 74/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.3863 - mae: 14.7075 - val_loss: 127.4846 - val_mae: 8.1854\n",
      "Epoch 75/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 359.4232 - mae: 14.6630 - val_loss: 128.7348 - val_mae: 8.3651\n",
      "Epoch 76/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361.7395 - mae: 14.6256 - val_loss: 162.2640 - val_mae: 9.9378\n",
      "Epoch 77/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 372.8048 - mae: 14.9502 - val_loss: 141.0908 - val_mae: 8.8830\n",
      "Epoch 78/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 370.7837 - mae: 15.0086 - val_loss: 132.8824 - val_mae: 8.5812\n",
      "Epoch 79/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.4027 - mae: 14.5809 - val_loss: 132.1957 - val_mae: 8.4440\n",
      "Epoch 80/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.0714 - mae: 15.0418 - val_loss: 126.8785 - val_mae: 8.2103\n",
      "Epoch 81/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 350.8185 - mae: 14.3687 - val_loss: 130.8328 - val_mae: 8.5107\n",
      "Epoch 82/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 336.8601 - mae: 14.2257 - val_loss: 126.9765 - val_mae: 8.2594\n",
      "Epoch 83/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 349.8313 - mae: 14.3403 - val_loss: 153.6363 - val_mae: 9.3948\n",
      "Epoch 84/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.0458 - mae: 14.6107 - val_loss: 156.4932 - val_mae: 9.7120\n",
      "Epoch 85/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 359.9760 - mae: 14.4979 - val_loss: 145.9901 - val_mae: 8.9959\n",
      "Epoch 86/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.1385 - mae: 14.7109 - val_loss: 139.7564 - val_mae: 8.6906\n",
      "Epoch 87/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 341.0182 - mae: 14.1167 - val_loss: 150.2911 - val_mae: 9.2395\n",
      "Epoch 88/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 352.7887 - mae: 14.4968 - val_loss: 125.8685 - val_mae: 8.1298\n",
      "Epoch 89/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.3124 - mae: 14.7214 - val_loss: 137.8690 - val_mae: 8.8037\n",
      "Epoch 90/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 330.3788 - mae: 13.9588 - val_loss: 132.1289 - val_mae: 8.4734\n",
      "Epoch 91/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.6490 - mae: 14.5282 - val_loss: 132.7334 - val_mae: 8.4079\n",
      "Epoch 92/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 349.8936 - mae: 14.3128 - val_loss: 124.8951 - val_mae: 8.1588\n",
      "Epoch 93/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 341.3182 - mae: 14.2943 - val_loss: 141.1373 - val_mae: 8.9517\n",
      "Epoch 94/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 364.2118 - mae: 14.9003 - val_loss: 143.0443 - val_mae: 9.0847\n",
      "Patience 30: Early stopping occurred at epoch 93\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 134.9778 - mae: 8.0509\n",
      "Patience 30: Validation MAE: 8.11\n",
      "Patience 30: Validation Loss: 124.45\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1484.3425 - mae: 28.5188 - val_loss: 329.4319 - val_mae: 13.7714\n",
      "Epoch 2/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 671.6348 - mae: 20.3293 - val_loss: 341.6189 - val_mae: 13.7335\n",
      "Epoch 3/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 648.0273 - mae: 19.9921 - val_loss: 249.4077 - val_mae: 12.3803\n",
      "Epoch 4/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 577.8306 - mae: 18.9335 - val_loss: 221.7703 - val_mae: 11.4078\n",
      "Epoch 5/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 556.2218 - mae: 18.1150 - val_loss: 288.4288 - val_mae: 13.1034\n",
      "Epoch 6/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 516.1014 - mae: 17.6453 - val_loss: 291.9362 - val_mae: 13.4818\n",
      "Epoch 7/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 523.0342 - mae: 17.9857 - val_loss: 157.5112 - val_mae: 9.4688\n",
      "Epoch 8/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 502.1405 - mae: 17.5322 - val_loss: 365.0597 - val_mae: 15.9818\n",
      "Epoch 9/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 498.9614 - mae: 17.5495 - val_loss: 174.2081 - val_mae: 9.9022\n",
      "Epoch 10/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 462.9206 - mae: 16.8605 - val_loss: 149.4046 - val_mae: 9.1047\n",
      "Epoch 11/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 476.1545 - mae: 17.0728 - val_loss: 194.9875 - val_mae: 10.6710\n",
      "Epoch 12/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 443.6848 - mae: 16.4061 - val_loss: 171.7912 - val_mae: 10.0998\n",
      "Epoch 13/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 451.8063 - mae: 16.5228 - val_loss: 144.2262 - val_mae: 8.9553\n",
      "Epoch 14/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 475.2994 - mae: 16.7086 - val_loss: 148.2981 - val_mae: 9.1783\n",
      "Epoch 15/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 443.3233 - mae: 16.5926 - val_loss: 145.0891 - val_mae: 8.9578\n",
      "Epoch 16/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 438.1741 - mae: 16.1486 - val_loss: 141.7859 - val_mae: 8.8901\n",
      "Epoch 17/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433.3953 - mae: 16.2770 - val_loss: 166.5082 - val_mae: 9.8355\n",
      "Epoch 18/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 421.9375 - mae: 15.7618 - val_loss: 142.1144 - val_mae: 8.9631\n",
      "Epoch 19/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 443.5621 - mae: 16.3821 - val_loss: 177.5719 - val_mae: 10.3811\n",
      "Epoch 20/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 430.2721 - mae: 16.0821 - val_loss: 139.2176 - val_mae: 8.7352\n",
      "Epoch 21/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 435.6006 - mae: 16.1853 - val_loss: 162.9293 - val_mae: 9.7382\n",
      "Epoch 22/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 448.7410 - mae: 16.4748 - val_loss: 156.0924 - val_mae: 9.6358\n",
      "Epoch 23/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 420.1935 - mae: 15.8072 - val_loss: 137.0359 - val_mae: 8.6721\n",
      "Epoch 24/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 449.3836 - mae: 16.4581 - val_loss: 145.7036 - val_mae: 8.9603\n",
      "Epoch 25/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 435.5616 - mae: 16.3346 - val_loss: 151.9227 - val_mae: 9.4698\n",
      "Epoch 26/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 418.6010 - mae: 15.7817 - val_loss: 137.8680 - val_mae: 8.7268\n",
      "Epoch 27/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.3457 - mae: 16.0749 - val_loss: 158.6279 - val_mae: 9.4198\n",
      "Epoch 28/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 442.2827 - mae: 16.3693 - val_loss: 161.4520 - val_mae: 9.3899\n",
      "Epoch 29/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 445.4103 - mae: 16.5005 - val_loss: 140.1027 - val_mae: 8.8496\n",
      "Epoch 30/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 430.5746 - mae: 16.0589 - val_loss: 170.1382 - val_mae: 9.9896\n",
      "Epoch 31/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 409.8328 - mae: 15.6521 - val_loss: 153.2507 - val_mae: 9.2397\n",
      "Epoch 32/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.7689 - mae: 16.1057 - val_loss: 147.8842 - val_mae: 9.1320\n",
      "Epoch 33/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 440.0010 - mae: 16.1820 - val_loss: 141.5867 - val_mae: 8.7830\n",
      "Epoch 34/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 408.4489 - mae: 15.8167 - val_loss: 136.9442 - val_mae: 8.7316\n",
      "Epoch 35/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.6917 - mae: 16.0070 - val_loss: 266.3985 - val_mae: 13.2247\n",
      "Epoch 36/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.1931 - mae: 16.1216 - val_loss: 215.7878 - val_mae: 11.7786\n",
      "Epoch 37/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 402.1347 - mae: 15.7564 - val_loss: 133.6727 - val_mae: 8.6193\n",
      "Epoch 38/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 412.9568 - mae: 15.7040 - val_loss: 168.2645 - val_mae: 10.1563\n",
      "Epoch 39/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.7237 - mae: 15.8706 - val_loss: 143.0674 - val_mae: 8.8833\n",
      "Epoch 40/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.7357 - mae: 15.6247 - val_loss: 136.9560 - val_mae: 8.6135\n",
      "Epoch 41/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 414.2277 - mae: 15.6216 - val_loss: 159.9194 - val_mae: 9.7922\n",
      "Epoch 42/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399.9955 - mae: 15.6426 - val_loss: 161.6775 - val_mae: 9.6416\n",
      "Epoch 43/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.4980 - mae: 15.7774 - val_loss: 142.1418 - val_mae: 8.9736\n",
      "Epoch 44/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 411.2460 - mae: 15.6143 - val_loss: 154.9964 - val_mae: 9.5898\n",
      "Epoch 45/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 426.7343 - mae: 15.7003 - val_loss: 137.3146 - val_mae: 8.7767\n",
      "Epoch 46/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382.8061 - mae: 15.1641 - val_loss: 132.4721 - val_mae: 8.4793\n",
      "Epoch 47/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 407.9593 - mae: 15.5449 - val_loss: 145.2781 - val_mae: 9.0655\n",
      "Epoch 48/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433.9921 - mae: 16.0437 - val_loss: 141.8717 - val_mae: 8.7850\n",
      "Epoch 49/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.9901 - mae: 15.5280 - val_loss: 144.0057 - val_mae: 8.9506\n",
      "Epoch 50/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 393.3994 - mae: 15.3452 - val_loss: 171.0978 - val_mae: 9.9428\n",
      "Epoch 51/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.7541 - mae: 15.4525 - val_loss: 131.7027 - val_mae: 8.3764\n",
      "Epoch 52/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.2803 - mae: 15.5979 - val_loss: 147.4266 - val_mae: 9.0970\n",
      "Epoch 53/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.5402 - mae: 15.1472 - val_loss: 133.3254 - val_mae: 8.5883\n",
      "Epoch 54/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391.3871 - mae: 15.1004 - val_loss: 133.3912 - val_mae: 8.4792\n",
      "Epoch 55/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391.0758 - mae: 15.3598 - val_loss: 132.6332 - val_mae: 8.4555\n",
      "Epoch 56/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.9620 - mae: 15.0185 - val_loss: 131.0673 - val_mae: 8.4446\n",
      "Epoch 57/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.5867 - mae: 15.6101 - val_loss: 128.6360 - val_mae: 8.3610\n",
      "Epoch 58/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.7973 - mae: 15.5534 - val_loss: 135.9387 - val_mae: 8.7118\n",
      "Epoch 59/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.7164 - mae: 15.6359 - val_loss: 147.9769 - val_mae: 9.2764\n",
      "Epoch 60/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 412.5883 - mae: 15.5431 - val_loss: 148.6611 - val_mae: 9.1828\n",
      "Epoch 61/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386.8327 - mae: 15.1762 - val_loss: 172.8007 - val_mae: 10.1854\n",
      "Epoch 62/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 404.4437 - mae: 15.4874 - val_loss: 133.1493 - val_mae: 8.4933\n",
      "Epoch 63/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 383.8859 - mae: 15.2805 - val_loss: 167.4326 - val_mae: 9.9941\n",
      "Epoch 64/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 408.9198 - mae: 15.4034 - val_loss: 147.8434 - val_mae: 9.2220\n",
      "Epoch 65/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 384.3969 - mae: 15.0942 - val_loss: 130.9722 - val_mae: 8.4226\n",
      "Epoch 66/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 402.4989 - mae: 15.5166 - val_loss: 132.8101 - val_mae: 8.5413\n",
      "Epoch 67/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394.1452 - mae: 15.3555 - val_loss: 126.6594 - val_mae: 8.2237\n",
      "Epoch 68/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394.1664 - mae: 15.4379 - val_loss: 152.9793 - val_mae: 9.5381\n",
      "Epoch 69/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 402.2018 - mae: 15.5222 - val_loss: 131.6218 - val_mae: 8.5169\n",
      "Epoch 70/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 370.3724 - mae: 15.0364 - val_loss: 131.5786 - val_mae: 8.5100\n",
      "Epoch 71/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 389.7715 - mae: 15.3009 - val_loss: 130.6546 - val_mae: 8.4276\n",
      "Epoch 72/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389.4364 - mae: 15.4581 - val_loss: 130.3664 - val_mae: 8.3649\n",
      "Epoch 73/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 360.4761 - mae: 14.6479 - val_loss: 142.8069 - val_mae: 9.0288\n",
      "Epoch 74/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391.0229 - mae: 15.4251 - val_loss: 132.5193 - val_mae: 8.5681\n",
      "Epoch 75/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.8667 - mae: 15.0264 - val_loss: 143.2270 - val_mae: 9.1528\n",
      "Epoch 76/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377.0126 - mae: 15.0769 - val_loss: 126.4014 - val_mae: 8.3163\n",
      "Epoch 77/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 386.5894 - mae: 15.0881 - val_loss: 139.2607 - val_mae: 8.9306\n",
      "Epoch 78/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387.4723 - mae: 15.1005 - val_loss: 134.8973 - val_mae: 8.6956\n",
      "Epoch 79/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 370.9973 - mae: 15.0590 - val_loss: 135.9094 - val_mae: 8.6795\n",
      "Epoch 80/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.4362 - mae: 14.9163 - val_loss: 134.5017 - val_mae: 8.6283\n",
      "Epoch 81/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377.9846 - mae: 14.9783 - val_loss: 130.9859 - val_mae: 8.4247\n",
      "Epoch 82/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 372.8248 - mae: 15.0047 - val_loss: 127.4235 - val_mae: 8.2904\n",
      "Epoch 83/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 372.9381 - mae: 15.1085 - val_loss: 136.5325 - val_mae: 8.7866\n",
      "Epoch 84/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.0255 - mae: 14.9601 - val_loss: 127.8907 - val_mae: 8.4097\n",
      "Epoch 85/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.5616 - mae: 15.1801 - val_loss: 135.2067 - val_mae: 8.7503\n",
      "Epoch 86/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 385.3942 - mae: 14.9791 - val_loss: 141.5903 - val_mae: 8.9742\n",
      "Epoch 87/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.2352 - mae: 15.1207 - val_loss: 143.3805 - val_mae: 9.0276\n",
      "Epoch 88/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.2680 - mae: 14.9251 - val_loss: 133.0454 - val_mae: 8.5680\n",
      "Epoch 89/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.8406 - mae: 15.3697 - val_loss: 136.9455 - val_mae: 8.6924\n",
      "Epoch 90/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.3130 - mae: 15.1492 - val_loss: 134.9687 - val_mae: 8.4797\n",
      "Epoch 91/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 351.5302 - mae: 14.7577 - val_loss: 145.7339 - val_mae: 9.1021\n",
      "Epoch 92/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.9424 - mae: 15.2101 - val_loss: 134.9394 - val_mae: 8.7867\n",
      "Epoch 93/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 384.3562 - mae: 14.9299 - val_loss: 123.5643 - val_mae: 8.1035\n",
      "Epoch 94/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.5240 - mae: 14.8903 - val_loss: 126.8729 - val_mae: 8.3272\n",
      "Epoch 95/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386.2450 - mae: 15.1143 - val_loss: 133.8114 - val_mae: 8.5840\n",
      "Epoch 96/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.8175 - mae: 15.1709 - val_loss: 128.4027 - val_mae: 8.4053\n",
      "Epoch 97/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 355.4026 - mae: 14.6267 - val_loss: 125.4083 - val_mae: 8.2662\n",
      "Epoch 98/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376.9119 - mae: 15.1166 - val_loss: 128.5110 - val_mae: 8.3167\n",
      "Epoch 99/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379.2430 - mae: 14.8908 - val_loss: 125.0601 - val_mae: 8.2490\n",
      "Epoch 100/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.3359 - mae: 14.8347 - val_loss: 123.8474 - val_mae: 8.1764\n",
      "Epoch 101/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.8032 - mae: 14.8144 - val_loss: 133.0583 - val_mae: 8.6339\n",
      "Epoch 102/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.9086 - mae: 14.4209 - val_loss: 131.1485 - val_mae: 8.4529\n",
      "Epoch 103/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.0176 - mae: 14.6877 - val_loss: 147.7068 - val_mae: 9.2212\n",
      "Epoch 104/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.8291 - mae: 14.9224 - val_loss: 161.1408 - val_mae: 9.7915\n",
      "Epoch 105/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 370.2823 - mae: 14.7837 - val_loss: 126.1503 - val_mae: 8.2989\n",
      "Epoch 106/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 365.7514 - mae: 14.7773 - val_loss: 129.9610 - val_mae: 8.4410\n",
      "Epoch 107/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 361.4060 - mae: 14.7318 - val_loss: 128.0574 - val_mae: 8.3820\n",
      "Epoch 108/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.0500 - mae: 15.1779 - val_loss: 126.5493 - val_mae: 8.2081\n",
      "Epoch 109/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.9277 - mae: 14.6815 - val_loss: 134.1732 - val_mae: 8.6607\n",
      "Epoch 110/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.6621 - mae: 14.5862 - val_loss: 142.7960 - val_mae: 9.0218\n",
      "Epoch 111/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.1049 - mae: 14.8487 - val_loss: 129.5738 - val_mae: 8.4657\n",
      "Epoch 112/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 378.6949 - mae: 14.9731 - val_loss: 160.6269 - val_mae: 9.6746\n",
      "Epoch 113/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.1720 - mae: 15.0151 - val_loss: 131.2878 - val_mae: 8.5913\n",
      "Patience 20: Early stopping occurred at epoch 112\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 133.6743 - mae: 8.1132\n",
      "Patience 20: Validation MAE: 8.10\n",
      "Patience 20: Validation Loss: 123.56\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2469.4231 - mae: 34.9748 - val_loss: 322.8975 - val_mae: 14.1710\n",
      "Epoch 2/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 760.2532 - mae: 21.4333 - val_loss: 298.2663 - val_mae: 14.4489\n",
      "Epoch 3/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 674.2451 - mae: 20.4736 - val_loss: 253.5808 - val_mae: 12.9036\n",
      "Epoch 4/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 641.0300 - mae: 19.7687 - val_loss: 226.6847 - val_mae: 11.5087\n",
      "Epoch 5/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 609.6844 - mae: 19.2927 - val_loss: 194.5122 - val_mae: 10.5786\n",
      "Epoch 6/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 533.8214 - mae: 18.1938 - val_loss: 237.7348 - val_mae: 11.8809\n",
      "Epoch 7/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 514.7145 - mae: 17.6939 - val_loss: 177.1712 - val_mae: 10.1634\n",
      "Epoch 8/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 513.1375 - mae: 17.6712 - val_loss: 162.3161 - val_mae: 9.6269\n",
      "Epoch 9/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 535.9373 - mae: 17.9015 - val_loss: 159.7026 - val_mae: 9.5264\n",
      "Epoch 10/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 524.6586 - mae: 17.9993 - val_loss: 163.6355 - val_mae: 9.6443\n",
      "Epoch 11/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 489.5432 - mae: 17.3001 - val_loss: 192.9525 - val_mae: 10.4905\n",
      "Epoch 12/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 472.2963 - mae: 17.0228 - val_loss: 152.0759 - val_mae: 9.2067\n",
      "Epoch 13/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 492.7971 - mae: 17.2252 - val_loss: 223.2218 - val_mae: 11.8971\n",
      "Epoch 14/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 459.8519 - mae: 16.8718 - val_loss: 153.9725 - val_mae: 9.1848\n",
      "Epoch 15/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 466.0586 - mae: 16.9980 - val_loss: 168.1947 - val_mae: 9.7550\n",
      "Epoch 16/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 492.0447 - mae: 16.9659 - val_loss: 148.7758 - val_mae: 9.1841\n",
      "Epoch 17/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 460.0759 - mae: 16.7435 - val_loss: 260.2861 - val_mae: 12.9180\n",
      "Epoch 18/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 489.0390 - mae: 17.3477 - val_loss: 201.1878 - val_mae: 11.0780\n",
      "Epoch 19/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 474.5009 - mae: 16.9091 - val_loss: 208.9245 - val_mae: 11.6307\n",
      "Epoch 20/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 483.2780 - mae: 17.1265 - val_loss: 142.3282 - val_mae: 8.9239\n",
      "Epoch 21/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 452.8779 - mae: 16.5748 - val_loss: 141.2468 - val_mae: 8.8239\n",
      "Epoch 22/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 448.7908 - mae: 16.4863 - val_loss: 145.3783 - val_mae: 8.9991\n",
      "Epoch 23/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459.2960 - mae: 16.7396 - val_loss: 164.1524 - val_mae: 9.7145\n",
      "Epoch 24/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459.4519 - mae: 16.8124 - val_loss: 147.6651 - val_mae: 9.1455\n",
      "Epoch 25/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461.6325 - mae: 16.7680 - val_loss: 138.9340 - val_mae: 8.7328\n",
      "Epoch 26/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.7147 - mae: 16.6401 - val_loss: 144.4729 - val_mae: 8.9082\n",
      "Epoch 27/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 496.0472 - mae: 17.1815 - val_loss: 235.0111 - val_mae: 11.9579\n",
      "Epoch 28/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 463.9988 - mae: 16.5209 - val_loss: 155.2157 - val_mae: 9.3430\n",
      "Epoch 29/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 475.4543 - mae: 17.0664 - val_loss: 137.2183 - val_mae: 8.6337\n",
      "Epoch 30/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 452.5289 - mae: 16.5887 - val_loss: 137.4652 - val_mae: 8.5618\n",
      "Epoch 31/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 453.6186 - mae: 16.7802 - val_loss: 135.6998 - val_mae: 8.6366\n",
      "Epoch 32/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 443.1830 - mae: 16.4555 - val_loss: 132.8055 - val_mae: 8.4746\n",
      "Epoch 33/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436.1125 - mae: 16.3474 - val_loss: 202.6959 - val_mae: 11.3323\n",
      "Epoch 34/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 452.8354 - mae: 16.5761 - val_loss: 135.6325 - val_mae: 8.6183\n",
      "Epoch 35/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 436.8643 - mae: 16.2362 - val_loss: 146.9465 - val_mae: 8.8916\n",
      "Epoch 36/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 449.1819 - mae: 16.3893 - val_loss: 138.7909 - val_mae: 8.6564\n",
      "Epoch 37/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.5847 - mae: 16.1578 - val_loss: 150.4454 - val_mae: 9.0268\n",
      "Epoch 38/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 440.5917 - mae: 16.2109 - val_loss: 152.2585 - val_mae: 9.2806\n",
      "Epoch 39/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 442.8898 - mae: 16.2774 - val_loss: 159.1286 - val_mae: 9.3740\n",
      "Epoch 40/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 454.5678 - mae: 16.4954 - val_loss: 175.7150 - val_mae: 10.3430\n",
      "Epoch 41/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 393.1159 - mae: 15.4531 - val_loss: 159.0014 - val_mae: 9.2085\n",
      "Epoch 42/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431.0644 - mae: 16.0662 - val_loss: 199.3113 - val_mae: 11.0654\n",
      "Patience 10: Early stopping occurred at epoch 41\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.6393 - mae: 8.5766\n",
      "Patience 10: Validation MAE: 8.47\n",
      "Patience 10: Validation Loss: 132.81\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 117.0957, MAE = 7.9254, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 124.4492, MAE = 8.1072, Early Stopping Occurred: True, Early Stopping Epoch: 93\n",
      "Patience 20: Loss = 123.5643, MAE = 8.1035, Early Stopping Occurred: True, Early Stopping Epoch: 112\n",
      "Patience 10: Loss = 132.8055, MAE = 8.4746, Early Stopping Occurred: True, Early Stopping Epoch: 41\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "results200 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    sbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    sbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_{}.keras'.format(patience), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = sbp_model.fit(\n",
    "        X_train_combined, SBP_Y_train_combined,\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_combined, SBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = sbp_model.evaluate(X_test_combined, SBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    results200.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in results200:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1326.9725 - mae: 26.0326 - val_loss: 407.7220 - val_mae: 15.0373\n",
      "Epoch 2/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 671.6589 - mae: 20.3963 - val_loss: 264.8920 - val_mae: 12.4135\n",
      "Epoch 3/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 599.0610 - mae: 19.3789 - val_loss: 271.8876 - val_mae: 12.7197\n",
      "Epoch 4/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 541.2142 - mae: 18.3257 - val_loss: 181.1248 - val_mae: 10.2274\n",
      "Epoch 5/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 545.9890 - mae: 18.3693 - val_loss: 178.5707 - val_mae: 10.2198\n",
      "Epoch 6/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 506.6088 - mae: 17.5804 - val_loss: 164.3987 - val_mae: 9.6851\n",
      "Epoch 7/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 507.8036 - mae: 17.6806 - val_loss: 157.2042 - val_mae: 9.4679\n",
      "Epoch 8/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 514.5306 - mae: 17.8330 - val_loss: 151.1375 - val_mae: 9.2807\n",
      "Epoch 9/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 516.2721 - mae: 17.4241 - val_loss: 151.3185 - val_mae: 9.2823\n",
      "Epoch 10/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 524.6708 - mae: 17.8593 - val_loss: 265.5265 - val_mae: 12.9420\n",
      "Epoch 11/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 470.1347 - mae: 16.8081 - val_loss: 145.7758 - val_mae: 8.9151\n",
      "Epoch 12/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 453.3336 - mae: 16.5976 - val_loss: 187.1551 - val_mae: 10.7577\n",
      "Epoch 13/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 481.7162 - mae: 17.1457 - val_loss: 187.4550 - val_mae: 10.6471\n",
      "Epoch 14/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 452.6307 - mae: 16.7291 - val_loss: 147.1732 - val_mae: 9.0386\n",
      "Epoch 15/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 462.1951 - mae: 16.6695 - val_loss: 145.3571 - val_mae: 8.9329\n",
      "Epoch 16/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 465.9318 - mae: 16.9012 - val_loss: 192.5290 - val_mae: 10.8593\n",
      "Epoch 17/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 467.9835 - mae: 16.9056 - val_loss: 147.1699 - val_mae: 8.9141\n",
      "Epoch 18/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 444.5496 - mae: 16.4124 - val_loss: 154.6682 - val_mae: 9.4610\n",
      "Epoch 19/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 419.9473 - mae: 16.1140 - val_loss: 149.3840 - val_mae: 9.2347\n",
      "Epoch 20/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 473.8972 - mae: 16.8683 - val_loss: 159.2036 - val_mae: 9.6590\n",
      "Epoch 21/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 431.8725 - mae: 16.0309 - val_loss: 178.4321 - val_mae: 10.3942\n",
      "Epoch 22/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 421.7931 - mae: 15.9587 - val_loss: 143.1250 - val_mae: 8.9077\n",
      "Epoch 23/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 442.0634 - mae: 16.0918 - val_loss: 151.5783 - val_mae: 9.3069\n",
      "Epoch 24/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 456.5533 - mae: 16.9938 - val_loss: 146.6321 - val_mae: 9.0150\n",
      "Epoch 25/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 423.5810 - mae: 15.9931 - val_loss: 158.5770 - val_mae: 9.7266\n",
      "Epoch 26/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 425.8191 - mae: 16.0330 - val_loss: 137.1169 - val_mae: 8.7561\n",
      "Epoch 27/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 408.5815 - mae: 15.5769 - val_loss: 140.2261 - val_mae: 8.7003\n",
      "Epoch 28/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 412.2359 - mae: 15.6985 - val_loss: 140.3696 - val_mae: 8.7968\n",
      "Epoch 29/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 415.0014 - mae: 15.7846 - val_loss: 145.0889 - val_mae: 8.9841\n",
      "Epoch 30/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 422.1261 - mae: 15.9684 - val_loss: 211.2008 - val_mae: 11.4207\n",
      "Epoch 31/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 409.7921 - mae: 15.7865 - val_loss: 141.2326 - val_mae: 8.7310\n",
      "Epoch 32/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 438.3657 - mae: 16.3589 - val_loss: 138.7207 - val_mae: 8.7593\n",
      "Epoch 33/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 403.1557 - mae: 15.6702 - val_loss: 136.3073 - val_mae: 8.6137\n",
      "Epoch 34/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 408.8064 - mae: 15.7171 - val_loss: 148.3848 - val_mae: 9.2979\n",
      "Epoch 35/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 388.7849 - mae: 15.3700 - val_loss: 196.1429 - val_mae: 11.0845\n",
      "Epoch 36/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 444.1158 - mae: 16.0444 - val_loss: 148.7853 - val_mae: 9.2269\n",
      "Epoch 37/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 392.6495 - mae: 15.2796 - val_loss: 137.6698 - val_mae: 8.7249\n",
      "Epoch 38/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 414.2297 - mae: 15.4316 - val_loss: 132.3021 - val_mae: 8.5333\n",
      "Epoch 39/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.3373 - mae: 15.7814 - val_loss: 141.7296 - val_mae: 8.6815\n",
      "Epoch 40/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 404.2379 - mae: 15.3688 - val_loss: 138.2334 - val_mae: 8.5737\n",
      "Epoch 41/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 389.8033 - mae: 15.3982 - val_loss: 135.4192 - val_mae: 8.6321\n",
      "Epoch 42/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 395.8604 - mae: 15.3728 - val_loss: 159.6738 - val_mae: 9.7006\n",
      "Epoch 43/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 415.0612 - mae: 15.8540 - val_loss: 150.1693 - val_mae: 9.3700\n",
      "Epoch 44/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380.7932 - mae: 15.1285 - val_loss: 130.7411 - val_mae: 8.4250\n",
      "Epoch 45/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 386.7756 - mae: 15.1475 - val_loss: 177.9745 - val_mae: 10.5173\n",
      "Epoch 46/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 400.4392 - mae: 15.2491 - val_loss: 133.9081 - val_mae: 8.5571\n",
      "Epoch 47/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 389.4377 - mae: 15.3131 - val_loss: 202.1238 - val_mae: 11.3234\n",
      "Epoch 48/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 394.2623 - mae: 15.5013 - val_loss: 256.8913 - val_mae: 13.2425\n",
      "Epoch 49/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 387.3947 - mae: 15.2056 - val_loss: 162.4008 - val_mae: 9.7261\n",
      "Epoch 50/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 389.3530 - mae: 15.5076 - val_loss: 131.6026 - val_mae: 8.4530\n",
      "Epoch 51/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 398.8748 - mae: 15.3643 - val_loss: 133.5625 - val_mae: 8.6043\n",
      "Epoch 52/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 412.0162 - mae: 15.5017 - val_loss: 144.4340 - val_mae: 9.0831\n",
      "Epoch 53/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 386.3055 - mae: 15.1806 - val_loss: 131.8304 - val_mae: 8.4426\n",
      "Epoch 54/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 384.4089 - mae: 15.2382 - val_loss: 133.7567 - val_mae: 8.5324\n",
      "Epoch 55/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 397.1214 - mae: 15.4220 - val_loss: 128.9426 - val_mae: 8.3688\n",
      "Epoch 56/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382.1406 - mae: 14.9921 - val_loss: 133.8723 - val_mae: 8.5248\n",
      "Epoch 57/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 393.9414 - mae: 15.1382 - val_loss: 201.5034 - val_mae: 11.3518\n",
      "Epoch 58/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 387.5715 - mae: 15.1504 - val_loss: 128.8430 - val_mae: 8.3250\n",
      "Epoch 59/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 384.0110 - mae: 15.1504 - val_loss: 136.4406 - val_mae: 8.6543\n",
      "Epoch 60/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 364.3109 - mae: 14.9864 - val_loss: 140.6455 - val_mae: 8.8942\n",
      "Epoch 61/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380.8939 - mae: 15.0598 - val_loss: 175.1025 - val_mae: 10.2521\n",
      "Epoch 62/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 390.8628 - mae: 15.1475 - val_loss: 202.3070 - val_mae: 11.5309\n",
      "Epoch 63/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 372.1916 - mae: 14.9789 - val_loss: 129.2056 - val_mae: 8.2519\n",
      "Epoch 64/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 416.8706 - mae: 15.6989 - val_loss: 141.3276 - val_mae: 8.9082\n",
      "Epoch 65/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 391.7116 - mae: 15.1898 - val_loss: 127.2832 - val_mae: 8.3071\n",
      "Epoch 66/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378.1812 - mae: 15.0326 - val_loss: 124.9988 - val_mae: 8.1912\n",
      "Epoch 67/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 372.4279 - mae: 15.1899 - val_loss: 130.1559 - val_mae: 8.4716\n",
      "Epoch 68/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 385.3587 - mae: 15.3170 - val_loss: 143.8802 - val_mae: 9.0883\n",
      "Epoch 69/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 364.2884 - mae: 14.8951 - val_loss: 130.2927 - val_mae: 8.4081\n",
      "Epoch 70/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 358.8930 - mae: 14.7610 - val_loss: 132.7031 - val_mae: 8.4277\n",
      "Epoch 71/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.5587 - mae: 14.9535 - val_loss: 131.9556 - val_mae: 8.4105\n",
      "Epoch 72/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 360.7207 - mae: 14.7780 - val_loss: 130.4547 - val_mae: 8.3584\n",
      "Epoch 73/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 361.5683 - mae: 14.8253 - val_loss: 144.1773 - val_mae: 8.8942\n",
      "Epoch 74/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 364.3532 - mae: 14.7082 - val_loss: 128.3289 - val_mae: 8.4085\n",
      "Epoch 75/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.5209 - mae: 14.7816 - val_loss: 131.1967 - val_mae: 8.2774\n",
      "Epoch 76/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 359.2845 - mae: 14.6354 - val_loss: 137.1243 - val_mae: 8.7285\n",
      "Epoch 77/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 371.2946 - mae: 14.9157 - val_loss: 128.5176 - val_mae: 8.3897\n",
      "Epoch 78/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 366.0866 - mae: 14.6732 - val_loss: 132.4301 - val_mae: 8.5563\n",
      "Epoch 79/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 358.0491 - mae: 14.6347 - val_loss: 133.6986 - val_mae: 8.5913\n",
      "Epoch 80/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 353.4841 - mae: 14.5607 - val_loss: 136.2308 - val_mae: 8.6641\n",
      "Epoch 81/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377.4996 - mae: 14.9675 - val_loss: 131.4848 - val_mae: 8.5338\n",
      "Epoch 82/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 370.4789 - mae: 14.6662 - val_loss: 129.8953 - val_mae: 8.4311\n",
      "Epoch 83/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380.5417 - mae: 14.8497 - val_loss: 124.9628 - val_mae: 8.1711\n",
      "Epoch 84/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 337.0100 - mae: 14.0237 - val_loss: 144.0643 - val_mae: 8.9715\n",
      "Epoch 85/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 355.0430 - mae: 14.5613 - val_loss: 132.1706 - val_mae: 8.5251\n",
      "Epoch 86/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 347.0350 - mae: 14.3007 - val_loss: 128.0215 - val_mae: 8.2322\n",
      "Epoch 87/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 346.8642 - mae: 14.2138 - val_loss: 136.4726 - val_mae: 8.7010\n",
      "Epoch 88/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 341.2946 - mae: 14.4232 - val_loss: 126.0379 - val_mae: 8.2871\n",
      "Epoch 89/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 353.5930 - mae: 14.5125 - val_loss: 132.9442 - val_mae: 8.4316\n",
      "Epoch 90/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 340.7512 - mae: 14.2834 - val_loss: 202.0031 - val_mae: 11.5135\n",
      "Epoch 91/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 332.6089 - mae: 14.0820 - val_loss: 136.2490 - val_mae: 8.6465\n",
      "Epoch 92/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328.3130 - mae: 14.1533 - val_loss: 133.1955 - val_mae: 8.5101\n",
      "Epoch 93/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 343.3674 - mae: 14.6052 - val_loss: 177.6433 - val_mae: 10.0163\n",
      "Epoch 94/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 354.7644 - mae: 14.5127 - val_loss: 143.3587 - val_mae: 9.1124\n",
      "Epoch 95/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 337.8149 - mae: 14.3104 - val_loss: 239.2978 - val_mae: 12.5642\n",
      "Epoch 96/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 368.4812 - mae: 14.9951 - val_loss: 126.0513 - val_mae: 8.2811\n",
      "Epoch 97/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 338.0803 - mae: 14.2535 - val_loss: 132.2064 - val_mae: 8.5678\n",
      "Epoch 98/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 359.2793 - mae: 14.5734 - val_loss: 132.0017 - val_mae: 8.5111\n",
      "Epoch 99/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 352.5226 - mae: 14.5192 - val_loss: 133.7493 - val_mae: 8.4518\n",
      "Epoch 100/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 365.4590 - mae: 14.7062 - val_loss: 131.9316 - val_mae: 8.5855\n",
      "Epoch 101/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 346.1216 - mae: 14.2650 - val_loss: 160.5677 - val_mae: 9.7435\n",
      "Epoch 102/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 334.9530 - mae: 14.3752 - val_loss: 124.1601 - val_mae: 8.2176\n",
      "Epoch 103/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 329.3913 - mae: 14.0503 - val_loss: 126.6961 - val_mae: 8.3263\n",
      "Epoch 104/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 338.3733 - mae: 14.2471 - val_loss: 132.0562 - val_mae: 8.4707\n",
      "Epoch 105/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 354.2779 - mae: 14.4546 - val_loss: 127.9558 - val_mae: 8.4203\n",
      "Epoch 106/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 308.2440 - mae: 13.6263 - val_loss: 129.1444 - val_mae: 8.2831\n",
      "Epoch 107/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 351.8540 - mae: 14.4615 - val_loss: 124.4898 - val_mae: 8.1627\n",
      "Epoch 108/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 336.0670 - mae: 14.0835 - val_loss: 121.8808 - val_mae: 8.0505\n",
      "Epoch 109/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 340.6998 - mae: 14.3324 - val_loss: 125.0012 - val_mae: 8.2284\n",
      "Epoch 110/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 353.5137 - mae: 14.3472 - val_loss: 126.1538 - val_mae: 8.1771\n",
      "Epoch 111/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 335.0403 - mae: 14.2840 - val_loss: 169.2386 - val_mae: 9.7817\n",
      "Epoch 112/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 348.1447 - mae: 14.3306 - val_loss: 160.2915 - val_mae: 9.7982\n",
      "Epoch 113/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 341.4714 - mae: 14.2116 - val_loss: 123.3506 - val_mae: 8.1051\n",
      "Epoch 114/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 351.3695 - mae: 14.5736 - val_loss: 151.4864 - val_mae: 9.4894\n",
      "Epoch 115/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 330.7286 - mae: 13.7922 - val_loss: 122.0915 - val_mae: 8.0195\n",
      "Epoch 116/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 339.8158 - mae: 14.1424 - val_loss: 132.8999 - val_mae: 8.5808\n",
      "Epoch 117/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 359.1339 - mae: 14.6504 - val_loss: 140.2986 - val_mae: 8.8325\n",
      "Epoch 118/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 327.3323 - mae: 13.8105 - val_loss: 139.7012 - val_mae: 8.8810\n",
      "Epoch 119/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 325.5047 - mae: 13.9018 - val_loss: 154.7334 - val_mae: 9.3837\n",
      "Epoch 120/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 333.8503 - mae: 14.2392 - val_loss: 122.4822 - val_mae: 8.1295\n",
      "Epoch 121/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 340.3604 - mae: 14.2431 - val_loss: 124.0392 - val_mae: 8.1098\n",
      "Epoch 122/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 322.4028 - mae: 13.6582 - val_loss: 129.7661 - val_mae: 8.4408\n",
      "Epoch 123/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 332.6273 - mae: 14.0321 - val_loss: 137.5170 - val_mae: 8.6056\n",
      "Epoch 124/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 328.4898 - mae: 13.9635 - val_loss: 145.1238 - val_mae: 9.1793\n",
      "Epoch 125/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 326.6690 - mae: 14.0387 - val_loss: 123.4908 - val_mae: 8.0728\n",
      "Epoch 126/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 317.9342 - mae: 13.8308 - val_loss: 137.7522 - val_mae: 8.7915\n",
      "Epoch 127/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 315.3615 - mae: 13.7246 - val_loss: 136.2348 - val_mae: 8.7131\n",
      "Epoch 128/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 335.7470 - mae: 13.9277 - val_loss: 128.3954 - val_mae: 8.2988\n",
      "Epoch 129/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 326.1261 - mae: 13.8361 - val_loss: 121.7042 - val_mae: 8.0855\n",
      "Epoch 130/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 327.4879 - mae: 14.0073 - val_loss: 123.9576 - val_mae: 8.0298\n",
      "Epoch 131/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 348.8684 - mae: 14.0297 - val_loss: 122.4397 - val_mae: 8.0517\n",
      "Epoch 132/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 321.0024 - mae: 13.8013 - val_loss: 123.7921 - val_mae: 8.1305\n",
      "Epoch 133/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 305.1538 - mae: 13.5156 - val_loss: 135.1043 - val_mae: 8.5056\n",
      "Epoch 134/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 339.4507 - mae: 14.1539 - val_loss: 125.9550 - val_mae: 8.3213\n",
      "Epoch 135/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 343.3165 - mae: 13.9957 - val_loss: 125.2154 - val_mae: 8.1072\n",
      "Epoch 136/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 345.9900 - mae: 14.2458 - val_loss: 126.1019 - val_mae: 8.2149\n",
      "Epoch 137/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 322.7567 - mae: 13.7154 - val_loss: 142.5563 - val_mae: 9.0718\n",
      "Epoch 138/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 318.4417 - mae: 13.8903 - val_loss: 122.2564 - val_mae: 8.0547\n",
      "Epoch 139/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 320.6630 - mae: 13.8318 - val_loss: 126.7118 - val_mae: 8.3753\n",
      "Epoch 140/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 310.9945 - mae: 13.4320 - val_loss: 120.8173 - val_mae: 8.0488\n",
      "Epoch 141/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 313.3894 - mae: 13.8072 - val_loss: 123.5534 - val_mae: 8.0026\n",
      "Epoch 142/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 315.9417 - mae: 13.6745 - val_loss: 129.4608 - val_mae: 8.3713\n",
      "Epoch 143/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 309.7568 - mae: 13.6089 - val_loss: 133.1933 - val_mae: 8.5796\n",
      "Epoch 144/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 300.1955 - mae: 13.4905 - val_loss: 134.5666 - val_mae: 8.7426\n",
      "Epoch 145/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 315.2906 - mae: 13.5956 - val_loss: 128.7920 - val_mae: 8.3455\n",
      "Epoch 146/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 312.8420 - mae: 13.5905 - val_loss: 124.1491 - val_mae: 8.1936\n",
      "Epoch 147/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 326.1877 - mae: 13.8007 - val_loss: 125.2501 - val_mae: 8.2349\n",
      "Epoch 148/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 338.0672 - mae: 14.0173 - val_loss: 182.2543 - val_mae: 10.5045\n",
      "Epoch 149/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 321.1578 - mae: 13.8890 - val_loss: 123.6415 - val_mae: 8.1474\n",
      "Epoch 150/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 308.9711 - mae: 13.4813 - val_loss: 120.1429 - val_mae: 7.9493\n",
      "Epoch 151/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 302.9624 - mae: 13.4352 - val_loss: 125.1951 - val_mae: 8.1422\n",
      "Epoch 152/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 325.2477 - mae: 13.7948 - val_loss: 123.2975 - val_mae: 8.1803\n",
      "Epoch 153/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 316.2083 - mae: 13.8938 - val_loss: 127.2963 - val_mae: 8.2110\n",
      "Epoch 154/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 313.3927 - mae: 13.5358 - val_loss: 127.4483 - val_mae: 8.3256\n",
      "Epoch 155/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 300.9867 - mae: 13.5017 - val_loss: 127.7263 - val_mae: 8.3030\n",
      "Epoch 156/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 311.7003 - mae: 13.6716 - val_loss: 128.8054 - val_mae: 8.2569\n",
      "Epoch 157/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 305.2822 - mae: 13.2991 - val_loss: 124.0283 - val_mae: 8.1172\n",
      "Epoch 158/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 319.8350 - mae: 13.5264 - val_loss: 121.2390 - val_mae: 8.0691\n",
      "Epoch 159/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 309.0832 - mae: 13.5354 - val_loss: 122.7807 - val_mae: 8.1358\n",
      "Epoch 160/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 325.2214 - mae: 13.6852 - val_loss: 122.9732 - val_mae: 8.1534\n",
      "Epoch 161/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 315.7606 - mae: 13.7444 - val_loss: 124.5542 - val_mae: 8.0554\n",
      "Epoch 162/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 288.6367 - mae: 13.1170 - val_loss: 126.5623 - val_mae: 8.2373\n",
      "Epoch 163/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 311.6718 - mae: 13.5719 - val_loss: 134.7651 - val_mae: 8.5386\n",
      "Epoch 164/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 298.2611 - mae: 13.2932 - val_loss: 119.1141 - val_mae: 7.9598\n",
      "Epoch 165/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 304.5066 - mae: 13.3832 - val_loss: 122.7524 - val_mae: 8.0373\n",
      "Epoch 166/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 304.6332 - mae: 13.3182 - val_loss: 122.1394 - val_mae: 8.0219\n",
      "Epoch 167/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 325.7561 - mae: 13.6685 - val_loss: 129.1198 - val_mae: 8.3647\n",
      "Epoch 168/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 318.3409 - mae: 13.6076 - val_loss: 119.5696 - val_mae: 7.9312\n",
      "Epoch 169/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 327.2853 - mae: 13.6983 - val_loss: 133.5982 - val_mae: 8.6466\n",
      "Epoch 170/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 297.1405 - mae: 13.1321 - val_loss: 129.4985 - val_mae: 8.3671\n",
      "Epoch 171/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 295.9968 - mae: 13.3205 - val_loss: 127.4775 - val_mae: 8.1701\n",
      "Epoch 172/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 287.8852 - mae: 12.9630 - val_loss: 117.5314 - val_mae: 7.9175\n",
      "Epoch 173/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 312.5685 - mae: 13.5249 - val_loss: 118.0446 - val_mae: 7.8621\n",
      "Epoch 174/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 300.6657 - mae: 13.4259 - val_loss: 124.3837 - val_mae: 8.1442\n",
      "Epoch 175/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 310.1505 - mae: 13.3204 - val_loss: 124.5542 - val_mae: 8.0673\n",
      "Epoch 176/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 289.2461 - mae: 13.0878 - val_loss: 126.2256 - val_mae: 8.2890\n",
      "Epoch 177/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 312.4274 - mae: 13.3571 - val_loss: 122.1377 - val_mae: 8.0453\n",
      "Epoch 178/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 297.9889 - mae: 12.9236 - val_loss: 118.4077 - val_mae: 7.9394\n",
      "Epoch 179/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 294.0779 - mae: 13.1288 - val_loss: 134.4402 - val_mae: 8.5146\n",
      "Epoch 180/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 300.7518 - mae: 13.1789 - val_loss: 126.2659 - val_mae: 8.2079\n",
      "Epoch 181/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 313.1656 - mae: 13.5365 - val_loss: 130.7273 - val_mae: 8.3787\n",
      "Epoch 182/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 306.0794 - mae: 13.3683 - val_loss: 144.2469 - val_mae: 9.0685\n",
      "Epoch 183/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 298.4017 - mae: 13.2099 - val_loss: 139.6104 - val_mae: 8.8824\n",
      "Epoch 184/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 293.4644 - mae: 13.0994 - val_loss: 119.8606 - val_mae: 7.9844\n",
      "Epoch 185/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 286.8268 - mae: 13.0905 - val_loss: 120.8864 - val_mae: 8.0402\n",
      "Epoch 186/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 279.9847 - mae: 12.8425 - val_loss: 145.9319 - val_mae: 9.1595\n",
      "Epoch 187/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 293.4168 - mae: 12.9799 - val_loss: 140.6290 - val_mae: 8.8699\n",
      "Epoch 188/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 300.8140 - mae: 13.1706 - val_loss: 121.5442 - val_mae: 8.0458\n",
      "Epoch 189/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 282.4741 - mae: 12.7851 - val_loss: 120.4007 - val_mae: 7.8968\n",
      "Epoch 190/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 293.4941 - mae: 13.2782 - val_loss: 125.9282 - val_mae: 8.1972\n",
      "Epoch 191/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 283.1142 - mae: 13.0192 - val_loss: 155.3647 - val_mae: 9.6962\n",
      "Epoch 192/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 281.4013 - mae: 13.0309 - val_loss: 122.6369 - val_mae: 8.1107\n",
      "Epoch 193/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 287.9219 - mae: 13.0233 - val_loss: 122.6691 - val_mae: 8.1557\n",
      "Epoch 194/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 289.0047 - mae: 13.0815 - val_loss: 134.4060 - val_mae: 8.4730\n",
      "Epoch 195/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 295.4008 - mae: 13.2049 - val_loss: 121.6065 - val_mae: 8.0042\n",
      "Epoch 196/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 302.0740 - mae: 13.3492 - val_loss: 126.9316 - val_mae: 8.3098\n",
      "Epoch 197/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 282.9930 - mae: 12.7777 - val_loss: 118.3484 - val_mae: 7.8716\n",
      "Epoch 198/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 274.7749 - mae: 12.8150 - val_loss: 129.6743 - val_mae: 8.4673\n",
      "Epoch 199/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 263.2517 - mae: 12.5266 - val_loss: 121.3763 - val_mae: 8.0904\n",
      "Epoch 200/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 280.5678 - mae: 12.8688 - val_loss: 118.2099 - val_mae: 7.8762\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.8380 - mae: 7.9598\n",
      "Patience 40: Validation MAE: 7.92\n",
      "Patience 40: Validation Loss: 117.53\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1755.4409 - mae: 29.8514 - val_loss: 329.5398 - val_mae: 13.6144\n",
      "Epoch 2/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 715.9340 - mae: 21.1428 - val_loss: 346.0937 - val_mae: 14.0846\n",
      "Epoch 3/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 642.3780 - mae: 19.8750 - val_loss: 289.3479 - val_mae: 13.0833\n",
      "Epoch 4/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 583.1179 - mae: 18.8183 - val_loss: 217.5075 - val_mae: 11.2261\n",
      "Epoch 5/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 567.1828 - mae: 18.7257 - val_loss: 174.3994 - val_mae: 10.0911\n",
      "Epoch 6/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 556.0081 - mae: 18.5033 - val_loss: 250.2449 - val_mae: 12.6708\n",
      "Epoch 7/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 497.4345 - mae: 17.2669 - val_loss: 159.1261 - val_mae: 9.5237\n",
      "Epoch 8/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 471.8453 - mae: 17.0458 - val_loss: 232.3380 - val_mae: 11.7501\n",
      "Epoch 9/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 544.3576 - mae: 17.9680 - val_loss: 155.1058 - val_mae: 9.4327\n",
      "Epoch 10/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 494.1231 - mae: 17.1715 - val_loss: 151.4630 - val_mae: 8.9194\n",
      "Epoch 11/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 476.0174 - mae: 17.0684 - val_loss: 192.0441 - val_mae: 10.8933\n",
      "Epoch 12/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 482.8183 - mae: 17.1965 - val_loss: 150.7428 - val_mae: 9.3093\n",
      "Epoch 13/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 497.2234 - mae: 17.4497 - val_loss: 144.4546 - val_mae: 8.9099\n",
      "Epoch 14/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 456.4131 - mae: 16.7034 - val_loss: 195.2520 - val_mae: 11.0749\n",
      "Epoch 15/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 484.0309 - mae: 17.2334 - val_loss: 214.5759 - val_mae: 11.5664\n",
      "Epoch 16/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 461.4796 - mae: 16.7229 - val_loss: 241.8608 - val_mae: 12.8141\n",
      "Epoch 17/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 461.0243 - mae: 16.7347 - val_loss: 212.7034 - val_mae: 11.7997\n",
      "Epoch 18/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 457.6649 - mae: 16.6115 - val_loss: 151.3439 - val_mae: 9.1930\n",
      "Epoch 19/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 475.7452 - mae: 17.0872 - val_loss: 150.1850 - val_mae: 9.0375\n",
      "Epoch 20/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 462.7206 - mae: 16.7593 - val_loss: 146.6476 - val_mae: 9.1500\n",
      "Epoch 21/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 454.6313 - mae: 16.7319 - val_loss: 195.2825 - val_mae: 11.2450\n",
      "Epoch 22/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 456.7091 - mae: 16.5876 - val_loss: 142.8063 - val_mae: 8.9592\n",
      "Epoch 23/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 432.0187 - mae: 16.2891 - val_loss: 205.4645 - val_mae: 11.5516\n",
      "Epoch 24/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 446.4100 - mae: 16.4074 - val_loss: 146.5308 - val_mae: 9.1440\n",
      "Epoch 25/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 435.8121 - mae: 16.2493 - val_loss: 151.1540 - val_mae: 9.2922\n",
      "Epoch 26/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 455.3531 - mae: 16.4500 - val_loss: 169.2475 - val_mae: 9.9469\n",
      "Epoch 27/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 439.2351 - mae: 16.3684 - val_loss: 144.3124 - val_mae: 8.8861\n",
      "Epoch 28/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 448.2136 - mae: 16.4985 - val_loss: 154.7425 - val_mae: 9.4447\n",
      "Epoch 29/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 427.9921 - mae: 15.9762 - val_loss: 134.4823 - val_mae: 8.6132\n",
      "Epoch 30/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 440.3550 - mae: 16.2356 - val_loss: 144.2089 - val_mae: 8.8787\n",
      "Epoch 31/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 426.7124 - mae: 16.1748 - val_loss: 160.6152 - val_mae: 9.8586\n",
      "Epoch 32/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 469.5976 - mae: 16.7965 - val_loss: 136.0799 - val_mae: 8.7743\n",
      "Epoch 33/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 411.7558 - mae: 15.9309 - val_loss: 159.9663 - val_mae: 9.7743\n",
      "Epoch 34/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 450.8109 - mae: 16.5206 - val_loss: 140.6353 - val_mae: 8.8949\n",
      "Epoch 35/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 412.9294 - mae: 16.0257 - val_loss: 169.0011 - val_mae: 9.9451\n",
      "Epoch 36/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 453.2760 - mae: 16.6756 - val_loss: 133.4104 - val_mae: 8.5488\n",
      "Epoch 37/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 413.7176 - mae: 15.8597 - val_loss: 225.2493 - val_mae: 12.1016\n",
      "Epoch 38/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 455.3657 - mae: 16.5672 - val_loss: 149.8147 - val_mae: 9.2023\n",
      "Epoch 39/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 452.3236 - mae: 16.5218 - val_loss: 132.9183 - val_mae: 8.4582\n",
      "Epoch 40/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 423.8542 - mae: 15.9814 - val_loss: 205.5229 - val_mae: 11.6649\n",
      "Epoch 41/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 419.4991 - mae: 15.8831 - val_loss: 131.9885 - val_mae: 8.5707\n",
      "Epoch 42/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 432.5905 - mae: 16.1136 - val_loss: 135.1689 - val_mae: 8.7428\n",
      "Epoch 43/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 415.9668 - mae: 15.8736 - val_loss: 149.8059 - val_mae: 8.9267\n",
      "Epoch 44/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 391.9016 - mae: 15.5231 - val_loss: 147.2162 - val_mae: 9.0574\n",
      "Epoch 45/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 401.9628 - mae: 15.7821 - val_loss: 153.1761 - val_mae: 9.3256\n",
      "Epoch 46/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 413.6111 - mae: 15.8994 - val_loss: 143.6836 - val_mae: 9.0346\n",
      "Epoch 47/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 429.6436 - mae: 16.0139 - val_loss: 130.5807 - val_mae: 8.4522\n",
      "Epoch 48/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 429.1176 - mae: 16.1681 - val_loss: 134.0711 - val_mae: 8.6472\n",
      "Epoch 49/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 406.3792 - mae: 15.5188 - val_loss: 151.2605 - val_mae: 9.4397\n",
      "Epoch 50/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 420.4717 - mae: 15.9131 - val_loss: 153.5833 - val_mae: 9.1613\n",
      "Epoch 51/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 420.8613 - mae: 15.6941 - val_loss: 161.1778 - val_mae: 9.6615\n",
      "Epoch 52/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 436.4425 - mae: 16.0544 - val_loss: 151.4498 - val_mae: 9.4975\n",
      "Epoch 53/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 404.1353 - mae: 15.3781 - val_loss: 132.5945 - val_mae: 8.5419\n",
      "Epoch 54/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 406.2844 - mae: 15.7020 - val_loss: 130.1979 - val_mae: 8.4508\n",
      "Epoch 55/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 412.6359 - mae: 15.6679 - val_loss: 191.7599 - val_mae: 11.0516\n",
      "Epoch 56/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.0170 - mae: 15.8826 - val_loss: 130.8166 - val_mae: 8.2719\n",
      "Epoch 57/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.5614 - mae: 15.5361 - val_loss: 162.4558 - val_mae: 9.7853\n",
      "Epoch 58/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 426.7955 - mae: 16.0513 - val_loss: 150.3058 - val_mae: 9.3179\n",
      "Epoch 59/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 394.4352 - mae: 15.2373 - val_loss: 291.9076 - val_mae: 14.3593\n",
      "Epoch 60/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 417.6195 - mae: 15.5572 - val_loss: 132.2064 - val_mae: 8.5505\n",
      "Epoch 61/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 389.4737 - mae: 15.3831 - val_loss: 129.9784 - val_mae: 8.4442\n",
      "Epoch 62/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 380.4339 - mae: 15.0990 - val_loss: 158.4772 - val_mae: 9.7989\n",
      "Epoch 63/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375.5197 - mae: 15.1365 - val_loss: 138.1850 - val_mae: 8.6776\n",
      "Epoch 64/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 410.8898 - mae: 15.4836 - val_loss: 138.3197 - val_mae: 8.7019\n",
      "Epoch 65/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377.5368 - mae: 15.2201 - val_loss: 127.8987 - val_mae: 8.4538\n",
      "Epoch 66/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 381.8800 - mae: 15.3555 - val_loss: 134.2361 - val_mae: 8.5584\n",
      "Epoch 67/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379.6580 - mae: 15.1332 - val_loss: 128.4284 - val_mae: 8.3927\n",
      "Epoch 68/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 372.6785 - mae: 15.0352 - val_loss: 133.5480 - val_mae: 8.5588\n",
      "Epoch 69/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.3602 - mae: 15.3008 - val_loss: 177.1040 - val_mae: 10.5760\n",
      "Epoch 70/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 373.9662 - mae: 14.9822 - val_loss: 142.6286 - val_mae: 8.8844\n",
      "Epoch 71/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 385.3164 - mae: 15.1527 - val_loss: 129.5480 - val_mae: 8.5315\n",
      "Epoch 72/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378.0899 - mae: 15.1409 - val_loss: 126.2401 - val_mae: 8.2806\n",
      "Epoch 73/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382.3987 - mae: 15.0896 - val_loss: 123.5084 - val_mae: 8.1270\n",
      "Epoch 74/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 395.2353 - mae: 15.4084 - val_loss: 128.8553 - val_mae: 8.2945\n",
      "Epoch 75/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 403.4729 - mae: 15.5721 - val_loss: 153.3575 - val_mae: 9.5786\n",
      "Epoch 76/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 392.8716 - mae: 15.1950 - val_loss: 124.2728 - val_mae: 8.1443\n",
      "Epoch 77/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 374.7335 - mae: 14.8352 - val_loss: 126.6352 - val_mae: 8.3484\n",
      "Epoch 78/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 392.8896 - mae: 15.1597 - val_loss: 127.6411 - val_mae: 8.2985\n",
      "Epoch 79/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380.0211 - mae: 15.0194 - val_loss: 131.4672 - val_mae: 8.4419\n",
      "Epoch 80/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 381.8957 - mae: 15.1567 - val_loss: 142.9653 - val_mae: 8.9035\n",
      "Epoch 81/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 384.7000 - mae: 15.0389 - val_loss: 131.6637 - val_mae: 8.4820\n",
      "Epoch 82/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 365.9405 - mae: 14.7019 - val_loss: 127.8188 - val_mae: 8.2969\n",
      "Epoch 83/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 352.3896 - mae: 14.5112 - val_loss: 130.2339 - val_mae: 8.3490\n",
      "Epoch 84/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 366.7501 - mae: 14.7740 - val_loss: 126.2038 - val_mae: 8.3594\n",
      "Epoch 85/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 366.0052 - mae: 14.8500 - val_loss: 124.3409 - val_mae: 8.1912\n",
      "Epoch 86/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 364.4371 - mae: 14.6550 - val_loss: 137.0637 - val_mae: 8.6739\n",
      "Epoch 87/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 368.2104 - mae: 14.6486 - val_loss: 120.7529 - val_mae: 8.0917\n",
      "Epoch 88/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 368.5660 - mae: 14.9684 - val_loss: 145.0481 - val_mae: 9.2070\n",
      "Epoch 89/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 362.2783 - mae: 14.6853 - val_loss: 132.8300 - val_mae: 8.5432\n",
      "Epoch 90/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 356.4743 - mae: 14.4763 - val_loss: 144.2687 - val_mae: 9.2014\n",
      "Epoch 91/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 365.4012 - mae: 14.8786 - val_loss: 132.3146 - val_mae: 8.5423\n",
      "Epoch 92/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 348.3309 - mae: 14.4093 - val_loss: 150.7193 - val_mae: 9.4367\n",
      "Epoch 93/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 371.7198 - mae: 14.7986 - val_loss: 129.1735 - val_mae: 8.4671\n",
      "Epoch 94/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 359.7097 - mae: 14.6579 - val_loss: 143.2112 - val_mae: 9.2360\n",
      "Epoch 95/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 369.5226 - mae: 14.6830 - val_loss: 125.8828 - val_mae: 8.2665\n",
      "Epoch 96/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 356.5185 - mae: 14.6518 - val_loss: 128.4270 - val_mae: 8.5283\n",
      "Epoch 97/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 348.7480 - mae: 14.4803 - val_loss: 125.4544 - val_mae: 8.1887\n",
      "Epoch 98/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 350.7456 - mae: 14.5717 - val_loss: 131.2147 - val_mae: 8.4891\n",
      "Epoch 99/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 372.4354 - mae: 14.8161 - val_loss: 135.0385 - val_mae: 8.5131\n",
      "Epoch 100/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 347.5326 - mae: 14.2861 - val_loss: 129.7581 - val_mae: 8.5113\n",
      "Epoch 101/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 358.0614 - mae: 14.7330 - val_loss: 128.0455 - val_mae: 8.3027\n",
      "Epoch 102/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 379.6751 - mae: 14.8996 - val_loss: 137.4319 - val_mae: 8.8077\n",
      "Epoch 103/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 336.8825 - mae: 14.2554 - val_loss: 135.5391 - val_mae: 8.7019\n",
      "Epoch 104/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 344.9824 - mae: 14.3275 - val_loss: 129.0955 - val_mae: 8.2555\n",
      "Epoch 105/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.0856 - mae: 14.9612 - val_loss: 161.7996 - val_mae: 9.8079\n",
      "Epoch 106/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 337.4752 - mae: 14.2867 - val_loss: 138.1318 - val_mae: 8.8098\n",
      "Epoch 107/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 348.1067 - mae: 14.4526 - val_loss: 137.6730 - val_mae: 8.8801\n",
      "Epoch 108/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 372.6898 - mae: 14.9883 - val_loss: 129.1452 - val_mae: 8.4056\n",
      "Epoch 109/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 371.2365 - mae: 14.8008 - val_loss: 135.4281 - val_mae: 8.8207\n",
      "Epoch 110/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 356.6527 - mae: 14.6206 - val_loss: 125.2531 - val_mae: 8.1684\n",
      "Epoch 111/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 358.3829 - mae: 14.6273 - val_loss: 121.8287 - val_mae: 8.0264\n",
      "Epoch 112/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 355.6799 - mae: 14.4123 - val_loss: 119.8787 - val_mae: 7.9634\n",
      "Epoch 113/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 330.8033 - mae: 14.1475 - val_loss: 121.0352 - val_mae: 8.0394\n",
      "Epoch 114/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 373.2600 - mae: 14.6773 - val_loss: 133.2997 - val_mae: 8.7164\n",
      "Epoch 115/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 348.0211 - mae: 14.4542 - val_loss: 119.4078 - val_mae: 7.9994\n",
      "Epoch 116/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 344.7634 - mae: 14.3541 - val_loss: 130.8076 - val_mae: 8.4001\n",
      "Epoch 117/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 341.2775 - mae: 14.2875 - val_loss: 124.0517 - val_mae: 8.2138\n",
      "Epoch 118/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 364.2030 - mae: 14.4809 - val_loss: 123.0067 - val_mae: 8.1439\n",
      "Epoch 119/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 324.1761 - mae: 13.9214 - val_loss: 133.1141 - val_mae: 8.6570\n",
      "Epoch 120/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 338.0789 - mae: 14.2353 - val_loss: 126.9744 - val_mae: 8.2958\n",
      "Epoch 121/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 337.5898 - mae: 14.1257 - val_loss: 126.8897 - val_mae: 8.2670\n",
      "Epoch 122/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 345.9223 - mae: 14.3037 - val_loss: 127.4570 - val_mae: 8.2857\n",
      "Epoch 123/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 341.5305 - mae: 14.4260 - val_loss: 127.6845 - val_mae: 8.2669\n",
      "Epoch 124/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 334.0201 - mae: 14.1090 - val_loss: 134.6875 - val_mae: 8.7544\n",
      "Epoch 125/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 342.1839 - mae: 14.2986 - val_loss: 129.6163 - val_mae: 8.3770\n",
      "Epoch 126/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 327.7247 - mae: 14.0399 - val_loss: 124.9203 - val_mae: 8.2201\n",
      "Epoch 127/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 345.8575 - mae: 14.2145 - val_loss: 140.9079 - val_mae: 8.9108\n",
      "Epoch 128/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 345.8483 - mae: 14.2190 - val_loss: 123.8439 - val_mae: 8.2881\n",
      "Epoch 129/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 330.9643 - mae: 13.9947 - val_loss: 123.5534 - val_mae: 8.1130\n",
      "Epoch 130/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 332.2033 - mae: 14.1936 - val_loss: 121.1384 - val_mae: 8.0641\n",
      "Epoch 131/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 363.7611 - mae: 14.3561 - val_loss: 125.4796 - val_mae: 8.2633\n",
      "Epoch 132/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 321.9444 - mae: 13.8046 - val_loss: 151.9598 - val_mae: 9.3609\n",
      "Epoch 133/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 318.1143 - mae: 13.7882 - val_loss: 152.6935 - val_mae: 9.4779\n",
      "Epoch 134/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 344.6554 - mae: 14.2518 - val_loss: 133.5485 - val_mae: 8.3459\n",
      "Epoch 135/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 329.2474 - mae: 13.8031 - val_loss: 137.1254 - val_mae: 8.7075\n",
      "Epoch 136/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 325.4054 - mae: 13.8726 - val_loss: 120.3800 - val_mae: 7.9186\n",
      "Epoch 137/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 329.5682 - mae: 14.1010 - val_loss: 126.7479 - val_mae: 8.3270\n",
      "Epoch 138/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 334.3618 - mae: 14.1798 - val_loss: 123.5601 - val_mae: 8.2079\n",
      "Epoch 139/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 320.9604 - mae: 13.9185 - val_loss: 148.3386 - val_mae: 9.2870\n",
      "Epoch 140/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 323.8276 - mae: 13.9688 - val_loss: 129.8635 - val_mae: 8.4108\n",
      "Epoch 141/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 340.4754 - mae: 14.1142 - val_loss: 147.0390 - val_mae: 9.1827\n",
      "Epoch 142/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 327.3282 - mae: 13.9606 - val_loss: 142.8907 - val_mae: 9.0716\n",
      "Epoch 143/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 315.0589 - mae: 13.5640 - val_loss: 179.7633 - val_mae: 10.6573\n",
      "Epoch 144/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 336.6552 - mae: 14.0359 - val_loss: 184.8119 - val_mae: 10.6895\n",
      "Epoch 145/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 326.8352 - mae: 14.0974 - val_loss: 125.9827 - val_mae: 8.1988\n",
      "Patience 30: Early stopping occurred at epoch 144\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.7927 - mae: 8.1213\n",
      "Patience 30: Validation MAE: 8.00\n",
      "Patience 30: Validation Loss: 119.41\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1453.4878 - mae: 27.5580 - val_loss: 301.6918 - val_mae: 14.1763\n",
      "Epoch 2/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 654.7042 - mae: 20.1371 - val_loss: 274.0699 - val_mae: 12.5482\n",
      "Epoch 3/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 594.3589 - mae: 19.2674 - val_loss: 337.2776 - val_mae: 14.8424\n",
      "Epoch 4/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 567.3464 - mae: 18.5706 - val_loss: 335.3583 - val_mae: 14.8036\n",
      "Epoch 5/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 529.0861 - mae: 17.9497 - val_loss: 331.9826 - val_mae: 14.8659\n",
      "Epoch 6/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 502.6420 - mae: 17.5138 - val_loss: 294.1281 - val_mae: 13.8278\n",
      "Epoch 7/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 498.3151 - mae: 17.1947 - val_loss: 185.0035 - val_mae: 10.4777\n",
      "Epoch 8/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 553.1586 - mae: 18.2802 - val_loss: 222.3258 - val_mae: 11.7908\n",
      "Epoch 9/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 512.9048 - mae: 17.3583 - val_loss: 157.7410 - val_mae: 9.4032\n",
      "Epoch 10/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 470.1718 - mae: 16.9489 - val_loss: 158.2393 - val_mae: 9.3750\n",
      "Epoch 11/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 465.6410 - mae: 17.0907 - val_loss: 154.5471 - val_mae: 9.3727\n",
      "Epoch 12/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 465.9896 - mae: 16.6043 - val_loss: 147.7669 - val_mae: 9.1049\n",
      "Epoch 13/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 504.4327 - mae: 17.4631 - val_loss: 152.7744 - val_mae: 9.1875\n",
      "Epoch 14/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 487.7823 - mae: 17.2926 - val_loss: 194.9180 - val_mae: 10.8562\n",
      "Epoch 15/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 454.3111 - mae: 16.5954 - val_loss: 332.4066 - val_mae: 15.3335\n",
      "Epoch 16/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 476.5677 - mae: 16.9847 - val_loss: 144.6587 - val_mae: 8.9693\n",
      "Epoch 17/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 468.2678 - mae: 16.8464 - val_loss: 206.6081 - val_mae: 11.0752\n",
      "Epoch 18/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 459.3803 - mae: 16.8042 - val_loss: 148.0413 - val_mae: 8.9354\n",
      "Epoch 19/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 451.2592 - mae: 16.6432 - val_loss: 155.4671 - val_mae: 9.5352\n",
      "Epoch 20/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 435.1971 - mae: 16.3152 - val_loss: 151.1171 - val_mae: 9.3190\n",
      "Epoch 21/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 430.1691 - mae: 16.2778 - val_loss: 176.5761 - val_mae: 10.2693\n",
      "Epoch 22/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 454.2836 - mae: 16.3626 - val_loss: 156.9348 - val_mae: 9.5933\n",
      "Epoch 23/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 442.0284 - mae: 16.1894 - val_loss: 180.5575 - val_mae: 10.6381\n",
      "Epoch 24/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 432.0881 - mae: 16.1967 - val_loss: 183.8973 - val_mae: 10.3400\n",
      "Epoch 25/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 440.0882 - mae: 16.1129 - val_loss: 234.9613 - val_mae: 11.8255\n",
      "Epoch 26/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 453.3427 - mae: 16.3782 - val_loss: 160.0059 - val_mae: 9.7045\n",
      "Epoch 27/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 424.1833 - mae: 16.1245 - val_loss: 144.4719 - val_mae: 9.0209\n",
      "Epoch 28/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 444.1821 - mae: 16.2132 - val_loss: 148.8506 - val_mae: 9.1015\n",
      "Epoch 29/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 431.0774 - mae: 16.0201 - val_loss: 149.7685 - val_mae: 9.2273\n",
      "Epoch 30/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 411.8271 - mae: 15.8193 - val_loss: 141.1247 - val_mae: 8.9452\n",
      "Epoch 31/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 435.9533 - mae: 16.1426 - val_loss: 150.3469 - val_mae: 9.2497\n",
      "Epoch 32/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 408.0260 - mae: 15.4398 - val_loss: 180.8893 - val_mae: 10.4983\n",
      "Epoch 33/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 427.0302 - mae: 16.0115 - val_loss: 157.8341 - val_mae: 9.7179\n",
      "Epoch 34/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 408.5763 - mae: 15.6813 - val_loss: 137.4469 - val_mae: 8.7234\n",
      "Epoch 35/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 428.5782 - mae: 16.1747 - val_loss: 146.2655 - val_mae: 8.8675\n",
      "Epoch 36/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 419.2538 - mae: 15.8908 - val_loss: 139.4368 - val_mae: 8.7992\n",
      "Epoch 37/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 420.3976 - mae: 15.8488 - val_loss: 134.9786 - val_mae: 8.6816\n",
      "Epoch 38/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 430.1869 - mae: 16.0090 - val_loss: 140.9494 - val_mae: 8.8484\n",
      "Epoch 39/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 403.3235 - mae: 15.3708 - val_loss: 146.7400 - val_mae: 9.2362\n",
      "Epoch 40/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 383.8135 - mae: 15.1265 - val_loss: 182.0475 - val_mae: 10.5131\n",
      "Epoch 41/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 384.3224 - mae: 15.3358 - val_loss: 134.7683 - val_mae: 8.5817\n",
      "Epoch 42/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 388.1544 - mae: 15.2463 - val_loss: 135.4267 - val_mae: 8.6330\n",
      "Epoch 43/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 368.1320 - mae: 14.8957 - val_loss: 158.8628 - val_mae: 9.6853\n",
      "Epoch 44/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 364.8957 - mae: 14.9547 - val_loss: 136.7614 - val_mae: 8.5279\n",
      "Epoch 45/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 381.0052 - mae: 15.1064 - val_loss: 135.0446 - val_mae: 8.4580\n",
      "Epoch 46/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 400.0029 - mae: 15.3941 - val_loss: 134.8561 - val_mae: 8.6362\n",
      "Epoch 47/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 396.6101 - mae: 15.3675 - val_loss: 257.1187 - val_mae: 13.1270\n",
      "Epoch 48/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 409.1344 - mae: 15.6162 - val_loss: 144.8851 - val_mae: 8.8608\n",
      "Epoch 49/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 374.7966 - mae: 14.9775 - val_loss: 133.6369 - val_mae: 8.5954\n",
      "Epoch 50/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 389.1609 - mae: 15.4139 - val_loss: 138.9808 - val_mae: 8.5471\n",
      "Epoch 51/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 382.8611 - mae: 15.2813 - val_loss: 147.2105 - val_mae: 9.2324\n",
      "Epoch 52/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 403.3594 - mae: 15.4221 - val_loss: 139.4072 - val_mae: 8.7398\n",
      "Epoch 53/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 374.3788 - mae: 15.0380 - val_loss: 145.6516 - val_mae: 9.0226\n",
      "Epoch 54/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 399.4053 - mae: 15.5122 - val_loss: 130.5250 - val_mae: 8.4450\n",
      "Epoch 55/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375.7225 - mae: 15.0777 - val_loss: 137.2370 - val_mae: 8.7215\n",
      "Epoch 56/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376.8075 - mae: 14.9710 - val_loss: 132.0409 - val_mae: 8.5549\n",
      "Epoch 57/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 388.6388 - mae: 15.2072 - val_loss: 136.5428 - val_mae: 8.6515\n",
      "Epoch 58/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 372.3320 - mae: 14.9910 - val_loss: 133.2785 - val_mae: 8.6043\n",
      "Epoch 59/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 383.2303 - mae: 15.1826 - val_loss: 140.2408 - val_mae: 8.8028\n",
      "Epoch 60/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 391.8535 - mae: 15.3535 - val_loss: 145.7855 - val_mae: 9.1541\n",
      "Epoch 61/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387.3677 - mae: 15.2322 - val_loss: 137.2560 - val_mae: 8.7265\n",
      "Epoch 62/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 394.6995 - mae: 15.4586 - val_loss: 134.8225 - val_mae: 8.4929\n",
      "Epoch 63/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 384.5239 - mae: 15.1608 - val_loss: 131.1148 - val_mae: 8.4265\n",
      "Epoch 64/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 386.0173 - mae: 15.0625 - val_loss: 128.5354 - val_mae: 8.2515\n",
      "Epoch 65/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 392.2062 - mae: 15.2252 - val_loss: 132.5734 - val_mae: 8.3813\n",
      "Epoch 66/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 385.9156 - mae: 15.1283 - val_loss: 166.2207 - val_mae: 9.8964\n",
      "Epoch 67/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.4171 - mae: 14.9034 - val_loss: 150.6018 - val_mae: 9.4217\n",
      "Epoch 68/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 368.7552 - mae: 14.8329 - val_loss: 133.0188 - val_mae: 8.4277\n",
      "Epoch 69/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 363.7523 - mae: 14.7577 - val_loss: 134.3987 - val_mae: 8.5383\n",
      "Epoch 70/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 384.0883 - mae: 15.0979 - val_loss: 136.1865 - val_mae: 8.6774\n",
      "Epoch 71/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 363.1626 - mae: 14.7851 - val_loss: 169.6553 - val_mae: 10.0914\n",
      "Epoch 72/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 353.0865 - mae: 14.6133 - val_loss: 153.3079 - val_mae: 9.5093\n",
      "Epoch 73/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 360.7785 - mae: 14.9034 - val_loss: 131.5546 - val_mae: 8.4309\n",
      "Epoch 74/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.6528 - mae: 14.7051 - val_loss: 150.9862 - val_mae: 9.4976\n",
      "Epoch 75/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 358.0802 - mae: 14.7901 - val_loss: 162.3213 - val_mae: 9.8657\n",
      "Epoch 76/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.3305 - mae: 14.8581 - val_loss: 139.5088 - val_mae: 8.7509\n",
      "Epoch 77/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 351.4771 - mae: 14.5651 - val_loss: 129.5591 - val_mae: 8.3963\n",
      "Epoch 78/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380.4103 - mae: 15.1419 - val_loss: 173.9553 - val_mae: 9.8415\n",
      "Epoch 79/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 367.3027 - mae: 14.6962 - val_loss: 126.8031 - val_mae: 8.2849\n",
      "Epoch 80/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 372.4178 - mae: 14.8046 - val_loss: 130.8540 - val_mae: 8.3338\n",
      "Epoch 81/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 352.2167 - mae: 14.6042 - val_loss: 146.3379 - val_mae: 8.8547\n",
      "Epoch 82/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 366.9413 - mae: 14.7645 - val_loss: 127.7025 - val_mae: 8.3324\n",
      "Epoch 83/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382.2707 - mae: 14.9233 - val_loss: 135.5871 - val_mae: 8.6450\n",
      "Epoch 84/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 356.2025 - mae: 14.6614 - val_loss: 138.7211 - val_mae: 8.7763\n",
      "Epoch 85/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 371.5678 - mae: 14.6304 - val_loss: 131.2298 - val_mae: 8.4101\n",
      "Epoch 86/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 365.7247 - mae: 14.7056 - val_loss: 125.5097 - val_mae: 8.2240\n",
      "Epoch 87/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 359.2780 - mae: 14.5566 - val_loss: 130.2706 - val_mae: 8.4924\n",
      "Epoch 88/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375.8634 - mae: 14.7215 - val_loss: 142.0491 - val_mae: 8.9913\n",
      "Epoch 89/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 338.2138 - mae: 14.2003 - val_loss: 159.4303 - val_mae: 9.6591\n",
      "Epoch 90/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 355.0754 - mae: 14.4831 - val_loss: 131.8877 - val_mae: 8.5929\n",
      "Epoch 91/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 357.0598 - mae: 14.5970 - val_loss: 130.9849 - val_mae: 8.4707\n",
      "Epoch 92/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 367.1570 - mae: 14.3741 - val_loss: 129.3594 - val_mae: 8.3887\n",
      "Epoch 93/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 348.3398 - mae: 14.4353 - val_loss: 160.8192 - val_mae: 9.4745\n",
      "Epoch 94/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375.5897 - mae: 14.9939 - val_loss: 157.7070 - val_mae: 9.6239\n",
      "Epoch 95/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 364.1316 - mae: 14.7135 - val_loss: 130.2022 - val_mae: 8.2555\n",
      "Epoch 96/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 348.8512 - mae: 14.4145 - val_loss: 127.6873 - val_mae: 8.2495\n",
      "Epoch 97/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 334.1306 - mae: 14.2296 - val_loss: 132.2836 - val_mae: 8.5090\n",
      "Epoch 98/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 328.8198 - mae: 14.1109 - val_loss: 137.1293 - val_mae: 8.4848\n",
      "Epoch 99/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 363.5552 - mae: 14.4355 - val_loss: 128.9955 - val_mae: 8.1895\n",
      "Epoch 100/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 340.5655 - mae: 14.2046 - val_loss: 132.4164 - val_mae: 8.4436\n",
      "Epoch 101/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328.8634 - mae: 14.1024 - val_loss: 129.6768 - val_mae: 8.3896\n",
      "Epoch 102/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 339.5497 - mae: 14.3022 - val_loss: 131.1994 - val_mae: 8.5340\n",
      "Epoch 103/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 357.9821 - mae: 14.3867 - val_loss: 135.6781 - val_mae: 8.6407\n",
      "Epoch 104/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 354.5540 - mae: 14.7491 - val_loss: 133.3008 - val_mae: 8.6766\n",
      "Epoch 105/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 342.3661 - mae: 14.3051 - val_loss: 136.2102 - val_mae: 8.7581\n",
      "Epoch 106/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 329.3252 - mae: 14.0134 - val_loss: 127.5309 - val_mae: 8.2284\n",
      "Patience 20: Early stopping occurred at epoch 105\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135.2908 - mae: 8.1834\n",
      "Patience 20: Validation MAE: 8.22\n",
      "Patience 20: Validation Loss: 125.51\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1359.9202 - mae: 26.9129 - val_loss: 318.8089 - val_mae: 13.4083\n",
      "Epoch 2/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 649.6913 - mae: 20.1035 - val_loss: 318.6735 - val_mae: 13.3291\n",
      "Epoch 3/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 580.8163 - mae: 19.0514 - val_loss: 251.5787 - val_mae: 11.9909\n",
      "Epoch 4/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 564.8448 - mae: 18.4923 - val_loss: 186.4016 - val_mae: 10.4343\n",
      "Epoch 5/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 529.0750 - mae: 18.1833 - val_loss: 265.9392 - val_mae: 13.2410\n",
      "Epoch 6/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 482.3876 - mae: 17.2004 - val_loss: 166.9538 - val_mae: 9.8329\n",
      "Epoch 7/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 459.2863 - mae: 16.8415 - val_loss: 181.0487 - val_mae: 10.0629\n",
      "Epoch 8/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 482.2558 - mae: 17.1458 - val_loss: 198.8513 - val_mae: 10.9180\n",
      "Epoch 9/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 486.4946 - mae: 17.2396 - val_loss: 167.0383 - val_mae: 9.7264\n",
      "Epoch 10/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 477.1212 - mae: 16.8027 - val_loss: 176.1792 - val_mae: 10.1824\n",
      "Epoch 11/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 451.2177 - mae: 16.6315 - val_loss: 150.5440 - val_mae: 9.2334\n",
      "Epoch 12/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 468.3902 - mae: 16.7564 - val_loss: 168.3744 - val_mae: 9.9039\n",
      "Epoch 13/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 472.4222 - mae: 16.8437 - val_loss: 154.7175 - val_mae: 9.3641\n",
      "Epoch 14/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 448.5803 - mae: 16.5341 - val_loss: 178.8191 - val_mae: 10.4189\n",
      "Epoch 15/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 423.5093 - mae: 15.9481 - val_loss: 156.9822 - val_mae: 9.3286\n",
      "Epoch 16/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 444.7547 - mae: 16.2356 - val_loss: 178.1780 - val_mae: 10.4464\n",
      "Epoch 17/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 426.4357 - mae: 16.3004 - val_loss: 152.1239 - val_mae: 8.9839\n",
      "Epoch 18/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 437.1443 - mae: 16.4012 - val_loss: 145.0215 - val_mae: 9.0436\n",
      "Epoch 19/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 410.6929 - mae: 15.8611 - val_loss: 137.9716 - val_mae: 8.6635\n",
      "Epoch 20/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 431.3745 - mae: 16.0560 - val_loss: 142.7726 - val_mae: 8.9048\n",
      "Epoch 21/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 423.7561 - mae: 15.9713 - val_loss: 146.6904 - val_mae: 8.9293\n",
      "Epoch 22/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 432.7979 - mae: 16.1337 - val_loss: 145.7959 - val_mae: 9.1486\n",
      "Epoch 23/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 415.7765 - mae: 15.8976 - val_loss: 205.0994 - val_mae: 11.4248\n",
      "Epoch 24/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 420.0269 - mae: 15.7848 - val_loss: 135.0204 - val_mae: 8.4157\n",
      "Epoch 25/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 431.1562 - mae: 16.2796 - val_loss: 162.2473 - val_mae: 9.6861\n",
      "Epoch 26/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 395.8134 - mae: 15.5367 - val_loss: 160.1657 - val_mae: 9.7642\n",
      "Epoch 27/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 412.8856 - mae: 15.8337 - val_loss: 153.3768 - val_mae: 9.4599\n",
      "Epoch 28/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 434.4424 - mae: 16.0972 - val_loss: 162.7195 - val_mae: 9.8235\n",
      "Epoch 29/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 411.1698 - mae: 15.6792 - val_loss: 156.8297 - val_mae: 9.5191\n",
      "Epoch 30/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 416.5873 - mae: 15.8077 - val_loss: 139.8830 - val_mae: 8.8455\n",
      "Epoch 31/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 410.5687 - mae: 15.8664 - val_loss: 154.6262 - val_mae: 9.5130\n",
      "Epoch 32/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 405.5820 - mae: 15.7537 - val_loss: 170.2713 - val_mae: 10.0517\n",
      "Epoch 33/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 419.9939 - mae: 15.9334 - val_loss: 142.4738 - val_mae: 8.9388\n",
      "Epoch 34/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 406.4834 - mae: 15.6512 - val_loss: 141.3950 - val_mae: 8.6670\n",
      "Patience 10: Early stopping occurred at epoch 33\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.3095 - mae: 8.4184\n",
      "Patience 10: Validation MAE: 8.42\n",
      "Patience 10: Validation Loss: 135.02\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 117.5314, MAE = 7.9175, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 119.4077, MAE = 7.9994, Early Stopping Occurred: True, Early Stopping Epoch: 144\n",
      "Patience 20: Loss = 125.5098, MAE = 8.2240, Early Stopping Occurred: True, Early Stopping Epoch: 105\n",
      "Patience 10: Loss = 135.0204, MAE = 8.4157, Early Stopping Occurred: True, Early Stopping Epoch: 33\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "results200_16 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    sbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    sbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_{}.keras'.format(patience), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = sbp_model.fit(\n",
    "        X_train_combined, SBP_Y_train_combined,\n",
    "        epochs=200,\n",
    "        batch_size=16,\n",
    "        validation_data=(X_test_combined, SBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = sbp_model.evaluate(X_test_combined, SBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    results200_16.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    # plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in results200_16:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN SBP (filter alternated)\n",
    "### First Conv1D filters 128\n",
    "-> epoch 50, batch-size = 32\n",
    "- Patience 40: Loss = 135.2585, MAE = 8.6710\n",
    "- Patience 30: Loss = 130.4749, MAE = 8.3256\n",
    "- Patience 20: Loss = 128.1490, MAE = 8.2887\n",
    "- Patience 10: Loss = 135.8297, MAE = 8.6428, Early Stopping Epoch: 34\n",
    "\n",
    "### First Conv1D filters 128\n",
    "-> epoch 60, batch-size = 32\n",
    "- Patience 40: Loss = 129.1048, MAE = 8.4466\n",
    "- Patience 30: Loss = 128.1865, MAE = 8.2143\n",
    "- Patience 20: Loss = 131.2920, MAE = 8.5060\n",
    "- Patience 10: Loss = 136.4874, MAE = 8.6103, Early Stopping Epoch: 46\n",
    "\n",
    "### First Conv1D filters 128\n",
    "-> epoch 100, batch-size = 32\n",
    "- Patience 40: Loss = 124.6289, MAE = 8.0537\n",
    "- Patience 30: Loss = 128.4817, MAE = 8.3647\n",
    "- Patience 20: Loss = 125.3785, MAE = 8.2437\n",
    "- Patience 10: Loss = 134.1710, MAE = 8.5108, Early Stopping Epoch: 44\n",
    "\n",
    "### First Conv1D filters 128\n",
    "-> epoch 150, batch-size = 16\n",
    "- Patience 40: Loss = 118.8970, MAE = 7.9755\n",
    "- Patience 30: Loss = 118.3266, MAE = 7.9201\n",
    "- Patience 20: Loss = 117.4870, MAE = 7.8967\n",
    "- Patience 10: Loss = 130.7383, MAE = 8.4441, Early Stopping Epoch: 50\n",
    "\n",
    "\n",
    "### First Conv1D filters 128\n",
    "-> epoch 150, batch-size = 32\n",
    "- Patience 40: Loss = 119.0548, MAE = 8.0408\n",
    "- Patience 30: Loss = 117.4382, MAE = 7.8401\n",
    "- Patience 20: Loss = 117.6743, MAE = 7.8894\n",
    "- Patience 10: Loss = 131.9274, MAE = 8.4349, Early Stopping Epoch: 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1875.5660 - mae: 31.5802 - val_loss: 309.5373 - val_mae: 14.6892\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 698.1579 - mae: 20.7916 - val_loss: 302.7098 - val_mae: 13.1213\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 614.0500 - mae: 19.5204 - val_loss: 244.2964 - val_mae: 11.9696\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 579.6587 - mae: 18.7916 - val_loss: 299.3297 - val_mae: 14.1951\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 556.0301 - mae: 18.4602 - val_loss: 198.5897 - val_mae: 10.7957\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 540.2421 - mae: 18.1067 - val_loss: 169.5541 - val_mae: 9.8953\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 493.7838 - mae: 17.4459 - val_loss: 204.1609 - val_mae: 11.2459\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 494.6828 - mae: 17.2418 - val_loss: 158.1351 - val_mae: 9.4777\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 478.1540 - mae: 17.0616 - val_loss: 146.7910 - val_mae: 8.9705\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 451.6253 - mae: 16.6126 - val_loss: 162.9896 - val_mae: 9.7228\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 457.7292 - mae: 16.8414 - val_loss: 145.2406 - val_mae: 8.9043\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 428.1096 - mae: 16.1212 - val_loss: 142.5198 - val_mae: 8.8672\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 461.9107 - mae: 16.6107 - val_loss: 155.0696 - val_mae: 9.4235\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 456.5607 - mae: 16.7336 - val_loss: 143.0353 - val_mae: 8.8081\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 480.8434 - mae: 17.0548 - val_loss: 201.1342 - val_mae: 11.1153\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 444.6233 - mae: 16.4590 - val_loss: 157.3857 - val_mae: 9.5379\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 440.1744 - mae: 16.4861 - val_loss: 147.5875 - val_mae: 9.1739\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 426.2223 - mae: 16.0142 - val_loss: 145.9552 - val_mae: 9.0843\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 420.8909 - mae: 15.8528 - val_loss: 232.9082 - val_mae: 12.3067\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 435.1870 - mae: 16.1264 - val_loss: 138.6670 - val_mae: 8.7464\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 439.6698 - mae: 16.4110 - val_loss: 200.3766 - val_mae: 10.9814\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 421.3245 - mae: 15.8632 - val_loss: 140.8461 - val_mae: 8.8656\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 418.4473 - mae: 15.9369 - val_loss: 166.7735 - val_mae: 9.8982\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 408.0438 - mae: 15.5743 - val_loss: 161.4362 - val_mae: 9.7605\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 437.2421 - mae: 15.9376 - val_loss: 215.0558 - val_mae: 11.8493\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 405.7586 - mae: 15.7183 - val_loss: 158.2039 - val_mae: 9.5502\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 412.1874 - mae: 15.7961 - val_loss: 159.1687 - val_mae: 9.6417\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 407.0221 - mae: 15.6988 - val_loss: 141.2942 - val_mae: 8.7484\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 427.6474 - mae: 16.0423 - val_loss: 150.7767 - val_mae: 9.2402\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 413.2474 - mae: 15.7031 - val_loss: 141.3825 - val_mae: 8.8472\n",
      "Epoch 31/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 412.6121 - mae: 15.7099 - val_loss: 161.9211 - val_mae: 9.7029\n",
      "Epoch 32/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 406.2980 - mae: 15.7578 - val_loss: 136.6022 - val_mae: 8.5867\n",
      "Epoch 33/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 404.9149 - mae: 15.6636 - val_loss: 140.5939 - val_mae: 8.6966\n",
      "Epoch 34/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 410.5096 - mae: 15.7229 - val_loss: 132.9930 - val_mae: 8.4042\n",
      "Epoch 35/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 402.9817 - mae: 15.5816 - val_loss: 136.0671 - val_mae: 8.6109\n",
      "Epoch 36/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 404.0530 - mae: 15.6709 - val_loss: 165.9320 - val_mae: 9.6226\n",
      "Epoch 37/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 410.6749 - mae: 15.8409 - val_loss: 140.4305 - val_mae: 8.8448\n",
      "Epoch 38/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 370.1323 - mae: 14.8005 - val_loss: 153.2428 - val_mae: 9.2839\n",
      "Epoch 39/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 403.0517 - mae: 15.3171 - val_loss: 141.3405 - val_mae: 8.8570\n",
      "Epoch 40/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 396.6440 - mae: 15.2833 - val_loss: 225.4401 - val_mae: 12.2510\n",
      "Epoch 41/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 416.6691 - mae: 15.7114 - val_loss: 136.5856 - val_mae: 8.6767\n",
      "Epoch 42/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 394.8402 - mae: 15.4193 - val_loss: 148.6007 - val_mae: 9.2428\n",
      "Epoch 43/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 393.9747 - mae: 15.3107 - val_loss: 225.0585 - val_mae: 12.0938\n",
      "Epoch 44/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 410.2952 - mae: 15.6367 - val_loss: 131.8714 - val_mae: 8.4864\n",
      "Epoch 45/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 381.7270 - mae: 15.0990 - val_loss: 130.6699 - val_mae: 8.4261\n",
      "Epoch 46/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 381.4527 - mae: 15.0973 - val_loss: 136.3260 - val_mae: 8.6782\n",
      "Epoch 47/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 396.1788 - mae: 15.3407 - val_loss: 130.3223 - val_mae: 8.3574\n",
      "Epoch 48/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 371.8730 - mae: 14.9194 - val_loss: 141.8231 - val_mae: 8.9171\n",
      "Epoch 49/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379.1044 - mae: 15.0998 - val_loss: 132.2054 - val_mae: 8.4777\n",
      "Epoch 50/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 405.0406 - mae: 15.4606 - val_loss: 137.6080 - val_mae: 8.7048\n",
      "Epoch 51/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 387.2311 - mae: 15.3279 - val_loss: 128.2643 - val_mae: 8.2574\n",
      "Epoch 52/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 394.8442 - mae: 15.4904 - val_loss: 133.8753 - val_mae: 8.6390\n",
      "Epoch 53/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 375.6918 - mae: 14.9209 - val_loss: 144.6508 - val_mae: 8.8756\n",
      "Epoch 54/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 383.5297 - mae: 15.0213 - val_loss: 138.2981 - val_mae: 8.7488\n",
      "Epoch 55/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 379.6506 - mae: 14.9939 - val_loss: 149.3631 - val_mae: 9.1774\n",
      "Epoch 56/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 367.5527 - mae: 14.8727 - val_loss: 143.7228 - val_mae: 9.1153\n",
      "Epoch 57/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 378.1376 - mae: 15.0650 - val_loss: 131.0350 - val_mae: 8.5098\n",
      "Epoch 58/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 366.7446 - mae: 14.8364 - val_loss: 131.3853 - val_mae: 8.4986\n",
      "Epoch 59/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 365.7237 - mae: 14.8937 - val_loss: 143.2995 - val_mae: 8.9547\n",
      "Epoch 60/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 371.4513 - mae: 14.9713 - val_loss: 129.3468 - val_mae: 8.3404\n",
      "Epoch 61/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 385.5446 - mae: 14.9524 - val_loss: 133.8401 - val_mae: 8.5766\n",
      "Epoch 62/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 358.5776 - mae: 14.8004 - val_loss: 129.1287 - val_mae: 8.3338\n",
      "Epoch 63/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 365.5960 - mae: 14.7466 - val_loss: 126.1914 - val_mae: 8.2127\n",
      "Epoch 64/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 390.1271 - mae: 15.2688 - val_loss: 206.6979 - val_mae: 11.3694\n",
      "Epoch 65/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 359.1366 - mae: 14.6534 - val_loss: 134.8549 - val_mae: 8.5516\n",
      "Epoch 66/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 372.1899 - mae: 15.0372 - val_loss: 217.8776 - val_mae: 12.0373\n",
      "Epoch 67/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 370.4717 - mae: 14.7655 - val_loss: 176.0893 - val_mae: 10.4551\n",
      "Epoch 68/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 364.8960 - mae: 14.8645 - val_loss: 131.3368 - val_mae: 8.4818\n",
      "Epoch 69/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 367.6361 - mae: 14.8619 - val_loss: 143.6635 - val_mae: 8.9661\n",
      "Epoch 70/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 372.6780 - mae: 14.7758 - val_loss: 136.6710 - val_mae: 8.6768\n",
      "Epoch 71/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 356.3358 - mae: 14.7605 - val_loss: 143.6721 - val_mae: 9.1275\n",
      "Epoch 72/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 347.3776 - mae: 14.3305 - val_loss: 135.9003 - val_mae: 8.7214\n",
      "Epoch 73/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 370.5215 - mae: 14.7331 - val_loss: 137.3539 - val_mae: 8.7717\n",
      "Epoch 74/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 362.1977 - mae: 14.6604 - val_loss: 126.7115 - val_mae: 8.2907\n",
      "Epoch 75/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 374.1278 - mae: 15.0325 - val_loss: 127.2139 - val_mae: 8.3565\n",
      "Epoch 76/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 348.8186 - mae: 14.3783 - val_loss: 125.3181 - val_mae: 8.1325\n",
      "Epoch 77/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 358.1444 - mae: 14.6460 - val_loss: 131.8930 - val_mae: 8.4295\n",
      "Epoch 78/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 334.8749 - mae: 14.1539 - val_loss: 134.6073 - val_mae: 8.6573\n",
      "Epoch 79/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 353.4788 - mae: 14.5988 - val_loss: 161.9599 - val_mae: 9.8606\n",
      "Epoch 80/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 347.0578 - mae: 14.5798 - val_loss: 160.4387 - val_mae: 9.7201\n",
      "Epoch 81/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 350.4897 - mae: 14.5622 - val_loss: 133.1705 - val_mae: 8.5062\n",
      "Epoch 82/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 340.0426 - mae: 14.2479 - val_loss: 134.6732 - val_mae: 8.7324\n",
      "Epoch 83/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 364.9934 - mae: 14.6799 - val_loss: 147.3992 - val_mae: 9.1621\n",
      "Epoch 84/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 345.6955 - mae: 14.2991 - val_loss: 131.0362 - val_mae: 8.4388\n",
      "Epoch 85/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 365.1602 - mae: 14.7632 - val_loss: 148.2887 - val_mae: 9.1019\n",
      "Epoch 86/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 363.9881 - mae: 14.8538 - val_loss: 135.8374 - val_mae: 8.6818\n",
      "Epoch 87/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 357.1272 - mae: 14.6312 - val_loss: 126.0327 - val_mae: 8.2007\n",
      "Epoch 88/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 354.0908 - mae: 14.5456 - val_loss: 136.7957 - val_mae: 8.6262\n",
      "Epoch 89/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 361.7617 - mae: 14.6204 - val_loss: 132.1424 - val_mae: 8.4934\n",
      "Epoch 90/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 347.6317 - mae: 14.4358 - val_loss: 197.3891 - val_mae: 11.1066\n",
      "Epoch 91/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 347.8000 - mae: 14.4465 - val_loss: 137.4393 - val_mae: 8.8753\n",
      "Epoch 92/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 359.5042 - mae: 14.6648 - val_loss: 125.6448 - val_mae: 8.1543\n",
      "Epoch 93/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 340.7458 - mae: 14.1180 - val_loss: 175.5548 - val_mae: 10.3442\n",
      "Epoch 94/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 348.6912 - mae: 14.3813 - val_loss: 128.3092 - val_mae: 8.3846\n",
      "Epoch 95/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 342.4546 - mae: 14.3572 - val_loss: 139.5984 - val_mae: 8.8946\n",
      "Epoch 96/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 348.8004 - mae: 14.3062 - val_loss: 139.2205 - val_mae: 8.9003\n",
      "Epoch 97/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 357.6200 - mae: 14.6102 - val_loss: 136.4927 - val_mae: 8.5842\n",
      "Epoch 98/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 358.3654 - mae: 14.5190 - val_loss: 135.3727 - val_mae: 8.5845\n",
      "Epoch 99/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 354.2902 - mae: 14.5806 - val_loss: 125.0859 - val_mae: 8.2938\n",
      "Epoch 100/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 336.3571 - mae: 14.2726 - val_loss: 123.5013 - val_mae: 8.1144\n",
      "Epoch 101/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 346.6211 - mae: 14.5575 - val_loss: 121.0936 - val_mae: 8.1014\n",
      "Epoch 102/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 342.9600 - mae: 14.2155 - val_loss: 199.5545 - val_mae: 11.3435\n",
      "Epoch 103/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 344.6161 - mae: 14.2501 - val_loss: 123.6994 - val_mae: 8.1492\n",
      "Epoch 104/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 326.8702 - mae: 14.0289 - val_loss: 126.3109 - val_mae: 8.3034\n",
      "Epoch 105/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 352.5468 - mae: 14.5441 - val_loss: 136.2810 - val_mae: 8.7121\n",
      "Epoch 106/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 335.8372 - mae: 14.2114 - val_loss: 143.9942 - val_mae: 9.1030\n",
      "Epoch 107/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 331.4091 - mae: 14.0593 - val_loss: 122.0153 - val_mae: 8.0761\n",
      "Epoch 108/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 330.7180 - mae: 14.0879 - val_loss: 124.6676 - val_mae: 8.1216\n",
      "Epoch 109/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 349.2035 - mae: 14.2026 - val_loss: 121.7337 - val_mae: 8.0119\n",
      "Epoch 110/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 347.0734 - mae: 14.1867 - val_loss: 121.5593 - val_mae: 8.1179\n",
      "Epoch 111/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 329.0181 - mae: 13.9528 - val_loss: 126.8100 - val_mae: 8.3379\n",
      "Epoch 112/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 346.7613 - mae: 14.2752 - val_loss: 120.0324 - val_mae: 7.9676\n",
      "Epoch 113/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 340.4831 - mae: 14.0199 - val_loss: 138.9668 - val_mae: 8.7923\n",
      "Epoch 114/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 336.4523 - mae: 14.2050 - val_loss: 123.1161 - val_mae: 8.1593\n",
      "Epoch 115/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 326.2934 - mae: 13.8352 - val_loss: 131.2127 - val_mae: 8.4199\n",
      "Epoch 116/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 327.8411 - mae: 13.9240 - val_loss: 125.5474 - val_mae: 8.1135\n",
      "Epoch 117/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 347.6645 - mae: 14.3479 - val_loss: 120.1496 - val_mae: 8.0139\n",
      "Epoch 118/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 356.8211 - mae: 14.2039 - val_loss: 169.5823 - val_mae: 9.9804\n",
      "Epoch 119/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 338.3185 - mae: 14.0508 - val_loss: 125.2730 - val_mae: 8.2814\n",
      "Epoch 120/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 326.5284 - mae: 13.8320 - val_loss: 128.6177 - val_mae: 8.4691\n",
      "Epoch 121/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 330.3449 - mae: 13.9014 - val_loss: 126.7130 - val_mae: 8.2809\n",
      "Epoch 122/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 325.5737 - mae: 13.8139 - val_loss: 141.6561 - val_mae: 8.9018\n",
      "Epoch 123/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 330.0666 - mae: 13.8815 - val_loss: 130.5739 - val_mae: 8.5745\n",
      "Epoch 124/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 329.9013 - mae: 13.9745 - val_loss: 186.6765 - val_mae: 10.8791\n",
      "Epoch 125/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 319.7776 - mae: 13.9325 - val_loss: 121.8483 - val_mae: 8.0317\n",
      "Epoch 126/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 321.4068 - mae: 13.7816 - val_loss: 122.2165 - val_mae: 8.1376\n",
      "Epoch 127/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 318.0330 - mae: 13.7397 - val_loss: 120.3689 - val_mae: 8.0417\n",
      "Epoch 128/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 310.4604 - mae: 13.5611 - val_loss: 118.8969 - val_mae: 7.9755\n",
      "Epoch 129/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 336.5576 - mae: 13.9483 - val_loss: 121.0020 - val_mae: 8.0634\n",
      "Epoch 130/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 325.2009 - mae: 13.8526 - val_loss: 124.7778 - val_mae: 8.2119\n",
      "Epoch 131/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 327.7415 - mae: 13.9326 - val_loss: 127.8237 - val_mae: 8.2920\n",
      "Epoch 132/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 317.8968 - mae: 13.7724 - val_loss: 146.8031 - val_mae: 9.1462\n",
      "Epoch 133/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 334.5377 - mae: 14.0425 - val_loss: 135.8923 - val_mae: 8.6492\n",
      "Epoch 134/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 319.5975 - mae: 13.7377 - val_loss: 143.5952 - val_mae: 9.1158\n",
      "Epoch 135/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 307.8336 - mae: 13.5344 - val_loss: 120.5547 - val_mae: 8.0173\n",
      "Epoch 136/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 329.1613 - mae: 13.9073 - val_loss: 162.2517 - val_mae: 9.6857\n",
      "Epoch 137/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 300.8449 - mae: 13.4247 - val_loss: 142.2165 - val_mae: 8.9507\n",
      "Epoch 138/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 331.2903 - mae: 13.8739 - val_loss: 129.7988 - val_mae: 8.4614\n",
      "Epoch 139/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 319.6224 - mae: 13.4036 - val_loss: 122.9635 - val_mae: 8.1284\n",
      "Epoch 140/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 312.9880 - mae: 13.6106 - val_loss: 148.9871 - val_mae: 9.2297\n",
      "Epoch 141/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 305.8750 - mae: 13.3850 - val_loss: 165.5593 - val_mae: 9.9811\n",
      "Epoch 142/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 309.9083 - mae: 13.4651 - val_loss: 122.1540 - val_mae: 8.0673\n",
      "Epoch 143/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 306.7364 - mae: 13.5303 - val_loss: 126.8103 - val_mae: 8.2610\n",
      "Epoch 144/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 321.2528 - mae: 13.5600 - val_loss: 149.0146 - val_mae: 9.2598\n",
      "Epoch 145/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 307.2914 - mae: 13.5610 - val_loss: 125.0695 - val_mae: 8.2638\n",
      "Epoch 146/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 294.9227 - mae: 13.2419 - val_loss: 121.0312 - val_mae: 8.0637\n",
      "Epoch 147/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 322.7150 - mae: 13.7618 - val_loss: 124.3957 - val_mae: 8.1825\n",
      "Epoch 148/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 304.3892 - mae: 13.3435 - val_loss: 122.2481 - val_mae: 8.0765\n",
      "Epoch 149/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 302.0547 - mae: 13.4360 - val_loss: 158.6643 - val_mae: 9.6107\n",
      "Epoch 150/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 308.2170 - mae: 13.5024 - val_loss: 122.5092 - val_mae: 8.1112\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.1368 - mae: 8.0560\n",
      "Patience 40: Validation MAE: 7.98\n",
      "Patience 40: Validation Loss: 118.90\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1772.0265 - mae: 30.2557 - val_loss: 314.8136 - val_mae: 13.3434\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 679.1856 - mae: 20.3728 - val_loss: 268.9735 - val_mae: 13.3128\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 593.3663 - mae: 19.1021 - val_loss: 192.5931 - val_mae: 10.7536\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 577.5630 - mae: 18.4240 - val_loss: 184.8130 - val_mae: 10.3772\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 525.6070 - mae: 18.1174 - val_loss: 187.5832 - val_mae: 10.6065\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 509.1122 - mae: 17.8284 - val_loss: 201.3905 - val_mae: 10.7799\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 532.9263 - mae: 17.9885 - val_loss: 209.1782 - val_mae: 11.4608\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 499.9602 - mae: 17.6398 - val_loss: 154.0854 - val_mae: 9.4480\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 457.6883 - mae: 16.6767 - val_loss: 153.1576 - val_mae: 9.2530\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 486.9195 - mae: 17.3565 - val_loss: 215.4321 - val_mae: 11.1295\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 457.0716 - mae: 16.5339 - val_loss: 182.8258 - val_mae: 10.3517\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 432.8035 - mae: 16.1818 - val_loss: 173.6094 - val_mae: 10.0958\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 451.8876 - mae: 16.5387 - val_loss: 150.2302 - val_mae: 9.1800\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 454.8775 - mae: 16.4818 - val_loss: 142.6358 - val_mae: 8.9055\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 448.6631 - mae: 16.3115 - val_loss: 165.2287 - val_mae: 9.7630\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 433.4882 - mae: 16.3713 - val_loss: 163.4456 - val_mae: 9.9749\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 461.7176 - mae: 16.6003 - val_loss: 146.4062 - val_mae: 9.1976\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 436.1130 - mae: 16.0367 - val_loss: 151.7440 - val_mae: 9.1884\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 430.2320 - mae: 16.1865 - val_loss: 145.7106 - val_mae: 8.9406\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 394.9078 - mae: 15.3840 - val_loss: 142.7984 - val_mae: 9.0704\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 436.1536 - mae: 16.1600 - val_loss: 152.9390 - val_mae: 9.0726\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 434.8466 - mae: 15.9912 - val_loss: 140.3995 - val_mae: 8.8232\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 421.8102 - mae: 15.9323 - val_loss: 172.4655 - val_mae: 9.9331\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 420.5045 - mae: 15.8927 - val_loss: 162.9820 - val_mae: 9.5868\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 450.9694 - mae: 16.2660 - val_loss: 138.2746 - val_mae: 8.8677\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 440.1937 - mae: 16.1463 - val_loss: 136.1392 - val_mae: 8.6951\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.1877 - mae: 15.8347 - val_loss: 141.6105 - val_mae: 9.0126\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 421.7068 - mae: 15.8740 - val_loss: 157.5501 - val_mae: 9.3517\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 425.4820 - mae: 16.0714 - val_loss: 141.4081 - val_mae: 8.8435\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 409.2571 - mae: 15.5566 - val_loss: 134.9784 - val_mae: 8.5321\n",
      "Epoch 31/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 423.9178 - mae: 16.1161 - val_loss: 155.5555 - val_mae: 9.4017\n",
      "Epoch 32/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 413.1729 - mae: 15.7773 - val_loss: 135.7816 - val_mae: 8.6193\n",
      "Epoch 33/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 427.8700 - mae: 15.9249 - val_loss: 143.3512 - val_mae: 8.8942\n",
      "Epoch 34/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 420.8524 - mae: 15.9723 - val_loss: 151.3920 - val_mae: 9.3663\n",
      "Epoch 35/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 395.9771 - mae: 15.6384 - val_loss: 134.0892 - val_mae: 8.6180\n",
      "Epoch 36/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 412.8593 - mae: 15.5933 - val_loss: 173.1581 - val_mae: 10.3767\n",
      "Epoch 37/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 388.0674 - mae: 15.3074 - val_loss: 143.3839 - val_mae: 8.7149\n",
      "Epoch 38/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 402.6431 - mae: 15.4876 - val_loss: 146.5307 - val_mae: 9.0980\n",
      "Epoch 39/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382.7695 - mae: 15.2098 - val_loss: 184.2061 - val_mae: 10.7234\n",
      "Epoch 40/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 415.7513 - mae: 15.8700 - val_loss: 141.8798 - val_mae: 8.9513\n",
      "Epoch 41/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 386.0803 - mae: 15.3640 - val_loss: 135.9211 - val_mae: 8.6709\n",
      "Epoch 42/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 395.3549 - mae: 15.3063 - val_loss: 128.6910 - val_mae: 8.2574\n",
      "Epoch 43/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 398.9227 - mae: 15.4180 - val_loss: 167.1369 - val_mae: 9.7597\n",
      "Epoch 44/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 392.6600 - mae: 15.4069 - val_loss: 135.1391 - val_mae: 8.6840\n",
      "Epoch 45/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 384.9975 - mae: 15.1842 - val_loss: 139.7302 - val_mae: 9.0317\n",
      "Epoch 46/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 387.9279 - mae: 15.0510 - val_loss: 131.7749 - val_mae: 8.4942\n",
      "Epoch 47/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 392.2107 - mae: 15.3474 - val_loss: 155.3272 - val_mae: 9.4271\n",
      "Epoch 48/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 379.6229 - mae: 15.0750 - val_loss: 130.2357 - val_mae: 8.3799\n",
      "Epoch 49/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 388.2787 - mae: 15.2466 - val_loss: 136.8322 - val_mae: 8.6741\n",
      "Epoch 50/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 370.9326 - mae: 14.8307 - val_loss: 192.3260 - val_mae: 10.8495\n",
      "Epoch 51/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377.3980 - mae: 14.9232 - val_loss: 142.7970 - val_mae: 8.9972\n",
      "Epoch 52/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 360.1156 - mae: 14.5804 - val_loss: 139.9553 - val_mae: 8.9669\n",
      "Epoch 53/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 385.6367 - mae: 15.0022 - val_loss: 145.3100 - val_mae: 8.8351\n",
      "Epoch 54/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380.1989 - mae: 15.1139 - val_loss: 145.9361 - val_mae: 9.1691\n",
      "Epoch 55/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387.6487 - mae: 15.4442 - val_loss: 190.5805 - val_mae: 10.8785\n",
      "Epoch 56/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 374.4815 - mae: 15.0813 - val_loss: 137.9681 - val_mae: 8.8887\n",
      "Epoch 57/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 384.0606 - mae: 15.0647 - val_loss: 133.2911 - val_mae: 8.4696\n",
      "Epoch 58/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 392.3723 - mae: 15.2813 - val_loss: 133.7150 - val_mae: 8.5971\n",
      "Epoch 59/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377.6998 - mae: 14.9561 - val_loss: 129.5410 - val_mae: 8.3143\n",
      "Epoch 60/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 386.9392 - mae: 14.9991 - val_loss: 177.8543 - val_mae: 10.3097\n",
      "Epoch 61/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 373.6432 - mae: 15.0359 - val_loss: 129.4480 - val_mae: 8.3009\n",
      "Epoch 62/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 358.4472 - mae: 14.8196 - val_loss: 187.8303 - val_mae: 11.0021\n",
      "Epoch 63/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 371.1513 - mae: 14.8677 - val_loss: 141.8918 - val_mae: 8.9900\n",
      "Epoch 64/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 351.8206 - mae: 14.3651 - val_loss: 131.6177 - val_mae: 8.4383\n",
      "Epoch 65/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 374.0846 - mae: 15.0254 - val_loss: 127.9882 - val_mae: 8.3471\n",
      "Epoch 66/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 365.1581 - mae: 14.8708 - val_loss: 143.9357 - val_mae: 9.0239\n",
      "Epoch 67/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387.0180 - mae: 15.3061 - val_loss: 133.5956 - val_mae: 8.6162\n",
      "Epoch 68/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 380.4184 - mae: 15.0080 - val_loss: 132.1812 - val_mae: 8.4609\n",
      "Epoch 69/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 374.8956 - mae: 14.9143 - val_loss: 139.0735 - val_mae: 8.8920\n",
      "Epoch 70/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 376.6523 - mae: 14.9150 - val_loss: 134.8126 - val_mae: 8.7365\n",
      "Epoch 71/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 366.2636 - mae: 14.9217 - val_loss: 149.4027 - val_mae: 9.1682\n",
      "Epoch 72/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 374.0034 - mae: 14.9516 - val_loss: 163.8617 - val_mae: 9.8870\n",
      "Epoch 73/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 368.2698 - mae: 14.9769 - val_loss: 151.0574 - val_mae: 9.4572\n",
      "Epoch 74/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.4650 - mae: 14.7775 - val_loss: 129.7427 - val_mae: 8.2762\n",
      "Epoch 75/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 367.1127 - mae: 14.8192 - val_loss: 126.9872 - val_mae: 8.2996\n",
      "Epoch 76/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 350.7322 - mae: 14.6160 - val_loss: 171.6976 - val_mae: 10.2734\n",
      "Epoch 77/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 371.4675 - mae: 15.1024 - val_loss: 123.7959 - val_mae: 8.2528\n",
      "Epoch 78/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 356.8661 - mae: 14.6973 - val_loss: 128.2845 - val_mae: 8.3022\n",
      "Epoch 79/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 343.0124 - mae: 14.3833 - val_loss: 162.1466 - val_mae: 9.9134\n",
      "Epoch 80/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 361.7336 - mae: 14.5833 - val_loss: 126.9221 - val_mae: 8.2392\n",
      "Epoch 81/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 384.0448 - mae: 14.7882 - val_loss: 131.2711 - val_mae: 8.4700\n",
      "Epoch 82/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 363.2195 - mae: 14.7775 - val_loss: 169.8179 - val_mae: 9.9614\n",
      "Epoch 83/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 365.7324 - mae: 14.8776 - val_loss: 139.4794 - val_mae: 9.0316\n",
      "Epoch 84/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 345.9995 - mae: 14.4814 - val_loss: 134.6346 - val_mae: 8.6364\n",
      "Epoch 85/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 356.7491 - mae: 14.6305 - val_loss: 148.0907 - val_mae: 9.4920\n",
      "Epoch 86/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 363.4903 - mae: 14.4921 - val_loss: 133.1851 - val_mae: 8.5517\n",
      "Epoch 87/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 360.1290 - mae: 14.3003 - val_loss: 130.2734 - val_mae: 8.5389\n",
      "Epoch 88/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 345.5626 - mae: 14.2166 - val_loss: 144.2681 - val_mae: 9.0048\n",
      "Epoch 89/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 368.5881 - mae: 14.8098 - val_loss: 122.6159 - val_mae: 8.0169\n",
      "Epoch 90/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 341.3770 - mae: 14.2840 - val_loss: 164.7980 - val_mae: 10.0834\n",
      "Epoch 91/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 350.2493 - mae: 14.3736 - val_loss: 129.8150 - val_mae: 8.4478\n",
      "Epoch 92/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 344.8021 - mae: 14.2789 - val_loss: 140.7367 - val_mae: 9.0323\n",
      "Epoch 93/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 348.5790 - mae: 14.4062 - val_loss: 129.8710 - val_mae: 8.3996\n",
      "Epoch 94/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 373.3940 - mae: 14.7254 - val_loss: 123.8490 - val_mae: 8.1652\n",
      "Epoch 95/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 352.0332 - mae: 14.4370 - val_loss: 123.6183 - val_mae: 8.1452\n",
      "Epoch 96/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 361.1570 - mae: 14.5822 - val_loss: 123.8844 - val_mae: 8.0453\n",
      "Epoch 97/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 340.3878 - mae: 14.1368 - val_loss: 155.9156 - val_mae: 9.4442\n",
      "Epoch 98/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 361.9818 - mae: 14.5789 - val_loss: 141.6570 - val_mae: 9.1293\n",
      "Epoch 99/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 323.6895 - mae: 14.0113 - val_loss: 125.1504 - val_mae: 8.2803\n",
      "Epoch 100/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 342.9959 - mae: 14.3193 - val_loss: 140.7902 - val_mae: 9.0165\n",
      "Epoch 101/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 350.1758 - mae: 14.3377 - val_loss: 125.1942 - val_mae: 8.1871\n",
      "Epoch 102/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 342.3440 - mae: 14.1954 - val_loss: 127.6695 - val_mae: 8.4135\n",
      "Epoch 103/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 351.7977 - mae: 14.6324 - val_loss: 127.6353 - val_mae: 8.4618\n",
      "Epoch 104/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 340.1799 - mae: 14.2896 - val_loss: 139.0971 - val_mae: 8.7867\n",
      "Epoch 105/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 317.7760 - mae: 13.8285 - val_loss: 132.1107 - val_mae: 8.5564\n",
      "Epoch 106/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 348.0257 - mae: 14.5259 - val_loss: 149.3427 - val_mae: 9.2624\n",
      "Epoch 107/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 333.5508 - mae: 14.0202 - val_loss: 127.8565 - val_mae: 8.3772\n",
      "Epoch 108/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 340.7764 - mae: 14.2661 - val_loss: 123.1708 - val_mae: 8.2023\n",
      "Epoch 109/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 308.8326 - mae: 13.6660 - val_loss: 132.7840 - val_mae: 8.6415\n",
      "Epoch 110/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 345.1770 - mae: 14.3463 - val_loss: 129.7804 - val_mae: 8.5206\n",
      "Epoch 111/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 354.2442 - mae: 14.3979 - val_loss: 126.1487 - val_mae: 8.2553\n",
      "Epoch 112/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 335.1935 - mae: 14.2084 - val_loss: 127.3002 - val_mae: 8.3982\n",
      "Epoch 113/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 337.1603 - mae: 14.3168 - val_loss: 122.7316 - val_mae: 8.1023\n",
      "Epoch 114/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 345.9370 - mae: 14.2592 - val_loss: 139.2416 - val_mae: 8.5622\n",
      "Epoch 115/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 335.9595 - mae: 14.0641 - val_loss: 142.1019 - val_mae: 9.0229\n",
      "Epoch 116/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 326.0620 - mae: 14.0535 - val_loss: 119.8651 - val_mae: 7.9039\n",
      "Epoch 117/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 319.5577 - mae: 13.7064 - val_loss: 124.1580 - val_mae: 8.1645\n",
      "Epoch 118/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 345.0869 - mae: 14.2523 - val_loss: 128.2068 - val_mae: 8.4024\n",
      "Epoch 119/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 322.8493 - mae: 13.9510 - val_loss: 122.5225 - val_mae: 8.1717\n",
      "Epoch 120/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 334.6343 - mae: 14.1075 - val_loss: 125.1887 - val_mae: 8.3252\n",
      "Epoch 121/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 329.8103 - mae: 14.1657 - val_loss: 124.9174 - val_mae: 8.2805\n",
      "Epoch 122/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 350.0132 - mae: 14.1165 - val_loss: 127.0990 - val_mae: 8.2327\n",
      "Epoch 123/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 346.3818 - mae: 14.3171 - val_loss: 120.6910 - val_mae: 8.0970\n",
      "Epoch 124/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 317.4328 - mae: 13.9371 - val_loss: 135.9291 - val_mae: 8.8557\n",
      "Epoch 125/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 342.3054 - mae: 14.1590 - val_loss: 132.3202 - val_mae: 8.6312\n",
      "Epoch 126/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 320.0462 - mae: 13.8424 - val_loss: 126.3619 - val_mae: 8.2344\n",
      "Epoch 127/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 323.1620 - mae: 13.8412 - val_loss: 121.5416 - val_mae: 8.1063\n",
      "Epoch 128/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 350.9414 - mae: 14.4488 - val_loss: 176.4470 - val_mae: 10.5629\n",
      "Epoch 129/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 337.0110 - mae: 14.0711 - val_loss: 119.6257 - val_mae: 7.9779\n",
      "Epoch 130/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 329.1938 - mae: 13.7521 - val_loss: 118.3266 - val_mae: 7.9201\n",
      "Epoch 131/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 336.6571 - mae: 14.1779 - val_loss: 126.6415 - val_mae: 8.3256\n",
      "Epoch 132/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 341.9562 - mae: 14.0083 - val_loss: 128.2914 - val_mae: 8.3605\n",
      "Epoch 133/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 332.6428 - mae: 14.0551 - val_loss: 126.5798 - val_mae: 8.3978\n",
      "Epoch 134/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 308.5952 - mae: 13.4430 - val_loss: 146.2634 - val_mae: 9.2815\n",
      "Epoch 135/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 329.3554 - mae: 13.7029 - val_loss: 122.7460 - val_mae: 8.2418\n",
      "Epoch 136/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 311.2829 - mae: 13.5082 - val_loss: 142.8066 - val_mae: 9.1322\n",
      "Epoch 137/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 320.9506 - mae: 13.7045 - val_loss: 149.0095 - val_mae: 9.3638\n",
      "Epoch 138/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 355.0656 - mae: 14.2101 - val_loss: 127.8222 - val_mae: 8.3652\n",
      "Epoch 139/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 322.9193 - mae: 13.7343 - val_loss: 121.9218 - val_mae: 8.1005\n",
      "Epoch 140/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 324.0000 - mae: 13.8607 - val_loss: 125.6315 - val_mae: 8.3079\n",
      "Epoch 141/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 319.1003 - mae: 13.6571 - val_loss: 145.8133 - val_mae: 9.4075\n",
      "Epoch 142/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 326.4020 - mae: 13.7818 - val_loss: 119.5672 - val_mae: 8.0812\n",
      "Epoch 143/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 332.2286 - mae: 13.7000 - val_loss: 125.7998 - val_mae: 8.1332\n",
      "Epoch 144/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 320.0509 - mae: 13.5906 - val_loss: 125.8744 - val_mae: 8.3133\n",
      "Epoch 145/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 325.0184 - mae: 13.8588 - val_loss: 143.0031 - val_mae: 8.9582\n",
      "Epoch 146/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 317.5206 - mae: 13.6928 - val_loss: 144.4190 - val_mae: 9.1391\n",
      "Epoch 147/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 316.2599 - mae: 13.5070 - val_loss: 145.5443 - val_mae: 9.1579\n",
      "Epoch 148/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 303.5293 - mae: 13.5090 - val_loss: 123.8256 - val_mae: 8.2127\n",
      "Epoch 149/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 336.0742 - mae: 13.8301 - val_loss: 133.3373 - val_mae: 8.6032\n",
      "Epoch 150/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 312.8592 - mae: 13.7552 - val_loss: 131.3481 - val_mae: 8.4568\n",
      "Patience 30: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.6705 - mae: 7.9954\n",
      "Patience 30: Validation MAE: 7.92\n",
      "Patience 30: Validation Loss: 118.33\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1913.3014 - mae: 31.0453 - val_loss: 311.9320 - val_mae: 14.8257\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 765.7222 - mae: 21.7963 - val_loss: 351.9281 - val_mae: 14.0261\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 699.0012 - mae: 20.7592 - val_loss: 283.9271 - val_mae: 13.8404\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 639.6608 - mae: 19.8217 - val_loss: 273.2759 - val_mae: 12.7244\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 603.6207 - mae: 19.2064 - val_loss: 213.1069 - val_mae: 11.0793\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 576.0417 - mae: 18.5261 - val_loss: 176.2230 - val_mae: 10.1595\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 546.8146 - mae: 18.1097 - val_loss: 334.7170 - val_mae: 14.9380\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 582.3268 - mae: 18.8281 - val_loss: 162.9467 - val_mae: 9.6039\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 538.8556 - mae: 18.3352 - val_loss: 153.7723 - val_mae: 9.2179\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 507.8737 - mae: 17.6588 - val_loss: 154.7591 - val_mae: 9.3523\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 489.3162 - mae: 17.3541 - val_loss: 157.1575 - val_mae: 9.4735\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 502.5732 - mae: 17.5582 - val_loss: 152.6515 - val_mae: 9.1834\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 475.1656 - mae: 17.0548 - val_loss: 222.2106 - val_mae: 11.7952\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 478.7876 - mae: 17.1523 - val_loss: 167.2056 - val_mae: 10.0378\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 472.3727 - mae: 17.0678 - val_loss: 231.3913 - val_mae: 12.3328\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 474.5159 - mae: 17.1093 - val_loss: 202.0882 - val_mae: 11.1989\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 489.9928 - mae: 17.1921 - val_loss: 146.4339 - val_mae: 8.9617\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 449.5807 - mae: 16.6975 - val_loss: 215.5476 - val_mae: 11.8742\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 485.9869 - mae: 17.2957 - val_loss: 156.3992 - val_mae: 9.1920\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 487.0883 - mae: 17.2679 - val_loss: 175.4390 - val_mae: 10.3422\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 508.0625 - mae: 17.4652 - val_loss: 162.3997 - val_mae: 9.8485\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 487.1320 - mae: 16.9693 - val_loss: 142.1411 - val_mae: 8.8696\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 477.4179 - mae: 16.9315 - val_loss: 155.4893 - val_mae: 9.3546\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 478.7242 - mae: 16.9811 - val_loss: 138.4237 - val_mae: 8.7454\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 474.8903 - mae: 16.9329 - val_loss: 153.2556 - val_mae: 9.3888\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 470.5092 - mae: 16.8152 - val_loss: 156.5466 - val_mae: 9.4614\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 479.6342 - mae: 16.9552 - val_loss: 139.2907 - val_mae: 8.7561\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 470.3771 - mae: 16.6745 - val_loss: 142.9782 - val_mae: 8.9363\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 473.1602 - mae: 16.9422 - val_loss: 147.5524 - val_mae: 9.2562\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 482.7558 - mae: 16.9425 - val_loss: 148.0936 - val_mae: 9.2194\n",
      "Epoch 31/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 466.3492 - mae: 16.8169 - val_loss: 166.7680 - val_mae: 9.9496\n",
      "Epoch 32/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 468.6859 - mae: 16.7894 - val_loss: 145.4887 - val_mae: 8.9098\n",
      "Epoch 33/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 470.1332 - mae: 16.9646 - val_loss: 260.4785 - val_mae: 13.1539\n",
      "Epoch 34/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 469.5911 - mae: 16.8919 - val_loss: 184.7421 - val_mae: 10.6466\n",
      "Epoch 35/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 464.8226 - mae: 16.7755 - val_loss: 138.4043 - val_mae: 8.7457\n",
      "Epoch 36/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 453.7261 - mae: 16.6717 - val_loss: 138.3227 - val_mae: 8.8394\n",
      "Epoch 37/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 431.3190 - mae: 16.3875 - val_loss: 143.4073 - val_mae: 8.8658\n",
      "Epoch 38/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 451.6239 - mae: 16.5767 - val_loss: 134.1467 - val_mae: 8.5730\n",
      "Epoch 39/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 446.1664 - mae: 16.4203 - val_loss: 140.9604 - val_mae: 8.8271\n",
      "Epoch 40/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 453.1728 - mae: 16.4360 - val_loss: 154.5936 - val_mae: 9.3473\n",
      "Epoch 41/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 456.3827 - mae: 16.4730 - val_loss: 146.1897 - val_mae: 9.0246\n",
      "Epoch 42/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 422.6436 - mae: 16.0611 - val_loss: 138.4539 - val_mae: 8.6975\n",
      "Epoch 43/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 441.6422 - mae: 16.3450 - val_loss: 133.5542 - val_mae: 8.5918\n",
      "Epoch 44/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 426.4478 - mae: 16.0760 - val_loss: 136.4208 - val_mae: 8.6527\n",
      "Epoch 45/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 409.7847 - mae: 15.6518 - val_loss: 133.7838 - val_mae: 8.5401\n",
      "Epoch 46/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 444.4954 - mae: 16.3119 - val_loss: 160.6758 - val_mae: 9.5471\n",
      "Epoch 47/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 427.4225 - mae: 16.2011 - val_loss: 169.3627 - val_mae: 10.2712\n",
      "Epoch 48/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 445.3256 - mae: 16.2908 - val_loss: 136.7271 - val_mae: 8.8647\n",
      "Epoch 49/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 452.3637 - mae: 16.5258 - val_loss: 143.3307 - val_mae: 9.1477\n",
      "Epoch 50/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 427.2121 - mae: 16.0934 - val_loss: 153.5899 - val_mae: 9.4523\n",
      "Epoch 51/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 438.8553 - mae: 16.1754 - val_loss: 149.0627 - val_mae: 9.1957\n",
      "Epoch 52/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 437.8364 - mae: 16.2562 - val_loss: 138.0698 - val_mae: 8.6914\n",
      "Epoch 53/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 429.2642 - mae: 16.1553 - val_loss: 157.2124 - val_mae: 9.5385\n",
      "Epoch 54/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 401.1985 - mae: 15.6110 - val_loss: 126.9540 - val_mae: 8.2956\n",
      "Epoch 55/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 434.2687 - mae: 16.1762 - val_loss: 127.5284 - val_mae: 8.2951\n",
      "Epoch 56/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 416.6532 - mae: 15.7838 - val_loss: 160.6233 - val_mae: 9.6915\n",
      "Epoch 57/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 428.7604 - mae: 16.2099 - val_loss: 140.0368 - val_mae: 8.8281\n",
      "Epoch 58/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 405.5888 - mae: 15.7294 - val_loss: 195.4050 - val_mae: 11.1418\n",
      "Epoch 59/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 441.3305 - mae: 16.1668 - val_loss: 138.5821 - val_mae: 8.8335\n",
      "Epoch 60/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 406.4534 - mae: 15.6559 - val_loss: 128.7816 - val_mae: 8.4387\n",
      "Epoch 61/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 405.2327 - mae: 15.8070 - val_loss: 136.6552 - val_mae: 8.8170\n",
      "Epoch 62/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 391.8487 - mae: 15.3887 - val_loss: 146.3422 - val_mae: 9.2556\n",
      "Epoch 63/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 410.1957 - mae: 15.5909 - val_loss: 138.4108 - val_mae: 8.7604\n",
      "Epoch 64/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 444.9752 - mae: 16.4985 - val_loss: 163.9519 - val_mae: 10.1127\n",
      "Epoch 65/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 408.0425 - mae: 15.7807 - val_loss: 150.0215 - val_mae: 9.2177\n",
      "Epoch 66/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 403.4319 - mae: 15.5656 - val_loss: 134.3427 - val_mae: 8.6177\n",
      "Epoch 67/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 385.7315 - mae: 15.1914 - val_loss: 129.2295 - val_mae: 8.4101\n",
      "Epoch 68/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 412.8980 - mae: 15.8689 - val_loss: 126.6508 - val_mae: 8.3213\n",
      "Epoch 69/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 396.8784 - mae: 15.5096 - val_loss: 128.3098 - val_mae: 8.3530\n",
      "Epoch 70/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 408.8218 - mae: 15.6436 - val_loss: 153.8769 - val_mae: 9.5655\n",
      "Epoch 71/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 400.1796 - mae: 15.6664 - val_loss: 142.3934 - val_mae: 9.1050\n",
      "Epoch 72/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387.7017 - mae: 15.3437 - val_loss: 158.9304 - val_mae: 9.7700\n",
      "Epoch 73/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 402.9541 - mae: 15.7421 - val_loss: 201.8953 - val_mae: 11.2617\n",
      "Epoch 74/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 410.4638 - mae: 15.6376 - val_loss: 124.1117 - val_mae: 8.2156\n",
      "Epoch 75/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 386.9674 - mae: 15.2048 - val_loss: 159.4823 - val_mae: 9.6484\n",
      "Epoch 76/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 408.2582 - mae: 15.4488 - val_loss: 142.2333 - val_mae: 8.9790\n",
      "Epoch 77/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 416.9304 - mae: 15.8324 - val_loss: 185.8438 - val_mae: 10.7125\n",
      "Epoch 78/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 386.0839 - mae: 15.1907 - val_loss: 127.4556 - val_mae: 8.3729\n",
      "Epoch 79/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 403.7925 - mae: 15.5234 - val_loss: 139.6668 - val_mae: 8.8641\n",
      "Epoch 80/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 394.7047 - mae: 15.3528 - val_loss: 124.3034 - val_mae: 8.1811\n",
      "Epoch 81/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 391.8689 - mae: 15.2164 - val_loss: 156.0445 - val_mae: 9.1187\n",
      "Epoch 82/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 408.2341 - mae: 15.5681 - val_loss: 169.6171 - val_mae: 10.1982\n",
      "Epoch 83/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 404.7598 - mae: 15.5832 - val_loss: 181.4048 - val_mae: 10.7741\n",
      "Epoch 84/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 382.2491 - mae: 15.3004 - val_loss: 128.3897 - val_mae: 8.5631\n",
      "Epoch 85/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 393.1016 - mae: 15.3106 - val_loss: 159.5379 - val_mae: 9.9179\n",
      "Epoch 86/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 373.0414 - mae: 15.1917 - val_loss: 148.8260 - val_mae: 9.4363\n",
      "Epoch 87/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 383.5233 - mae: 15.3103 - val_loss: 143.0731 - val_mae: 8.8698\n",
      "Epoch 88/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 390.4499 - mae: 15.0744 - val_loss: 138.1492 - val_mae: 8.8207\n",
      "Epoch 89/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 397.2854 - mae: 15.2954 - val_loss: 126.6970 - val_mae: 8.3600\n",
      "Epoch 90/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 408.6213 - mae: 15.5677 - val_loss: 131.0435 - val_mae: 8.5560\n",
      "Epoch 91/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377.6389 - mae: 15.0756 - val_loss: 167.3272 - val_mae: 9.9582\n",
      "Epoch 92/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 368.3669 - mae: 15.0413 - val_loss: 123.7511 - val_mae: 8.2167\n",
      "Epoch 93/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 382.3373 - mae: 15.2383 - val_loss: 141.0109 - val_mae: 8.7677\n",
      "Epoch 94/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 353.2032 - mae: 14.6432 - val_loss: 125.3915 - val_mae: 8.2563\n",
      "Epoch 95/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 369.2058 - mae: 15.0086 - val_loss: 170.3042 - val_mae: 10.1900\n",
      "Epoch 96/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 401.2427 - mae: 15.3704 - val_loss: 140.6047 - val_mae: 8.9863\n",
      "Epoch 97/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380.5979 - mae: 15.0793 - val_loss: 153.4631 - val_mae: 9.4200\n",
      "Epoch 98/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375.7393 - mae: 14.8358 - val_loss: 123.4952 - val_mae: 8.1697\n",
      "Epoch 99/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 371.0401 - mae: 14.9438 - val_loss: 137.7184 - val_mae: 8.9216\n",
      "Epoch 100/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 364.0544 - mae: 14.8576 - val_loss: 146.7604 - val_mae: 9.2823\n",
      "Epoch 101/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 359.8477 - mae: 14.5728 - val_loss: 120.8752 - val_mae: 8.1770\n",
      "Epoch 102/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376.7617 - mae: 14.8981 - val_loss: 127.0426 - val_mae: 8.3853\n",
      "Epoch 103/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 365.2188 - mae: 14.6985 - val_loss: 148.5711 - val_mae: 9.2711\n",
      "Epoch 104/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 369.2022 - mae: 14.8593 - val_loss: 139.0613 - val_mae: 8.7262\n",
      "Epoch 105/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 368.8245 - mae: 14.6424 - val_loss: 124.0286 - val_mae: 8.2421\n",
      "Epoch 106/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 370.0723 - mae: 14.7712 - val_loss: 129.9462 - val_mae: 8.4092\n",
      "Epoch 107/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 364.4048 - mae: 14.9005 - val_loss: 132.1513 - val_mae: 8.4566\n",
      "Epoch 108/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 367.6505 - mae: 14.8634 - val_loss: 126.4201 - val_mae: 8.3358\n",
      "Epoch 109/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 356.7866 - mae: 14.6140 - val_loss: 121.6199 - val_mae: 8.0626\n",
      "Epoch 110/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 352.0474 - mae: 14.7802 - val_loss: 119.1169 - val_mae: 8.0603\n",
      "Epoch 111/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 361.1089 - mae: 14.6646 - val_loss: 128.9662 - val_mae: 8.3675\n",
      "Epoch 112/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 393.2229 - mae: 15.1746 - val_loss: 144.4460 - val_mae: 9.0038\n",
      "Epoch 113/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 353.1991 - mae: 14.5099 - val_loss: 133.3121 - val_mae: 8.6853\n",
      "Epoch 114/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 372.3994 - mae: 14.7134 - val_loss: 181.1941 - val_mae: 10.7161\n",
      "Epoch 115/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 371.7333 - mae: 14.8226 - val_loss: 139.7313 - val_mae: 8.9794\n",
      "Epoch 116/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 372.4943 - mae: 14.7341 - val_loss: 125.1331 - val_mae: 8.2396\n",
      "Epoch 117/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 354.2614 - mae: 14.3644 - val_loss: 133.2205 - val_mae: 8.6054\n",
      "Epoch 118/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 367.7433 - mae: 14.7803 - val_loss: 143.5567 - val_mae: 9.0733\n",
      "Epoch 119/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 341.6356 - mae: 14.4140 - val_loss: 119.7835 - val_mae: 8.0665\n",
      "Epoch 120/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 350.2572 - mae: 14.3737 - val_loss: 123.0465 - val_mae: 8.1916\n",
      "Epoch 121/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 346.7986 - mae: 14.2741 - val_loss: 124.3937 - val_mae: 8.2773\n",
      "Epoch 122/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 367.0127 - mae: 14.6850 - val_loss: 124.1651 - val_mae: 8.2346\n",
      "Epoch 123/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 333.9006 - mae: 14.2036 - val_loss: 117.7498 - val_mae: 7.9185\n",
      "Epoch 124/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 332.9689 - mae: 14.1017 - val_loss: 134.6506 - val_mae: 8.7558\n",
      "Epoch 125/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 336.0227 - mae: 14.1252 - val_loss: 131.8262 - val_mae: 8.5751\n",
      "Epoch 126/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 357.2256 - mae: 14.6111 - val_loss: 136.6708 - val_mae: 8.7228\n",
      "Epoch 127/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 347.4961 - mae: 14.3384 - val_loss: 124.8386 - val_mae: 8.2823\n",
      "Epoch 128/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 350.9890 - mae: 14.5527 - val_loss: 126.0121 - val_mae: 8.3964\n",
      "Epoch 129/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 370.5836 - mae: 14.6325 - val_loss: 131.7846 - val_mae: 8.6076\n",
      "Epoch 130/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 328.8736 - mae: 13.9470 - val_loss: 139.1017 - val_mae: 9.0042\n",
      "Epoch 131/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 355.1684 - mae: 14.4761 - val_loss: 117.4869 - val_mae: 7.8967\n",
      "Epoch 132/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 341.2367 - mae: 14.1435 - val_loss: 125.0249 - val_mae: 8.2357\n",
      "Epoch 133/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 368.3035 - mae: 14.6052 - val_loss: 128.6046 - val_mae: 8.4523\n",
      "Epoch 134/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 335.4758 - mae: 14.2145 - val_loss: 150.1107 - val_mae: 9.3009\n",
      "Epoch 135/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 334.2152 - mae: 14.1582 - val_loss: 125.2426 - val_mae: 8.2818\n",
      "Epoch 136/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 328.7657 - mae: 14.1122 - val_loss: 147.7059 - val_mae: 9.2346\n",
      "Epoch 137/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 363.1263 - mae: 14.3817 - val_loss: 117.7538 - val_mae: 7.9138\n",
      "Epoch 138/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 335.0684 - mae: 14.2079 - val_loss: 119.1023 - val_mae: 8.0264\n",
      "Epoch 139/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 334.6141 - mae: 13.9584 - val_loss: 122.0339 - val_mae: 8.0997\n",
      "Epoch 140/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 341.5796 - mae: 14.1748 - val_loss: 120.0051 - val_mae: 8.0550\n",
      "Epoch 141/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 318.8659 - mae: 13.7562 - val_loss: 120.7328 - val_mae: 8.0874\n",
      "Epoch 142/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 340.7684 - mae: 14.1403 - val_loss: 119.7561 - val_mae: 7.9712\n",
      "Epoch 143/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 317.3945 - mae: 13.8173 - val_loss: 122.7539 - val_mae: 8.2206\n",
      "Epoch 144/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 342.9394 - mae: 14.3240 - val_loss: 122.0364 - val_mae: 8.0322\n",
      "Epoch 145/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 331.5996 - mae: 14.0876 - val_loss: 127.6458 - val_mae: 8.3690\n",
      "Epoch 146/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 330.2630 - mae: 13.8868 - val_loss: 119.6053 - val_mae: 8.0794\n",
      "Epoch 147/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 309.9794 - mae: 13.6034 - val_loss: 136.1727 - val_mae: 8.7761\n",
      "Epoch 148/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 315.6367 - mae: 13.6274 - val_loss: 117.8593 - val_mae: 7.9826\n",
      "Epoch 149/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 318.5064 - mae: 13.7626 - val_loss: 139.1294 - val_mae: 8.9773\n",
      "Epoch 150/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 327.1364 - mae: 13.9658 - val_loss: 131.4664 - val_mae: 8.5496\n",
      "Patience 20: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 129.0924 - mae: 7.9193\n",
      "Patience 20: Validation MAE: 7.90\n",
      "Patience 20: Validation Loss: 117.49\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1968.0140 - mae: 31.9293 - val_loss: 308.9862 - val_mae: 13.8666\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 685.0306 - mae: 20.5327 - val_loss: 286.6033 - val_mae: 12.8102\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 602.8105 - mae: 19.5079 - val_loss: 262.7140 - val_mae: 12.3512\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 544.0157 - mae: 18.4445 - val_loss: 191.0160 - val_mae: 10.5308\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 537.7246 - mae: 18.2550 - val_loss: 165.6789 - val_mae: 9.6822\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 492.8190 - mae: 17.4640 - val_loss: 167.8389 - val_mae: 9.6424\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 478.9391 - mae: 17.1389 - val_loss: 179.9322 - val_mae: 10.0215\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 475.0059 - mae: 16.9388 - val_loss: 158.8587 - val_mae: 9.2495\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 489.8794 - mae: 17.4775 - val_loss: 222.3910 - val_mae: 12.0445\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 455.1104 - mae: 16.7585 - val_loss: 150.6606 - val_mae: 9.0781\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 458.6258 - mae: 16.6896 - val_loss: 211.1584 - val_mae: 11.5453\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 461.7063 - mae: 16.7038 - val_loss: 148.4212 - val_mae: 9.1419\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 477.7607 - mae: 16.8026 - val_loss: 146.2724 - val_mae: 8.9576\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 488.3931 - mae: 16.9957 - val_loss: 142.7608 - val_mae: 8.8900\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 454.4070 - mae: 16.4928 - val_loss: 150.8116 - val_mae: 9.0256\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 450.3637 - mae: 16.5916 - val_loss: 161.0205 - val_mae: 9.5681\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 463.3123 - mae: 16.7198 - val_loss: 156.9653 - val_mae: 9.4580\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 443.8839 - mae: 16.3897 - val_loss: 140.6185 - val_mae: 8.7738\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 428.3583 - mae: 16.0508 - val_loss: 150.8750 - val_mae: 9.0678\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 432.4324 - mae: 16.2770 - val_loss: 152.9717 - val_mae: 9.3027\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 432.8709 - mae: 16.1405 - val_loss: 137.4869 - val_mae: 8.6390\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 420.0575 - mae: 15.8731 - val_loss: 187.3398 - val_mae: 10.4911\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 431.8731 - mae: 16.1425 - val_loss: 142.1971 - val_mae: 8.7921\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 413.3727 - mae: 15.7509 - val_loss: 156.9511 - val_mae: 9.4127\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 411.4466 - mae: 15.7650 - val_loss: 161.9037 - val_mae: 9.3742\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 423.2818 - mae: 15.8858 - val_loss: 138.2204 - val_mae: 8.7096\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 417.8305 - mae: 15.8878 - val_loss: 144.3226 - val_mae: 9.0354\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 419.3345 - mae: 15.7419 - val_loss: 136.3367 - val_mae: 8.6360\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 427.8350 - mae: 16.0018 - val_loss: 140.4923 - val_mae: 8.7255\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 413.6834 - mae: 15.6964 - val_loss: 135.8454 - val_mae: 8.6714\n",
      "Epoch 31/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 398.1893 - mae: 15.5524 - val_loss: 154.8784 - val_mae: 9.4600\n",
      "Epoch 32/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 416.9970 - mae: 15.8161 - val_loss: 136.6870 - val_mae: 8.6436\n",
      "Epoch 33/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 394.5650 - mae: 15.3973 - val_loss: 300.9431 - val_mae: 14.6512\n",
      "Epoch 34/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 428.5480 - mae: 15.9810 - val_loss: 158.8874 - val_mae: 9.4615\n",
      "Epoch 35/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 402.1662 - mae: 15.4531 - val_loss: 183.6886 - val_mae: 10.4771\n",
      "Epoch 36/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 410.7186 - mae: 15.8314 - val_loss: 193.5872 - val_mae: 10.8713\n",
      "Epoch 37/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 411.6334 - mae: 15.5543 - val_loss: 137.4234 - val_mae: 8.6724\n",
      "Epoch 38/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 417.6376 - mae: 15.7280 - val_loss: 143.8516 - val_mae: 9.0230\n",
      "Epoch 39/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 404.4419 - mae: 15.4936 - val_loss: 184.9697 - val_mae: 10.2988\n",
      "Epoch 40/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 400.2318 - mae: 15.6347 - val_loss: 134.0168 - val_mae: 8.5960\n",
      "Epoch 41/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 400.1689 - mae: 15.4042 - val_loss: 130.7383 - val_mae: 8.4441\n",
      "Epoch 42/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 409.3845 - mae: 15.7294 - val_loss: 136.4576 - val_mae: 8.8025\n",
      "Epoch 43/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 409.2939 - mae: 15.5141 - val_loss: 142.4687 - val_mae: 8.8185\n",
      "Epoch 44/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 389.8997 - mae: 15.2263 - val_loss: 132.4764 - val_mae: 8.5544\n",
      "Epoch 45/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 365.8644 - mae: 14.7610 - val_loss: 139.6703 - val_mae: 8.8749\n",
      "Epoch 46/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377.4472 - mae: 15.0358 - val_loss: 142.4400 - val_mae: 8.9413\n",
      "Epoch 47/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 391.2541 - mae: 15.1901 - val_loss: 138.5302 - val_mae: 9.0141\n",
      "Epoch 48/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387.6078 - mae: 15.4144 - val_loss: 175.8226 - val_mae: 10.5391\n",
      "Epoch 49/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 388.9813 - mae: 15.3821 - val_loss: 180.1221 - val_mae: 10.4585\n",
      "Epoch 50/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379.3412 - mae: 15.2264 - val_loss: 187.3957 - val_mae: 10.8340\n",
      "Epoch 51/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 412.8126 - mae: 15.5345 - val_loss: 141.7736 - val_mae: 8.9331\n",
      "Patience 10: Early stopping occurred at epoch 50\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.4814 - mae: 8.4515\n",
      "Patience 10: Validation MAE: 8.44\n",
      "Patience 10: Validation Loss: 130.74\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 118.8970, MAE = 7.9755, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 118.3266, MAE = 7.9201, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 20: Loss = 117.4870, MAE = 7.8967, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 10: Loss = 130.7383, MAE = 8.4441, Early Stopping Occurred: True, Early Stopping Epoch: 50\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "results = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    sbp_model = Sequential([\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    sbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_{}.keras'.format(patience), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = sbp_model.fit(\n",
    "        X_train_combined, SBP_Y_train_combined,\n",
    "        epochs=150,\n",
    "        batch_size=16,\n",
    "        validation_data=(X_test_combined, SBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = sbp_model.evaluate(X_test_combined, SBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    results.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in results:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN for DBP\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 50, batch-size = 16\n",
    "- Patience 40: Loss = 57.1890, MAE = 5.3846\n",
    "- Patience 30: Loss = 56.7720, MAE = 5.4701\n",
    "- Patience 20: Loss = 54.8869, MAE = 5.2500\n",
    "- Patience 10: Loss = 55.6157, MAE = 5.3538, Early Stopping Epoch: 41\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 50, batch-size = 32\n",
    "- Patience 40: Loss = 56.0244, MAE = 5.3419\n",
    "- Patience 30: Loss = 56.2613, MAE = 5.3335\n",
    "- Patience 20: Loss = 56.3914, MAE = 5.3639\n",
    "- Patience 10: Loss = 59.6671, MAE = 5.6499, Early Stopping Epoch: 23\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 100, batch-size = 16\n",
    "- Patience 40: Loss = 52.7448, MAE = 5.2128\n",
    "- Patience 30: Loss = 53.8743, MAE = 5.2439\n",
    "- Patience 20: Loss = 53.5456, MAE = 5.2462\n",
    "- Patience 10: Loss = 59.9646, MAE = 5.5666, Early Stopping Epoch: 30\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 100, batch-size = 32\n",
    "- Patience 40: Loss = 54.1577, MAE = 5.2251\n",
    "- Patience 30: Loss = 54.3697, MAE = 5.2682\n",
    "- Patience 20: Loss = 53.3733, MAE = 5.1637\n",
    "- Patience 10: Loss = 55.4956, MAE = 5.3511, Early Stopping Epoch: 78\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 150, batch-size = 16\n",
    "- Patience 40: Loss = 52.5120, MAE = 5.1191\n",
    "- Patience 30: Loss = 53.1025, MAE = 5.1688, Early Stopping Epoch: 137\n",
    "- Patience 20: Loss = 52.1628, MAE = 5.1445, Early Stopping Epoch: 136\n",
    "- Patience 10: Loss = 58.3427, MAE = 5.5590, Early Stopping Epoch: 29\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 150, batch-size = 32\n",
    "- Patience 40: Loss = 51.1310, MAE = 5.0696\n",
    "- Patience 30: Loss = 54.8134, MAE = 5.2679, Early Stopping Epoch: 76\n",
    "- Patience 20: Loss = 58.3394, MAE = 5.4970, Early Stopping Epoch: 45\n",
    "- Patience 10: Loss = 58.4436, MAE = 5.5170, Early Stopping Epoch: 28\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 200, batch-size = 16\n",
    "- Patience 40: Loss = 51.5722, MAE = 5.0560, Early Stopping Epoch: 113\n",
    "- Patience 30: Loss = 52.3869, MAE = 5.1304, Early Stopping Epoch: 147\n",
    "- Patience 20: Loss = 52.9575, MAE = 5.1575, Early Stopping Epoch: 99\n",
    "- Patience 10: Loss = 57.1061, MAE = 5.3802, Early Stopping Epoch: 30\n",
    "\n",
    "### Early stopping (patience)\n",
    "-> epoch 200, batch-size = 32\n",
    "- Patience 40: Loss = 49.1604, MAE = 4.9449\n",
    "- Patience 30: Loss = 52.1515, MAE = 5.1085, Early Stopping Epoch: 161\n",
    "- Patience 20: Loss = 53.2336, MAE = 5.2543, Early Stopping Epoch: 122\n",
    "- Patience 10: Loss = 55.8708, MAE = 5.3361, Early Stopping Epoch: 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 859.4346 - mae: 18.4320 - val_loss: 168.6546 - val_mae: 9.5579\n",
      "Epoch 2/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 236.7228 - mae: 12.0242 - val_loss: 161.6131 - val_mae: 9.3401\n",
      "Epoch 3/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 217.1088 - mae: 11.4376 - val_loss: 89.4234 - val_mae: 7.2411\n",
      "Epoch 4/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 185.1796 - mae: 10.5732 - val_loss: 91.7165 - val_mae: 7.6644\n",
      "Epoch 5/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 182.8268 - mae: 10.5121 - val_loss: 98.4073 - val_mae: 7.3608\n",
      "Epoch 6/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 178.4524 - mae: 10.3355 - val_loss: 77.6180 - val_mae: 6.5033\n",
      "Epoch 7/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 183.1896 - mae: 10.4701 - val_loss: 81.3565 - val_mae: 6.8569\n",
      "Epoch 8/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 163.8319 - mae: 9.9569 - val_loss: 104.0288 - val_mae: 7.8051\n",
      "Epoch 9/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 163.4455 - mae: 9.7518 - val_loss: 80.9211 - val_mae: 6.5895\n",
      "Epoch 10/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 168.0087 - mae: 9.9684 - val_loss: 71.8604 - val_mae: 6.1793\n",
      "Epoch 11/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 163.9514 - mae: 9.7977 - val_loss: 68.0447 - val_mae: 6.1099\n",
      "Epoch 12/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 166.3286 - mae: 9.8464 - val_loss: 67.1383 - val_mae: 6.1115\n",
      "Epoch 13/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 160.4234 - mae: 9.7704 - val_loss: 69.1981 - val_mae: 6.1726\n",
      "Epoch 14/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 160.5072 - mae: 9.7663 - val_loss: 63.8473 - val_mae: 5.7596\n",
      "Epoch 15/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 156.5798 - mae: 9.5764 - val_loss: 63.5823 - val_mae: 5.8529\n",
      "Epoch 16/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.3353 - mae: 9.3142 - val_loss: 64.3256 - val_mae: 5.8880\n",
      "Epoch 17/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 161.3703 - mae: 9.7743 - val_loss: 66.7799 - val_mae: 5.8888\n",
      "Epoch 18/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 149.1298 - mae: 9.3600 - val_loss: 70.1864 - val_mae: 6.3377\n",
      "Epoch 19/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 160.0524 - mae: 9.6967 - val_loss: 63.9876 - val_mae: 5.8224\n",
      "Epoch 20/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.8646 - mae: 9.3720 - val_loss: 65.1367 - val_mae: 5.8125\n",
      "Epoch 21/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 151.1780 - mae: 9.4511 - val_loss: 64.7170 - val_mae: 5.8520\n",
      "Epoch 22/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 149.0207 - mae: 9.4302 - val_loss: 69.1449 - val_mae: 6.0785\n",
      "Epoch 23/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.5370 - mae: 9.5391 - val_loss: 97.2270 - val_mae: 7.4965\n",
      "Epoch 24/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 147.8841 - mae: 9.3464 - val_loss: 59.6051 - val_mae: 5.5630\n",
      "Epoch 25/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.3155 - mae: 9.4664 - val_loss: 64.1151 - val_mae: 5.7738\n",
      "Epoch 26/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.5881 - mae: 9.0143 - val_loss: 62.0197 - val_mae: 5.7747\n",
      "Epoch 27/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.4707 - mae: 9.2028 - val_loss: 60.8401 - val_mae: 5.6826\n",
      "Epoch 28/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.5163 - mae: 9.1538 - val_loss: 65.8402 - val_mae: 5.8904\n",
      "Epoch 29/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.9287 - mae: 9.2249 - val_loss: 59.8406 - val_mae: 5.5220\n",
      "Epoch 30/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 143.8922 - mae: 9.1735 - val_loss: 71.1787 - val_mae: 6.0706\n",
      "Epoch 31/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.3269 - mae: 9.0771 - val_loss: 62.6922 - val_mae: 5.6483\n",
      "Epoch 32/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.1132 - mae: 9.0189 - val_loss: 61.3403 - val_mae: 5.5411\n",
      "Epoch 33/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.0058 - mae: 9.1363 - val_loss: 63.2899 - val_mae: 5.6963\n",
      "Epoch 34/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.1950 - mae: 8.9201 - val_loss: 60.5632 - val_mae: 5.6795\n",
      "Epoch 35/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.6620 - mae: 8.9061 - val_loss: 74.6154 - val_mae: 6.6643\n",
      "Epoch 36/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.3512 - mae: 8.8690 - val_loss: 63.3056 - val_mae: 5.7075\n",
      "Epoch 37/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.5547 - mae: 9.0377 - val_loss: 60.8226 - val_mae: 5.5209\n",
      "Epoch 38/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.4065 - mae: 8.9124 - val_loss: 59.7663 - val_mae: 5.5015\n",
      "Epoch 39/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.0970 - mae: 8.9854 - val_loss: 63.3760 - val_mae: 5.9272\n",
      "Epoch 40/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.5809 - mae: 8.8626 - val_loss: 58.5179 - val_mae: 5.4271\n",
      "Epoch 41/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 131.5683 - mae: 8.7700 - val_loss: 62.9282 - val_mae: 5.6559\n",
      "Epoch 42/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.3200 - mae: 8.9767 - val_loss: 62.4016 - val_mae: 5.7451\n",
      "Epoch 43/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.4036 - mae: 8.9234 - val_loss: 57.1890 - val_mae: 5.3846\n",
      "Epoch 44/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.9567 - mae: 8.7495 - val_loss: 62.9680 - val_mae: 5.7080\n",
      "Epoch 45/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.1377 - mae: 8.6345 - val_loss: 58.7836 - val_mae: 5.4318\n",
      "Epoch 46/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.4068 - mae: 8.9260 - val_loss: 59.4577 - val_mae: 5.5726\n",
      "Epoch 47/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.7674 - mae: 8.6764 - val_loss: 60.5141 - val_mae: 5.5206\n",
      "Epoch 48/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 133.4508 - mae: 8.9010 - val_loss: 60.4546 - val_mae: 5.5382\n",
      "Epoch 49/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.0117 - mae: 8.7796 - val_loss: 65.2121 - val_mae: 5.7619\n",
      "Epoch 50/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.5631 - mae: 8.6694 - val_loss: 63.1855 - val_mae: 5.6573\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64.9349 - mae: 5.5885\n",
      "Patience 40: Validation MAE: 5.38\n",
      "Patience 40: Validation Loss: 57.19\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 907.1143 - mae: 19.2896 - val_loss: 145.8339 - val_mae: 9.9210\n",
      "Epoch 2/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 263.7732 - mae: 12.7030 - val_loss: 126.8291 - val_mae: 8.4272\n",
      "Epoch 3/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 225.3468 - mae: 11.7867 - val_loss: 104.6447 - val_mae: 8.6132\n",
      "Epoch 4/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 191.7137 - mae: 10.7900 - val_loss: 75.6892 - val_mae: 6.6623\n",
      "Epoch 5/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 174.7609 - mae: 10.2007 - val_loss: 70.2164 - val_mae: 6.1225\n",
      "Epoch 6/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 167.8706 - mae: 10.0032 - val_loss: 77.2036 - val_mae: 6.8535\n",
      "Epoch 7/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 157.0975 - mae: 9.6510 - val_loss: 140.4814 - val_mae: 9.5308\n",
      "Epoch 8/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 158.3886 - mae: 9.6732 - val_loss: 77.2807 - val_mae: 6.4654\n",
      "Epoch 9/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152.5626 - mae: 9.4542 - val_loss: 65.4300 - val_mae: 5.8946\n",
      "Epoch 10/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157.9226 - mae: 9.6678 - val_loss: 67.6564 - val_mae: 5.9525\n",
      "Epoch 11/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 163.0378 - mae: 9.7547 - val_loss: 71.2912 - val_mae: 6.1216\n",
      "Epoch 12/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 151.3831 - mae: 9.5339 - val_loss: 85.1674 - val_mae: 6.7535\n",
      "Epoch 13/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 155.2288 - mae: 9.5451 - val_loss: 71.2520 - val_mae: 6.2190\n",
      "Epoch 14/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.1304 - mae: 9.3867 - val_loss: 65.1682 - val_mae: 5.9875\n",
      "Epoch 15/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 146.4305 - mae: 9.3564 - val_loss: 63.9516 - val_mae: 5.8228\n",
      "Epoch 16/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 154.1078 - mae: 9.5137 - val_loss: 67.9278 - val_mae: 5.9673\n",
      "Epoch 17/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.3056 - mae: 9.1683 - val_loss: 60.1983 - val_mae: 5.6311\n",
      "Epoch 18/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.2185 - mae: 9.3559 - val_loss: 67.1404 - val_mae: 6.1475\n",
      "Epoch 19/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 148.3047 - mae: 9.3310 - val_loss: 59.5680 - val_mae: 5.6301\n",
      "Epoch 20/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 142.2673 - mae: 9.1799 - val_loss: 70.2056 - val_mae: 6.0544\n",
      "Epoch 21/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.4380 - mae: 9.2903 - val_loss: 62.2871 - val_mae: 5.8234\n",
      "Epoch 22/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.6265 - mae: 9.2552 - val_loss: 61.0888 - val_mae: 5.7926\n",
      "Epoch 23/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.3351 - mae: 9.0146 - val_loss: 60.6091 - val_mae: 5.7169\n",
      "Epoch 24/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.9236 - mae: 9.1428 - val_loss: 63.3979 - val_mae: 5.7938\n",
      "Epoch 25/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.1546 - mae: 8.9804 - val_loss: 67.2127 - val_mae: 6.2430\n",
      "Epoch 26/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.2554 - mae: 9.0914 - val_loss: 65.8698 - val_mae: 5.8453\n",
      "Epoch 27/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.3299 - mae: 9.1802 - val_loss: 57.9957 - val_mae: 5.5010\n",
      "Epoch 28/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 150.0582 - mae: 9.3740 - val_loss: 61.0877 - val_mae: 5.7396\n",
      "Epoch 29/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.1582 - mae: 8.8103 - val_loss: 63.8580 - val_mae: 5.7719\n",
      "Epoch 30/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 149.3109 - mae: 9.2954 - val_loss: 61.4945 - val_mae: 5.6743\n",
      "Epoch 31/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.6668 - mae: 8.9231 - val_loss: 60.9383 - val_mae: 5.7763\n",
      "Epoch 32/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.5580 - mae: 9.0448 - val_loss: 68.2349 - val_mae: 6.0855\n",
      "Epoch 33/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.1943 - mae: 8.7885 - val_loss: 59.7278 - val_mae: 5.5720\n",
      "Epoch 34/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.7609 - mae: 8.8904 - val_loss: 65.1235 - val_mae: 6.1260\n",
      "Epoch 35/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 149.0435 - mae: 9.2763 - val_loss: 62.5204 - val_mae: 5.7254\n",
      "Epoch 36/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.0686 - mae: 8.6642 - val_loss: 69.0889 - val_mae: 6.0718\n",
      "Epoch 37/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.1954 - mae: 8.7102 - val_loss: 63.6448 - val_mae: 5.7879\n",
      "Epoch 38/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.0665 - mae: 8.7397 - val_loss: 62.1415 - val_mae: 5.7782\n",
      "Epoch 39/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.7600 - mae: 8.6279 - val_loss: 73.2671 - val_mae: 6.2885\n",
      "Epoch 40/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.6973 - mae: 8.6732 - val_loss: 109.0575 - val_mae: 7.9745\n",
      "Epoch 41/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.0074 - mae: 8.6188 - val_loss: 62.4290 - val_mae: 5.8225\n",
      "Epoch 42/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.8432 - mae: 8.7886 - val_loss: 64.7834 - val_mae: 6.0934\n",
      "Epoch 43/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.4605 - mae: 8.9482 - val_loss: 65.8126 - val_mae: 5.8063\n",
      "Epoch 44/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.0016 - mae: 8.9259 - val_loss: 56.7720 - val_mae: 5.4701\n",
      "Epoch 45/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 128.2258 - mae: 8.6618 - val_loss: 63.4190 - val_mae: 5.7555\n",
      "Epoch 46/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.5942 - mae: 8.4475 - val_loss: 63.6896 - val_mae: 5.8002\n",
      "Epoch 47/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.8232 - mae: 8.7848 - val_loss: 59.6893 - val_mae: 5.5516\n",
      "Epoch 48/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.2613 - mae: 8.6051 - val_loss: 95.8479 - val_mae: 7.7014\n",
      "Epoch 49/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 133.5909 - mae: 8.8288 - val_loss: 61.2724 - val_mae: 5.6135\n",
      "Epoch 50/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.9829 - mae: 8.7275 - val_loss: 61.3785 - val_mae: 5.7244\n",
      "Patience 30: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.0904 - mae: 5.6258\n",
      "Patience 30: Validation MAE: 5.47\n",
      "Patience 30: Validation Loss: 56.77\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 810.5560 - mae: 18.6623 - val_loss: 141.9393 - val_mae: 9.7240\n",
      "Epoch 2/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 257.2338 - mae: 12.5044 - val_loss: 112.6449 - val_mae: 8.1002\n",
      "Epoch 3/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 196.7568 - mae: 10.8528 - val_loss: 109.1773 - val_mae: 7.6856\n",
      "Epoch 4/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 189.4840 - mae: 10.5974 - val_loss: 112.5915 - val_mae: 8.9106\n",
      "Epoch 5/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 169.3844 - mae: 10.0621 - val_loss: 66.3038 - val_mae: 5.8837\n",
      "Epoch 6/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 160.5059 - mae: 9.6933 - val_loss: 66.0624 - val_mae: 5.9624\n",
      "Epoch 7/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 154.8775 - mae: 9.6907 - val_loss: 61.9874 - val_mae: 5.7208\n",
      "Epoch 8/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 149.4406 - mae: 9.4043 - val_loss: 67.3849 - val_mae: 5.9492\n",
      "Epoch 9/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 150.0168 - mae: 9.3612 - val_loss: 68.5213 - val_mae: 6.0133\n",
      "Epoch 10/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.2088 - mae: 9.3393 - val_loss: 61.1346 - val_mae: 5.6875\n",
      "Epoch 11/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 150.9034 - mae: 9.3811 - val_loss: 67.0961 - val_mae: 5.8853\n",
      "Epoch 12/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.6258 - mae: 9.0956 - val_loss: 65.4594 - val_mae: 5.7353\n",
      "Epoch 13/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.3846 - mae: 8.8955 - val_loss: 68.1870 - val_mae: 5.9037\n",
      "Epoch 14/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.7557 - mae: 9.0074 - val_loss: 60.4077 - val_mae: 5.5508\n",
      "Epoch 15/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 144.6771 - mae: 9.1768 - val_loss: 62.3798 - val_mae: 5.6688\n",
      "Epoch 16/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.8467 - mae: 8.9931 - val_loss: 59.1060 - val_mae: 5.4452\n",
      "Epoch 17/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.7174 - mae: 8.8657 - val_loss: 71.6504 - val_mae: 6.4978\n",
      "Epoch 18/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.8901 - mae: 9.0409 - val_loss: 62.3217 - val_mae: 5.6313\n",
      "Epoch 19/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 139.3524 - mae: 9.1245 - val_loss: 57.1881 - val_mae: 5.4025\n",
      "Epoch 20/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.7963 - mae: 8.6904 - val_loss: 59.1908 - val_mae: 5.6878\n",
      "Epoch 21/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 132.7210 - mae: 8.7664 - val_loss: 65.5262 - val_mae: 5.9065\n",
      "Epoch 22/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 141.5608 - mae: 9.1091 - val_loss: 70.9206 - val_mae: 6.1030\n",
      "Epoch 23/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.7890 - mae: 8.7685 - val_loss: 69.0292 - val_mae: 6.0533\n",
      "Epoch 24/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.3210 - mae: 8.7494 - val_loss: 85.8908 - val_mae: 6.8458\n",
      "Epoch 25/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.0099 - mae: 8.8112 - val_loss: 57.8466 - val_mae: 5.4343\n",
      "Epoch 26/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.6684 - mae: 8.6663 - val_loss: 59.4321 - val_mae: 5.4889\n",
      "Epoch 27/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.9759 - mae: 8.5431 - val_loss: 59.7655 - val_mae: 5.5521\n",
      "Epoch 28/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.6411 - mae: 8.9196 - val_loss: 59.5936 - val_mae: 5.6278\n",
      "Epoch 29/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.9246 - mae: 8.8590 - val_loss: 62.3693 - val_mae: 5.6002\n",
      "Epoch 30/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.7290 - mae: 8.5106 - val_loss: 61.8591 - val_mae: 5.6385\n",
      "Epoch 31/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.9670 - mae: 8.5717 - val_loss: 55.9993 - val_mae: 5.3721\n",
      "Epoch 32/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.6620 - mae: 8.4473 - val_loss: 56.6526 - val_mae: 5.4127\n",
      "Epoch 33/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.4419 - mae: 8.6194 - val_loss: 59.9595 - val_mae: 5.6198\n",
      "Epoch 34/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.5218 - mae: 8.5084 - val_loss: 56.9615 - val_mae: 5.3952\n",
      "Epoch 35/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.0704 - mae: 8.6001 - val_loss: 55.6758 - val_mae: 5.3154\n",
      "Epoch 36/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.2609 - mae: 8.5847 - val_loss: 59.9025 - val_mae: 5.7567\n",
      "Epoch 37/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.9509 - mae: 8.6847 - val_loss: 55.6777 - val_mae: 5.3264\n",
      "Epoch 38/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.4685 - mae: 8.4202 - val_loss: 56.0079 - val_mae: 5.3875\n",
      "Epoch 39/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.0709 - mae: 8.2594 - val_loss: 58.1380 - val_mae: 5.4980\n",
      "Epoch 40/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.6376 - mae: 8.4034 - val_loss: 57.3041 - val_mae: 5.3710\n",
      "Epoch 41/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.2413 - mae: 8.3443 - val_loss: 56.2036 - val_mae: 5.4559\n",
      "Epoch 42/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.3078 - mae: 8.3960 - val_loss: 63.7330 - val_mae: 5.9596\n",
      "Epoch 43/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.9496 - mae: 8.2622 - val_loss: 65.3543 - val_mae: 5.8618\n",
      "Epoch 44/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.8236 - mae: 8.2035 - val_loss: 71.5395 - val_mae: 6.3166\n",
      "Epoch 45/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.5418 - mae: 8.2929 - val_loss: 57.0615 - val_mae: 5.3711\n",
      "Epoch 46/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.1947 - mae: 8.1599 - val_loss: 57.7208 - val_mae: 5.5623\n",
      "Epoch 47/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.9962 - mae: 8.3816 - val_loss: 74.4635 - val_mae: 6.2844\n",
      "Epoch 48/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.2909 - mae: 8.4558 - val_loss: 67.3977 - val_mae: 6.0408\n",
      "Epoch 49/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.0240 - mae: 8.5531 - val_loss: 61.5965 - val_mae: 5.7121\n",
      "Epoch 50/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114.4526 - mae: 8.0880 - val_loss: 54.8869 - val_mae: 5.2500\n",
      "Patience 20: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.3129 - mae: 5.4091\n",
      "Patience 20: Validation MAE: 5.25\n",
      "Patience 20: Validation Loss: 54.89\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 674.2423 - mae: 17.4570 - val_loss: 137.8399 - val_mae: 8.9815\n",
      "Epoch 2/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 219.3207 - mae: 11.5778 - val_loss: 110.7438 - val_mae: 7.6374\n",
      "Epoch 3/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 204.0552 - mae: 11.1963 - val_loss: 90.3599 - val_mae: 6.7910\n",
      "Epoch 4/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 179.5721 - mae: 10.3437 - val_loss: 77.1925 - val_mae: 6.3879\n",
      "Epoch 5/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 169.8648 - mae: 10.0902 - val_loss: 83.3764 - val_mae: 6.6766\n",
      "Epoch 6/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 160.2321 - mae: 9.7672 - val_loss: 65.5455 - val_mae: 5.9919\n",
      "Epoch 7/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 156.2637 - mae: 9.6555 - val_loss: 63.8045 - val_mae: 5.7586\n",
      "Epoch 8/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.3345 - mae: 9.1705 - val_loss: 60.6891 - val_mae: 5.6655\n",
      "Epoch 9/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.4269 - mae: 9.1364 - val_loss: 66.4977 - val_mae: 5.9016\n",
      "Epoch 10/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.1079 - mae: 9.2922 - val_loss: 67.3147 - val_mae: 6.2312\n",
      "Epoch 11/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 139.4821 - mae: 9.0707 - val_loss: 59.6850 - val_mae: 5.5674\n",
      "Epoch 12/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.4449 - mae: 9.1084 - val_loss: 87.7034 - val_mae: 7.0940\n",
      "Epoch 13/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 137.7144 - mae: 8.9614 - val_loss: 114.1449 - val_mae: 8.3387\n",
      "Epoch 14/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 146.8920 - mae: 9.2862 - val_loss: 63.1512 - val_mae: 5.6520\n",
      "Epoch 15/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.5933 - mae: 8.8477 - val_loss: 62.1047 - val_mae: 5.7001\n",
      "Epoch 16/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.7950 - mae: 8.8165 - val_loss: 63.9316 - val_mae: 6.0247\n",
      "Epoch 17/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.2425 - mae: 8.9080 - val_loss: 78.5194 - val_mae: 6.5921\n",
      "Epoch 18/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.5057 - mae: 9.1264 - val_loss: 57.7255 - val_mae: 5.4374\n",
      "Epoch 19/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 131.3958 - mae: 8.8004 - val_loss: 79.1296 - val_mae: 6.9222\n",
      "Epoch 20/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.7726 - mae: 8.7703 - val_loss: 61.5180 - val_mae: 5.6270\n",
      "Epoch 21/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.6283 - mae: 8.6946 - val_loss: 94.1845 - val_mae: 7.5377\n",
      "Epoch 22/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 131.0732 - mae: 8.7297 - val_loss: 65.8338 - val_mae: 5.8455\n",
      "Epoch 23/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.6755 - mae: 8.5280 - val_loss: 56.8904 - val_mae: 5.3831\n",
      "Epoch 24/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.8406 - mae: 8.6132 - val_loss: 57.6195 - val_mae: 5.5027\n",
      "Epoch 25/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.0743 - mae: 8.6982 - val_loss: 64.7684 - val_mae: 5.8470\n",
      "Epoch 26/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.4583 - mae: 8.5620 - val_loss: 73.3980 - val_mae: 6.1694\n",
      "Epoch 27/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.8534 - mae: 8.5508 - val_loss: 61.9322 - val_mae: 5.7622\n",
      "Epoch 28/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.2721 - mae: 8.5213 - val_loss: 58.2496 - val_mae: 5.4270\n",
      "Epoch 29/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.8815 - mae: 8.4757 - val_loss: 57.8122 - val_mae: 5.4465\n",
      "Epoch 30/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.4763 - mae: 8.7465 - val_loss: 72.9304 - val_mae: 6.7200\n",
      "Epoch 31/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.2203 - mae: 8.2760 - val_loss: 62.5602 - val_mae: 5.7166\n",
      "Epoch 32/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 132.8622 - mae: 8.7181 - val_loss: 55.6157 - val_mae: 5.3538\n",
      "Epoch 33/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.6874 - mae: 8.4961 - val_loss: 57.8286 - val_mae: 5.4271\n",
      "Epoch 34/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.2704 - mae: 8.3079 - val_loss: 61.0963 - val_mae: 5.6907\n",
      "Epoch 35/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 120.7665 - mae: 8.3508 - val_loss: 58.7963 - val_mae: 5.5503\n",
      "Epoch 36/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.3206 - mae: 8.5113 - val_loss: 59.0982 - val_mae: 5.5286\n",
      "Epoch 37/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.9208 - mae: 8.3270 - val_loss: 59.9294 - val_mae: 5.7107\n",
      "Epoch 38/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.5970 - mae: 8.2780 - val_loss: 56.1302 - val_mae: 5.4087\n",
      "Epoch 39/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.8306 - mae: 8.3444 - val_loss: 55.7950 - val_mae: 5.4750\n",
      "Epoch 40/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 120.9847 - mae: 8.2503 - val_loss: 60.0471 - val_mae: 5.6193\n",
      "Epoch 41/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 126.8797 - mae: 8.5198 - val_loss: 69.3826 - val_mae: 6.1146\n",
      "Epoch 42/50\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114.0744 - mae: 8.1987 - val_loss: 61.8883 - val_mae: 5.6730\n",
      "Patience 10: Early stopping occurred at epoch 41\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.7692 - mae: 5.5417\n",
      "Patience 10: Validation MAE: 5.35\n",
      "Patience 10: Validation Loss: 55.62\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 57.1890, MAE = 5.3846, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 56.7720, MAE = 5.4701, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 20: Loss = 54.8869, MAE = 5.2500, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 10: Loss = 55.6157, MAE = 5.3538, Early Stopping Occurred: True, Early Stopping Epoch: 41\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "bresults50 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    dbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    dbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'best_model_{patience}.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = dbp_model.fit(\n",
    "        X_train_combined, DBP_Y_train_combined,\n",
    "        epochs=50,\n",
    "        batch_size=16,\n",
    "        validation_data=(X_test_combined, DBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = dbp_model.evaluate(X_test_combined, DBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    bresults50.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    # 학습 및 검증 손실 그래프 시각화\n",
    "    # plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.title(f'Patience = {patience}')\n",
    "    # plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in bresults50:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 903.4009 - mae: 20.7902 - val_loss: 159.8213 - val_mae: 10.2953\n",
      "Epoch 2/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 293.8080 - mae: 13.5126 - val_loss: 143.1318 - val_mae: 9.1212\n",
      "Epoch 3/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 263.2870 - mae: 12.6548 - val_loss: 106.6781 - val_mae: 8.3460\n",
      "Epoch 4/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 210.1910 - mae: 11.3745 - val_loss: 96.8045 - val_mae: 7.2977\n",
      "Epoch 5/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 191.8613 - mae: 10.8627 - val_loss: 87.6627 - val_mae: 6.7979\n",
      "Epoch 6/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 179.9329 - mae: 10.3675 - val_loss: 83.0775 - val_mae: 7.1267\n",
      "Epoch 7/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 184.9284 - mae: 10.6744 - val_loss: 67.0378 - val_mae: 5.9739\n",
      "Epoch 8/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 184.1646 - mae: 10.4674 - val_loss: 67.1139 - val_mae: 5.8754\n",
      "Epoch 9/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 181.2997 - mae: 10.3782 - val_loss: 70.3558 - val_mae: 5.9454\n",
      "Epoch 10/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 170.3722 - mae: 10.1384 - val_loss: 63.9132 - val_mae: 5.7618\n",
      "Epoch 11/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 163.2956 - mae: 9.8002 - val_loss: 62.7190 - val_mae: 5.6510\n",
      "Epoch 12/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 161.2202 - mae: 9.8291 - val_loss: 64.8516 - val_mae: 5.6916\n",
      "Epoch 13/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 163.9687 - mae: 9.9167 - val_loss: 62.1593 - val_mae: 5.6789\n",
      "Epoch 14/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 150.9223 - mae: 9.4945 - val_loss: 69.7278 - val_mae: 5.9887\n",
      "Epoch 15/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 158.5834 - mae: 9.7147 - val_loss: 87.8562 - val_mae: 6.7010\n",
      "Epoch 16/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.9362 - mae: 9.5813 - val_loss: 62.6385 - val_mae: 5.6620\n",
      "Epoch 17/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 151.7198 - mae: 9.5311 - val_loss: 69.3048 - val_mae: 5.9691\n",
      "Epoch 18/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 154.3487 - mae: 9.5808 - val_loss: 65.3134 - val_mae: 5.7166\n",
      "Epoch 19/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 156.0289 - mae: 9.5757 - val_loss: 59.6615 - val_mae: 5.4591\n",
      "Epoch 20/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 154.4199 - mae: 9.5277 - val_loss: 59.6626 - val_mae: 5.5000\n",
      "Epoch 21/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 154.8636 - mae: 9.6038 - val_loss: 62.7120 - val_mae: 5.7826\n",
      "Epoch 22/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 155.0054 - mae: 9.6013 - val_loss: 62.9642 - val_mae: 5.6317\n",
      "Epoch 23/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 161.3760 - mae: 9.7944 - val_loss: 64.1068 - val_mae: 5.6441\n",
      "Epoch 24/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 158.6540 - mae: 9.6287 - val_loss: 59.7051 - val_mae: 5.4508\n",
      "Epoch 25/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 159.7463 - mae: 9.6600 - val_loss: 57.7644 - val_mae: 5.3709\n",
      "Epoch 26/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.5703 - mae: 9.2921 - val_loss: 60.8573 - val_mae: 5.7491\n",
      "Epoch 27/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.0912 - mae: 9.2863 - val_loss: 57.2287 - val_mae: 5.4401\n",
      "Epoch 28/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 150.9964 - mae: 9.4449 - val_loss: 64.8114 - val_mae: 5.7713\n",
      "Epoch 29/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.1237 - mae: 9.4294 - val_loss: 60.6103 - val_mae: 5.4740\n",
      "Epoch 30/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.6638 - mae: 9.5300 - val_loss: 66.8196 - val_mae: 5.8208\n",
      "Epoch 31/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.2097 - mae: 9.2576 - val_loss: 67.7837 - val_mae: 5.8733\n",
      "Epoch 32/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.5915 - mae: 9.2620 - val_loss: 57.1209 - val_mae: 5.4004\n",
      "Epoch 33/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.9732 - mae: 8.9997 - val_loss: 57.7431 - val_mae: 5.4289\n",
      "Epoch 34/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.0936 - mae: 9.4119 - val_loss: 64.5243 - val_mae: 5.8450\n",
      "Epoch 35/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.5368 - mae: 9.1590 - val_loss: 68.7764 - val_mae: 6.0326\n",
      "Epoch 36/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.6739 - mae: 9.1953 - val_loss: 56.0244 - val_mae: 5.3419\n",
      "Epoch 37/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 143.0154 - mae: 9.1369 - val_loss: 57.7255 - val_mae: 5.5018\n",
      "Epoch 38/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.8649 - mae: 9.0004 - val_loss: 58.0913 - val_mae: 5.5598\n",
      "Epoch 39/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.4294 - mae: 9.0253 - val_loss: 57.7879 - val_mae: 5.4909\n",
      "Epoch 40/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.2111 - mae: 9.0312 - val_loss: 64.8929 - val_mae: 5.8592\n",
      "Epoch 41/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.3867 - mae: 9.0573 - val_loss: 59.7556 - val_mae: 5.5599\n",
      "Epoch 42/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.6307 - mae: 9.0590 - val_loss: 64.9188 - val_mae: 5.8545\n",
      "Epoch 43/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.3145 - mae: 9.2830 - val_loss: 64.8239 - val_mae: 5.8530\n",
      "Epoch 44/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.6064 - mae: 9.0412 - val_loss: 59.5260 - val_mae: 5.4495\n",
      "Epoch 45/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.4459 - mae: 9.1050 - val_loss: 64.5813 - val_mae: 5.7049\n",
      "Epoch 46/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 128.4720 - mae: 8.6614 - val_loss: 59.2007 - val_mae: 5.4636\n",
      "Epoch 47/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 139.9372 - mae: 9.0698 - val_loss: 57.0523 - val_mae: 5.4940\n",
      "Epoch 48/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 139.9916 - mae: 9.0205 - val_loss: 58.8223 - val_mae: 5.4855\n",
      "Epoch 49/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 139.1148 - mae: 9.0493 - val_loss: 58.5067 - val_mae: 5.4477\n",
      "Epoch 50/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.3577 - mae: 8.8747 - val_loss: 64.4545 - val_mae: 6.1494\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.6591 - mae: 5.4681\n",
      "Patience 40: Validation MAE: 5.34\n",
      "Patience 40: Validation Loss: 56.02\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 794.3688 - mae: 19.3771 - val_loss: 162.2738 - val_mae: 9.7910\n",
      "Epoch 2/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 247.6165 - mae: 12.2720 - val_loss: 163.0614 - val_mae: 9.1320\n",
      "Epoch 3/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 223.4210 - mae: 11.6477 - val_loss: 108.4887 - val_mae: 8.1467\n",
      "Epoch 4/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 214.8825 - mae: 11.4077 - val_loss: 97.4177 - val_mae: 7.3235\n",
      "Epoch 5/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 190.8398 - mae: 10.7276 - val_loss: 95.3721 - val_mae: 7.1169\n",
      "Epoch 6/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 185.5780 - mae: 10.5650 - val_loss: 105.4888 - val_mae: 7.5208\n",
      "Epoch 7/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 177.3733 - mae: 10.3882 - val_loss: 71.7284 - val_mae: 6.1483\n",
      "Epoch 8/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 170.7951 - mae: 10.0173 - val_loss: 67.4664 - val_mae: 5.9583\n",
      "Epoch 9/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 159.8513 - mae: 9.7260 - val_loss: 74.4826 - val_mae: 6.2266\n",
      "Epoch 10/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.3607 - mae: 9.4819 - val_loss: 68.4808 - val_mae: 6.1809\n",
      "Epoch 11/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 158.2677 - mae: 9.7091 - val_loss: 76.4816 - val_mae: 6.4223\n",
      "Epoch 12/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.4683 - mae: 9.2502 - val_loss: 84.4835 - val_mae: 7.2419\n",
      "Epoch 13/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 153.8689 - mae: 9.4649 - val_loss: 66.6862 - val_mae: 6.0538\n",
      "Epoch 14/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 154.5435 - mae: 9.5307 - val_loss: 61.8956 - val_mae: 5.6418\n",
      "Epoch 15/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 148.3682 - mae: 9.4743 - val_loss: 68.4625 - val_mae: 6.1883\n",
      "Epoch 16/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 145.8351 - mae: 9.2416 - val_loss: 64.9357 - val_mae: 5.7477\n",
      "Epoch 17/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 139.1026 - mae: 8.9748 - val_loss: 71.0210 - val_mae: 6.0825\n",
      "Epoch 18/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 145.9344 - mae: 9.1919 - val_loss: 64.8678 - val_mae: 6.0150\n",
      "Epoch 19/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 144.4113 - mae: 9.2009 - val_loss: 62.2160 - val_mae: 5.6052\n",
      "Epoch 20/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 149.5173 - mae: 9.3521 - val_loss: 61.0540 - val_mae: 5.6423\n",
      "Epoch 21/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.8284 - mae: 9.0363 - val_loss: 60.7121 - val_mae: 5.5637\n",
      "Epoch 22/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.7494 - mae: 9.3494 - val_loss: 71.9596 - val_mae: 6.1189\n",
      "Epoch 23/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 139.6800 - mae: 9.0523 - val_loss: 73.4419 - val_mae: 6.2062\n",
      "Epoch 24/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 147.4193 - mae: 9.4005 - val_loss: 61.3243 - val_mae: 5.6073\n",
      "Epoch 25/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 134.5609 - mae: 8.9364 - val_loss: 60.2335 - val_mae: 5.5072\n",
      "Epoch 26/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 135.1048 - mae: 8.8916 - val_loss: 82.1054 - val_mae: 6.7461\n",
      "Epoch 27/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 138.9514 - mae: 9.0628 - val_loss: 61.5146 - val_mae: 5.5714\n",
      "Epoch 28/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 133.3301 - mae: 8.7960 - val_loss: 59.6194 - val_mae: 5.6025\n",
      "Epoch 29/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 135.2248 - mae: 8.9302 - val_loss: 59.5042 - val_mae: 5.4949\n",
      "Epoch 30/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.3240 - mae: 8.9792 - val_loss: 59.7792 - val_mae: 5.4872\n",
      "Epoch 31/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.0913 - mae: 9.0581 - val_loss: 82.8302 - val_mae: 6.7233\n",
      "Epoch 32/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.5782 - mae: 8.9824 - val_loss: 58.5299 - val_mae: 5.4631\n",
      "Epoch 33/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 134.7089 - mae: 8.9047 - val_loss: 62.0650 - val_mae: 5.5831\n",
      "Epoch 34/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 129.0850 - mae: 8.6400 - val_loss: 62.9167 - val_mae: 5.6211\n",
      "Epoch 35/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 135.2301 - mae: 8.9040 - val_loss: 86.9870 - val_mae: 6.9047\n",
      "Epoch 36/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 133.7879 - mae: 8.8789 - val_loss: 59.3072 - val_mae: 5.5737\n",
      "Epoch 37/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.9004 - mae: 9.0059 - val_loss: 60.7696 - val_mae: 5.8155\n",
      "Epoch 38/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.8364 - mae: 8.7343 - val_loss: 59.5492 - val_mae: 5.4697\n",
      "Epoch 39/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 129.3002 - mae: 8.7196 - val_loss: 61.9090 - val_mae: 5.8259\n",
      "Epoch 40/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 127.4953 - mae: 8.6979 - val_loss: 57.0105 - val_mae: 5.3823\n",
      "Epoch 41/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 138.8088 - mae: 8.8497 - val_loss: 59.2093 - val_mae: 5.5145\n",
      "Epoch 42/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 131.5501 - mae: 8.7305 - val_loss: 59.0056 - val_mae: 5.4704\n",
      "Epoch 43/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.9339 - mae: 8.6083 - val_loss: 57.4139 - val_mae: 5.4201\n",
      "Epoch 44/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.9476 - mae: 8.9429 - val_loss: 66.0312 - val_mae: 6.1775\n",
      "Epoch 45/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 131.7297 - mae: 8.8000 - val_loss: 72.1422 - val_mae: 6.2714\n",
      "Epoch 46/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 132.8645 - mae: 8.8024 - val_loss: 61.3455 - val_mae: 5.6414\n",
      "Epoch 47/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 125.2554 - mae: 8.6425 - val_loss: 56.2613 - val_mae: 5.3335\n",
      "Epoch 48/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.6562 - mae: 8.7158 - val_loss: 67.2605 - val_mae: 5.9676\n",
      "Epoch 49/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 134.1736 - mae: 8.7858 - val_loss: 56.6163 - val_mae: 5.3676\n",
      "Epoch 50/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 120.8359 - mae: 8.4020 - val_loss: 56.6001 - val_mae: 5.3639\n",
      "Patience 30: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.1601 - mae: 5.5298\n",
      "Patience 30: Validation MAE: 5.33\n",
      "Patience 30: Validation Loss: 56.26\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 757.5181 - mae: 19.3923 - val_loss: 147.3144 - val_mae: 10.1467\n",
      "Epoch 2/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 244.6834 - mae: 12.4434 - val_loss: 161.3978 - val_mae: 11.0826\n",
      "Epoch 3/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 244.5115 - mae: 12.1342 - val_loss: 106.1489 - val_mae: 8.0912\n",
      "Epoch 4/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 216.3358 - mae: 11.4511 - val_loss: 84.1837 - val_mae: 7.0776\n",
      "Epoch 5/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 190.0571 - mae: 10.6344 - val_loss: 77.6025 - val_mae: 6.3549\n",
      "Epoch 6/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 171.7010 - mae: 10.1280 - val_loss: 73.8458 - val_mae: 6.1962\n",
      "Epoch 7/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 167.3613 - mae: 9.9596 - val_loss: 68.1915 - val_mae: 5.9328\n",
      "Epoch 8/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 173.2169 - mae: 10.1311 - val_loss: 65.6446 - val_mae: 5.8497\n",
      "Epoch 9/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 161.0180 - mae: 9.8133 - val_loss: 66.5030 - val_mae: 5.8393\n",
      "Epoch 10/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 170.7221 - mae: 9.9822 - val_loss: 62.3695 - val_mae: 5.8110\n",
      "Epoch 11/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 162.3304 - mae: 9.7328 - val_loss: 66.4764 - val_mae: 5.9112\n",
      "Epoch 12/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 161.4017 - mae: 9.6795 - val_loss: 71.7830 - val_mae: 6.1319\n",
      "Epoch 13/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 159.1903 - mae: 9.6933 - val_loss: 100.5292 - val_mae: 7.4490\n",
      "Epoch 14/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 169.6581 - mae: 10.1029 - val_loss: 63.6174 - val_mae: 5.7074\n",
      "Epoch 15/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 159.7671 - mae: 9.7909 - val_loss: 65.1418 - val_mae: 5.7867\n",
      "Epoch 16/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.8876 - mae: 9.5392 - val_loss: 72.0620 - val_mae: 6.1266\n",
      "Epoch 17/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 150.5589 - mae: 9.4092 - val_loss: 65.8025 - val_mae: 5.8061\n",
      "Epoch 18/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 157.9507 - mae: 9.6734 - val_loss: 59.7379 - val_mae: 5.6419\n",
      "Epoch 19/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 156.6543 - mae: 9.5902 - val_loss: 61.5760 - val_mae: 5.6333\n",
      "Epoch 20/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 150.3944 - mae: 9.3762 - val_loss: 62.3255 - val_mae: 5.8748\n",
      "Epoch 21/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 151.0192 - mae: 9.3935 - val_loss: 63.5970 - val_mae: 5.7106\n",
      "Epoch 22/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.7943 - mae: 9.4897 - val_loss: 59.7217 - val_mae: 5.6369\n",
      "Epoch 23/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 151.8635 - mae: 9.4958 - val_loss: 61.8425 - val_mae: 5.6233\n",
      "Epoch 24/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 150.2531 - mae: 9.5038 - val_loss: 58.2935 - val_mae: 5.5400\n",
      "Epoch 25/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.2210 - mae: 9.2676 - val_loss: 58.1971 - val_mae: 5.5304\n",
      "Epoch 26/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 155.4900 - mae: 9.5337 - val_loss: 60.3269 - val_mae: 5.7340\n",
      "Epoch 27/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.1733 - mae: 9.2122 - val_loss: 59.3521 - val_mae: 5.5784\n",
      "Epoch 28/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 147.4452 - mae: 9.2274 - val_loss: 58.8857 - val_mae: 5.5877\n",
      "Epoch 29/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.9620 - mae: 9.2368 - val_loss: 59.1754 - val_mae: 5.5115\n",
      "Epoch 30/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.8870 - mae: 9.1198 - val_loss: 59.7372 - val_mae: 5.5980\n",
      "Epoch 31/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.5780 - mae: 9.0178 - val_loss: 62.8327 - val_mae: 5.6722\n",
      "Epoch 32/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.4567 - mae: 9.1475 - val_loss: 58.5678 - val_mae: 5.5200\n",
      "Epoch 33/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.0313 - mae: 9.0577 - val_loss: 58.4256 - val_mae: 5.5840\n",
      "Epoch 34/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 141.9218 - mae: 9.1791 - val_loss: 74.6118 - val_mae: 6.4034\n",
      "Epoch 35/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.3500 - mae: 9.3642 - val_loss: 57.1527 - val_mae: 5.4762\n",
      "Epoch 36/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.0639 - mae: 8.8652 - val_loss: 58.0804 - val_mae: 5.4879\n",
      "Epoch 37/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.0555 - mae: 9.0610 - val_loss: 60.0035 - val_mae: 5.5618\n",
      "Epoch 38/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.0112 - mae: 9.0443 - val_loss: 56.8935 - val_mae: 5.4945\n",
      "Epoch 39/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 134.1076 - mae: 8.9055 - val_loss: 66.2871 - val_mae: 5.8558\n",
      "Epoch 40/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.8120 - mae: 9.0527 - val_loss: 59.0848 - val_mae: 5.4829\n",
      "Epoch 41/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.0105 - mae: 8.8675 - val_loss: 57.4899 - val_mae: 5.4102\n",
      "Epoch 42/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.9164 - mae: 8.9233 - val_loss: 60.2115 - val_mae: 5.5661\n",
      "Epoch 43/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.4540 - mae: 9.0118 - val_loss: 60.4501 - val_mae: 5.6130\n",
      "Epoch 44/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.0442 - mae: 9.0894 - val_loss: 57.9828 - val_mae: 5.4816\n",
      "Epoch 45/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.8795 - mae: 8.7348 - val_loss: 59.2734 - val_mae: 5.4721\n",
      "Epoch 46/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.7878 - mae: 8.6067 - val_loss: 60.3229 - val_mae: 5.7559\n",
      "Epoch 47/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 134.7821 - mae: 8.8987 - val_loss: 57.9704 - val_mae: 5.5583\n",
      "Epoch 48/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.9831 - mae: 8.7715 - val_loss: 58.8957 - val_mae: 5.5284\n",
      "Epoch 49/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.3169 - mae: 8.7911 - val_loss: 56.6237 - val_mae: 5.4126\n",
      "Epoch 50/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.4157 - mae: 8.9755 - val_loss: 56.3914 - val_mae: 5.3639\n",
      "Patience 20: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.0338 - mae: 5.5594\n",
      "Patience 20: Validation MAE: 5.36\n",
      "Patience 20: Validation Loss: 56.39\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 742.2298 - mae: 17.7673 - val_loss: 159.6208 - val_mae: 10.6612\n",
      "Epoch 2/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 251.8221 - mae: 12.1926 - val_loss: 120.4362 - val_mae: 8.4418\n",
      "Epoch 3/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 215.7897 - mae: 11.4732 - val_loss: 113.1220 - val_mae: 7.9411\n",
      "Epoch 4/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 199.3171 - mae: 11.0592 - val_loss: 82.5281 - val_mae: 7.0462\n",
      "Epoch 5/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 186.3321 - mae: 10.4371 - val_loss: 71.0786 - val_mae: 6.2402\n",
      "Epoch 6/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 178.1505 - mae: 10.1969 - val_loss: 77.3736 - val_mae: 6.4176\n",
      "Epoch 7/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 173.4177 - mae: 10.0618 - val_loss: 66.5827 - val_mae: 5.9923\n",
      "Epoch 8/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 155.7903 - mae: 9.6092 - val_loss: 65.0960 - val_mae: 6.0515\n",
      "Epoch 9/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.1020 - mae: 9.4824 - val_loss: 82.4962 - val_mae: 6.7577\n",
      "Epoch 10/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.9343 - mae: 9.2175 - val_loss: 70.6382 - val_mae: 6.4463\n",
      "Epoch 11/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 153.1196 - mae: 9.4679 - val_loss: 60.4061 - val_mae: 5.6755\n",
      "Epoch 12/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.9787 - mae: 9.2768 - val_loss: 62.4202 - val_mae: 5.9353\n",
      "Epoch 13/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.8800 - mae: 9.3863 - val_loss: 81.8214 - val_mae: 7.1882\n",
      "Epoch 14/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 148.2831 - mae: 9.3934 - val_loss: 59.6671 - val_mae: 5.6499\n",
      "Epoch 15/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.8022 - mae: 9.1648 - val_loss: 78.9472 - val_mae: 6.6544\n",
      "Epoch 16/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 154.1086 - mae: 9.5334 - val_loss: 59.9154 - val_mae: 5.6216\n",
      "Epoch 17/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.9301 - mae: 9.0059 - val_loss: 60.0432 - val_mae: 5.6100\n",
      "Epoch 18/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.8206 - mae: 9.2808 - val_loss: 80.8696 - val_mae: 6.5112\n",
      "Epoch 19/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.1017 - mae: 9.2056 - val_loss: 67.4721 - val_mae: 5.9475\n",
      "Epoch 20/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.6050 - mae: 9.0064 - val_loss: 70.8610 - val_mae: 6.1446\n",
      "Epoch 21/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.1314 - mae: 9.0237 - val_loss: 60.3997 - val_mae: 5.6793\n",
      "Epoch 22/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.4250 - mae: 8.9084 - val_loss: 67.2355 - val_mae: 5.9399\n",
      "Epoch 23/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.2006 - mae: 8.9549 - val_loss: 80.6320 - val_mae: 6.7940\n",
      "Epoch 24/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.3484 - mae: 8.8499 - val_loss: 79.1869 - val_mae: 6.7672\n",
      "Patience 10: Early stopping occurred at epoch 23\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.4319 - mae: 5.7900\n",
      "Patience 10: Validation MAE: 5.65\n",
      "Patience 10: Validation Loss: 59.67\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 56.0244, MAE = 5.3419, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 56.2613, MAE = 5.3335, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 20: Loss = 56.3914, MAE = 5.3639, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 10: Loss = 59.6671, MAE = 5.6499, Early Stopping Occurred: True, Early Stopping Epoch: 23\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "bresults50_1 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    dbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    dbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'best_model_{patience}.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = dbp_model.fit(\n",
    "        X_train_combined, DBP_Y_train_combined,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_combined, DBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = dbp_model.evaluate(X_test_combined, DBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    bresults50_1.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    # 학습 및 검증 손실 그래프 시각화\n",
    "    # plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.title(f'Patience = {patience}')\n",
    "    # plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in bresults50_1:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.4156 - mae: 17.7561 - val_loss: 147.1665 - val_mae: 8.9166\n",
      "Epoch 2/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 245.1749 - mae: 12.2677 - val_loss: 110.5828 - val_mae: 7.6382\n",
      "Epoch 3/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 193.2501 - mae: 10.8388 - val_loss: 123.4006 - val_mae: 9.3237\n",
      "Epoch 4/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 187.0896 - mae: 10.5879 - val_loss: 80.1286 - val_mae: 6.3860\n",
      "Epoch 5/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 167.4248 - mae: 10.0138 - val_loss: 105.9951 - val_mae: 7.7294\n",
      "Epoch 6/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 171.7829 - mae: 10.0689 - val_loss: 72.4689 - val_mae: 6.4383\n",
      "Epoch 7/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 173.8675 - mae: 10.1129 - val_loss: 63.9397 - val_mae: 5.7463\n",
      "Epoch 8/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156.1737 - mae: 9.5931 - val_loss: 92.1189 - val_mae: 6.9683\n",
      "Epoch 9/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 170.0808 - mae: 9.9715 - val_loss: 64.4021 - val_mae: 5.8237\n",
      "Epoch 10/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 167.4234 - mae: 9.9530 - val_loss: 73.1791 - val_mae: 6.2208\n",
      "Epoch 11/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159.4578 - mae: 9.7304 - val_loss: 67.0018 - val_mae: 5.8733\n",
      "Epoch 12/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158.7211 - mae: 9.6743 - val_loss: 105.2092 - val_mae: 7.8231\n",
      "Epoch 13/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 151.0338 - mae: 9.4569 - val_loss: 102.5718 - val_mae: 7.7333\n",
      "Epoch 14/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 154.9357 - mae: 9.5831 - val_loss: 62.9200 - val_mae: 5.7037\n",
      "Epoch 15/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158.4024 - mae: 9.6196 - val_loss: 64.2927 - val_mae: 5.7345\n",
      "Epoch 16/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.6308 - mae: 9.1549 - val_loss: 62.0950 - val_mae: 5.6872\n",
      "Epoch 17/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.2513 - mae: 9.4717 - val_loss: 59.6117 - val_mae: 5.5859\n",
      "Epoch 18/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.6795 - mae: 9.2348 - val_loss: 62.2631 - val_mae: 5.6218\n",
      "Epoch 19/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.5795 - mae: 9.0949 - val_loss: 62.5719 - val_mae: 5.7292\n",
      "Epoch 20/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145.1388 - mae: 9.2115 - val_loss: 65.2801 - val_mae: 5.7312\n",
      "Epoch 21/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146.6096 - mae: 9.3266 - val_loss: 58.6290 - val_mae: 5.5066\n",
      "Epoch 22/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146.3696 - mae: 9.3013 - val_loss: 59.5342 - val_mae: 5.6500\n",
      "Epoch 23/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.9220 - mae: 9.0156 - val_loss: 59.0813 - val_mae: 5.4934\n",
      "Epoch 24/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.2821 - mae: 9.1053 - val_loss: 63.1468 - val_mae: 5.7272\n",
      "Epoch 25/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.2979 - mae: 9.2887 - val_loss: 60.0550 - val_mae: 5.5595\n",
      "Epoch 26/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 144.9389 - mae: 9.1383 - val_loss: 61.4222 - val_mae: 5.6533\n",
      "Epoch 27/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.2103 - mae: 8.8474 - val_loss: 67.3996 - val_mae: 6.0129\n",
      "Epoch 28/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 131.9335 - mae: 8.8309 - val_loss: 59.8468 - val_mae: 5.6184\n",
      "Epoch 29/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.7214 - mae: 9.1428 - val_loss: 60.3891 - val_mae: 5.6012\n",
      "Epoch 30/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.0196 - mae: 9.0537 - val_loss: 58.0100 - val_mae: 5.5647\n",
      "Epoch 31/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.9655 - mae: 8.9041 - val_loss: 65.0952 - val_mae: 5.9081\n",
      "Epoch 32/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.3832 - mae: 8.9845 - val_loss: 62.4241 - val_mae: 5.7064\n",
      "Epoch 33/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.3954 - mae: 8.9255 - val_loss: 62.2622 - val_mae: 5.7738\n",
      "Epoch 34/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.4805 - mae: 8.6705 - val_loss: 58.8334 - val_mae: 5.5669\n",
      "Epoch 35/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.9936 - mae: 8.8714 - val_loss: 63.5531 - val_mae: 5.7333\n",
      "Epoch 36/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.3162 - mae: 8.9151 - val_loss: 57.0041 - val_mae: 5.4967\n",
      "Epoch 37/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.4625 - mae: 8.7928 - val_loss: 64.6909 - val_mae: 5.8893\n",
      "Epoch 38/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.5927 - mae: 8.8911 - val_loss: 69.7822 - val_mae: 6.4559\n",
      "Epoch 39/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.3317 - mae: 8.7764 - val_loss: 56.9825 - val_mae: 5.4883\n",
      "Epoch 40/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 131.9533 - mae: 8.7425 - val_loss: 60.0042 - val_mae: 5.6178\n",
      "Epoch 41/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.8894 - mae: 8.8884 - val_loss: 67.1462 - val_mae: 5.8951\n",
      "Epoch 42/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.9100 - mae: 8.7568 - val_loss: 58.5345 - val_mae: 5.4535\n",
      "Epoch 43/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.0337 - mae: 8.8249 - val_loss: 57.8167 - val_mae: 5.4864\n",
      "Epoch 44/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.6134 - mae: 8.7747 - val_loss: 62.2916 - val_mae: 5.7747\n",
      "Epoch 45/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.1817 - mae: 8.8673 - val_loss: 56.3478 - val_mae: 5.3407\n",
      "Epoch 46/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.4258 - mae: 8.6349 - val_loss: 61.1088 - val_mae: 5.5896\n",
      "Epoch 47/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.6231 - mae: 8.5767 - val_loss: 55.3291 - val_mae: 5.3586\n",
      "Epoch 48/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.8204 - mae: 8.5704 - val_loss: 65.2350 - val_mae: 5.8772\n",
      "Epoch 49/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.9335 - mae: 8.7435 - val_loss: 68.1722 - val_mae: 6.0381\n",
      "Epoch 50/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.3583 - mae: 8.4432 - val_loss: 57.0980 - val_mae: 5.4202\n",
      "Epoch 51/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.7186 - mae: 8.4584 - val_loss: 58.9423 - val_mae: 5.5893\n",
      "Epoch 52/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.6818 - mae: 8.5891 - val_loss: 67.8624 - val_mae: 5.9580\n",
      "Epoch 53/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.1627 - mae: 8.5161 - val_loss: 56.6149 - val_mae: 5.3851\n",
      "Epoch 54/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.8961 - mae: 8.5290 - val_loss: 58.6768 - val_mae: 5.5603\n",
      "Epoch 55/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.2406 - mae: 8.5950 - val_loss: 61.5429 - val_mae: 5.6378\n",
      "Epoch 56/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114.4513 - mae: 8.1334 - val_loss: 54.9634 - val_mae: 5.3158\n",
      "Epoch 57/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.6219 - mae: 8.2306 - val_loss: 61.4016 - val_mae: 5.6711\n",
      "Epoch 58/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.2134 - mae: 8.6272 - val_loss: 59.3190 - val_mae: 5.5953\n",
      "Epoch 59/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.2675 - mae: 8.4830 - val_loss: 57.3640 - val_mae: 5.5059\n",
      "Epoch 60/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.2925 - mae: 8.4487 - val_loss: 55.7388 - val_mae: 5.3804\n",
      "Epoch 61/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.5139 - mae: 8.2858 - val_loss: 59.2779 - val_mae: 5.5669\n",
      "Epoch 62/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.8137 - mae: 8.4660 - val_loss: 85.8105 - val_mae: 6.9148\n",
      "Epoch 63/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.4131 - mae: 8.5604 - val_loss: 59.4496 - val_mae: 5.4761\n",
      "Epoch 64/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.3966 - mae: 8.3506 - val_loss: 67.1315 - val_mae: 5.9915\n",
      "Epoch 65/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114.0472 - mae: 8.1189 - val_loss: 55.9210 - val_mae: 5.4033\n",
      "Epoch 66/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.7794 - mae: 8.2012 - val_loss: 62.5486 - val_mae: 5.7928\n",
      "Epoch 67/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.4233 - mae: 8.1936 - val_loss: 57.0670 - val_mae: 5.4121\n",
      "Epoch 68/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.6176 - mae: 8.1746 - val_loss: 60.4877 - val_mae: 5.6136\n",
      "Epoch 69/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 116.8382 - mae: 8.1988 - val_loss: 55.4100 - val_mae: 5.3293\n",
      "Epoch 70/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 118.2752 - mae: 8.2516 - val_loss: 62.3758 - val_mae: 5.7564\n",
      "Epoch 71/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.1574 - mae: 8.1052 - val_loss: 82.3185 - val_mae: 7.2358\n",
      "Epoch 72/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.0080 - mae: 8.2537 - val_loss: 60.3787 - val_mae: 5.5439\n",
      "Epoch 73/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.4478 - mae: 8.4239 - val_loss: 56.8743 - val_mae: 5.4608\n",
      "Epoch 74/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.6713 - mae: 8.2116 - val_loss: 60.4589 - val_mae: 5.6014\n",
      "Epoch 75/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.0609 - mae: 8.0336 - val_loss: 83.9420 - val_mae: 6.9380\n",
      "Epoch 76/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.5707 - mae: 8.1982 - val_loss: 54.5904 - val_mae: 5.3773\n",
      "Epoch 77/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.9478 - mae: 8.1556 - val_loss: 57.3205 - val_mae: 5.4116\n",
      "Epoch 78/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.6091 - mae: 8.1949 - val_loss: 58.3225 - val_mae: 5.5972\n",
      "Epoch 79/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.2351 - mae: 7.9393 - val_loss: 55.0184 - val_mae: 5.3963\n",
      "Epoch 80/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.0848 - mae: 8.1433 - val_loss: 56.4415 - val_mae: 5.5526\n",
      "Epoch 81/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114.2777 - mae: 8.0819 - val_loss: 54.7662 - val_mae: 5.3602\n",
      "Epoch 82/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.4849 - mae: 7.9566 - val_loss: 72.7405 - val_mae: 6.2634\n",
      "Epoch 83/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.2094 - mae: 7.9486 - val_loss: 58.4357 - val_mae: 5.7034\n",
      "Epoch 84/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.0915 - mae: 8.0642 - val_loss: 53.5298 - val_mae: 5.2435\n",
      "Epoch 85/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.6024 - mae: 7.9042 - val_loss: 55.6303 - val_mae: 5.3908\n",
      "Epoch 86/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.0240 - mae: 7.9913 - val_loss: 52.7449 - val_mae: 5.2128\n",
      "Epoch 87/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.6265 - mae: 8.0271 - val_loss: 57.3166 - val_mae: 5.4350\n",
      "Epoch 88/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.3246 - mae: 8.0642 - val_loss: 53.3905 - val_mae: 5.2483\n",
      "Epoch 89/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110.2825 - mae: 7.9396 - val_loss: 56.5743 - val_mae: 5.4181\n",
      "Epoch 90/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.8727 - mae: 7.8097 - val_loss: 56.3797 - val_mae: 5.3766\n",
      "Epoch 91/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.0979 - mae: 7.8577 - val_loss: 77.4161 - val_mae: 6.5386\n",
      "Epoch 92/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.8146 - mae: 8.0275 - val_loss: 60.3780 - val_mae: 5.5918\n",
      "Epoch 93/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109.9383 - mae: 7.8841 - val_loss: 54.7749 - val_mae: 5.4048\n",
      "Epoch 94/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 113.1674 - mae: 8.1164 - val_loss: 53.5651 - val_mae: 5.3160\n",
      "Epoch 95/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 106.2457 - mae: 7.8408 - val_loss: 56.8601 - val_mae: 5.5009\n",
      "Epoch 96/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 104.3355 - mae: 7.7633 - val_loss: 54.2786 - val_mae: 5.3811\n",
      "Epoch 97/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 103.9549 - mae: 7.7036 - val_loss: 60.2389 - val_mae: 5.5609\n",
      "Epoch 98/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 105.5840 - mae: 7.7706 - val_loss: 54.9261 - val_mae: 5.3351\n",
      "Epoch 99/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 107.3051 - mae: 7.8481 - val_loss: 57.2571 - val_mae: 5.4741\n",
      "Epoch 100/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 106.9681 - mae: 7.7076 - val_loss: 59.3329 - val_mae: 5.5234\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.8048 - mae: 5.3819\n",
      "Patience 40: Validation MAE: 5.21\n",
      "Patience 40: Validation Loss: 52.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 534.3429 - mae: 16.8070 - val_loss: 132.9263 - val_mae: 9.7791\n",
      "Epoch 2/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 244.1353 - mae: 12.4193 - val_loss: 116.9608 - val_mae: 7.8707\n",
      "Epoch 3/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 201.1733 - mae: 11.1976 - val_loss: 82.9357 - val_mae: 7.2714\n",
      "Epoch 4/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 185.7084 - mae: 10.5867 - val_loss: 73.5211 - val_mae: 6.2892\n",
      "Epoch 5/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 188.9635 - mae: 10.5672 - val_loss: 68.8262 - val_mae: 6.2407\n",
      "Epoch 6/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 169.2564 - mae: 10.0661 - val_loss: 64.5637 - val_mae: 5.7887\n",
      "Epoch 7/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 165.0732 - mae: 9.8729 - val_loss: 64.2355 - val_mae: 5.8237\n",
      "Epoch 8/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 171.3374 - mae: 10.2162 - val_loss: 70.5293 - val_mae: 6.0482\n",
      "Epoch 9/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 163.9834 - mae: 9.9256 - val_loss: 82.9340 - val_mae: 6.6830\n",
      "Epoch 10/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 164.6719 - mae: 9.9407 - val_loss: 60.8786 - val_mae: 5.6072\n",
      "Epoch 11/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 157.6054 - mae: 9.6643 - val_loss: 63.5275 - val_mae: 5.8195\n",
      "Epoch 12/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 155.5736 - mae: 9.7476 - val_loss: 65.3204 - val_mae: 5.9351\n",
      "Epoch 13/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 158.6832 - mae: 9.7693 - val_loss: 63.9697 - val_mae: 5.7174\n",
      "Epoch 14/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.4223 - mae: 9.5619 - val_loss: 71.9970 - val_mae: 6.0859\n",
      "Epoch 15/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.7250 - mae: 9.5677 - val_loss: 112.0146 - val_mae: 8.3641\n",
      "Epoch 16/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 154.3673 - mae: 9.6320 - val_loss: 60.9745 - val_mae: 5.6211\n",
      "Epoch 17/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 163.8724 - mae: 9.8153 - val_loss: 83.5907 - val_mae: 6.8405\n",
      "Epoch 18/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 162.7773 - mae: 9.7075 - val_loss: 58.8128 - val_mae: 5.5059\n",
      "Epoch 19/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 162.7745 - mae: 9.7608 - val_loss: 65.2114 - val_mae: 5.8254\n",
      "Epoch 20/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 158.1595 - mae: 9.5660 - val_loss: 61.1770 - val_mae: 5.6371\n",
      "Epoch 21/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 151.5428 - mae: 9.4331 - val_loss: 60.6949 - val_mae: 5.6475\n",
      "Epoch 22/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 157.4586 - mae: 9.6667 - val_loss: 62.5759 - val_mae: 5.7432\n",
      "Epoch 23/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.7260 - mae: 9.5516 - val_loss: 64.0521 - val_mae: 5.7612\n",
      "Epoch 24/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.5546 - mae: 9.3328 - val_loss: 65.0601 - val_mae: 5.7973\n",
      "Epoch 25/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.8699 - mae: 9.4628 - val_loss: 62.6815 - val_mae: 5.7167\n",
      "Epoch 26/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 150.8170 - mae: 9.3781 - val_loss: 73.3010 - val_mae: 6.3461\n",
      "Epoch 27/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.9428 - mae: 9.1092 - val_loss: 61.3036 - val_mae: 5.6578\n",
      "Epoch 28/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.9632 - mae: 9.2029 - val_loss: 85.4761 - val_mae: 6.8751\n",
      "Epoch 29/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.8850 - mae: 9.2198 - val_loss: 60.9527 - val_mae: 5.7259\n",
      "Epoch 30/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.6071 - mae: 9.5927 - val_loss: 79.3186 - val_mae: 6.7000\n",
      "Epoch 31/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.1314 - mae: 9.4253 - val_loss: 58.7076 - val_mae: 5.5566\n",
      "Epoch 32/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.7425 - mae: 9.4689 - val_loss: 60.2873 - val_mae: 5.5251\n",
      "Epoch 33/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.9735 - mae: 9.0233 - val_loss: 58.2034 - val_mae: 5.5262\n",
      "Epoch 34/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.6480 - mae: 9.2836 - val_loss: 72.1519 - val_mae: 6.2263\n",
      "Epoch 35/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.7773 - mae: 9.3069 - val_loss: 58.1512 - val_mae: 5.5003\n",
      "Epoch 36/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.1170 - mae: 9.2485 - val_loss: 57.2926 - val_mae: 5.4296\n",
      "Epoch 37/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.9543 - mae: 9.2221 - val_loss: 57.2312 - val_mae: 5.4393\n",
      "Epoch 38/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.1911 - mae: 9.0440 - val_loss: 60.8495 - val_mae: 5.6510\n",
      "Epoch 39/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.9084 - mae: 9.2490 - val_loss: 62.8768 - val_mae: 5.6587\n",
      "Epoch 40/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.6743 - mae: 9.0241 - val_loss: 59.3829 - val_mae: 5.6070\n",
      "Epoch 41/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.0470 - mae: 9.1440 - val_loss: 57.5391 - val_mae: 5.4870\n",
      "Epoch 42/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.7918 - mae: 8.8636 - val_loss: 70.4394 - val_mae: 6.1871\n",
      "Epoch 43/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.0288 - mae: 9.1102 - val_loss: 58.3139 - val_mae: 5.5711\n",
      "Epoch 44/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.2871 - mae: 8.9354 - val_loss: 65.1515 - val_mae: 6.1810\n",
      "Epoch 45/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.7836 - mae: 9.0767 - val_loss: 60.5323 - val_mae: 5.7210\n",
      "Epoch 46/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.4184 - mae: 8.8691 - val_loss: 60.3949 - val_mae: 5.6979\n",
      "Epoch 47/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.3480 - mae: 8.9520 - val_loss: 61.8190 - val_mae: 5.6460\n",
      "Epoch 48/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.5454 - mae: 8.9969 - val_loss: 61.9957 - val_mae: 5.6807\n",
      "Epoch 49/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.2998 - mae: 8.6428 - val_loss: 57.0295 - val_mae: 5.4564\n",
      "Epoch 50/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.1731 - mae: 8.7121 - val_loss: 68.3906 - val_mae: 6.4044\n",
      "Epoch 51/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.3426 - mae: 9.0219 - val_loss: 93.1282 - val_mae: 7.4220\n",
      "Epoch 52/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.7846 - mae: 9.2014 - val_loss: 56.6888 - val_mae: 5.4153\n",
      "Epoch 53/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.3022 - mae: 8.7387 - val_loss: 67.0326 - val_mae: 5.8727\n",
      "Epoch 54/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.9559 - mae: 8.5524 - val_loss: 85.9891 - val_mae: 6.8486\n",
      "Epoch 55/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.2128 - mae: 8.8073 - val_loss: 54.8569 - val_mae: 5.3196\n",
      "Epoch 56/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.8249 - mae: 8.8079 - val_loss: 86.8723 - val_mae: 7.0516\n",
      "Epoch 57/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.7172 - mae: 8.6113 - val_loss: 67.9187 - val_mae: 6.2760\n",
      "Epoch 58/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.0840 - mae: 8.8429 - val_loss: 57.7361 - val_mae: 5.4298\n",
      "Epoch 59/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.9363 - mae: 8.6847 - val_loss: 56.6197 - val_mae: 5.3524\n",
      "Epoch 60/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.5003 - mae: 8.4486 - val_loss: 58.4835 - val_mae: 5.6293\n",
      "Epoch 61/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.2356 - mae: 8.6963 - val_loss: 59.9041 - val_mae: 5.6699\n",
      "Epoch 62/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.4090 - mae: 8.5571 - val_loss: 68.9949 - val_mae: 6.0129\n",
      "Epoch 63/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.0906 - mae: 8.7230 - val_loss: 56.2640 - val_mae: 5.3455\n",
      "Epoch 64/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.9728 - mae: 8.8316 - val_loss: 56.1588 - val_mae: 5.2359\n",
      "Epoch 65/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.4091 - mae: 8.7324 - val_loss: 61.1764 - val_mae: 5.6697\n",
      "Epoch 66/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.5951 - mae: 8.6634 - val_loss: 62.8426 - val_mae: 5.6836\n",
      "Epoch 67/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.7178 - mae: 8.4376 - val_loss: 68.7635 - val_mae: 6.0033\n",
      "Epoch 68/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.0293 - mae: 8.1599 - val_loss: 57.7085 - val_mae: 5.4547\n",
      "Epoch 69/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.2612 - mae: 8.4292 - val_loss: 54.8146 - val_mae: 5.2464\n",
      "Epoch 70/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.0020 - mae: 8.3900 - val_loss: 59.5946 - val_mae: 5.5516\n",
      "Epoch 71/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.1134 - mae: 8.5506 - val_loss: 59.3228 - val_mae: 5.5796\n",
      "Epoch 72/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.9436 - mae: 8.5349 - val_loss: 61.4884 - val_mae: 5.5691\n",
      "Epoch 73/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.4278 - mae: 8.3710 - val_loss: 62.4979 - val_mae: 5.6747\n",
      "Epoch 74/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.6497 - mae: 8.5450 - val_loss: 60.7023 - val_mae: 5.7611\n",
      "Epoch 75/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.7043 - mae: 8.6899 - val_loss: 70.1036 - val_mae: 6.1219\n",
      "Epoch 76/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.5302 - mae: 8.4873 - val_loss: 55.3813 - val_mae: 5.2469\n",
      "Epoch 77/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.4981 - mae: 8.4589 - val_loss: 62.1126 - val_mae: 5.6780\n",
      "Epoch 78/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.4022 - mae: 8.4739 - val_loss: 60.3190 - val_mae: 5.5008\n",
      "Epoch 79/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.2441 - mae: 8.4305 - val_loss: 54.6816 - val_mae: 5.2166\n",
      "Epoch 80/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.9268 - mae: 8.2381 - val_loss: 60.6792 - val_mae: 5.7207\n",
      "Epoch 81/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.4778 - mae: 8.2770 - val_loss: 55.1069 - val_mae: 5.2558\n",
      "Epoch 82/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.8501 - mae: 8.2177 - val_loss: 58.4044 - val_mae: 5.3960\n",
      "Epoch 83/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.6841 - mae: 8.0791 - val_loss: 55.5223 - val_mae: 5.3904\n",
      "Epoch 84/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.3889 - mae: 8.3840 - val_loss: 60.7171 - val_mae: 5.6158\n",
      "Epoch 85/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.6937 - mae: 8.2232 - val_loss: 60.4967 - val_mae: 5.5647\n",
      "Epoch 86/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.8614 - mae: 8.0515 - val_loss: 56.3013 - val_mae: 5.3578\n",
      "Epoch 87/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.2157 - mae: 7.9960 - val_loss: 60.5905 - val_mae: 5.5820\n",
      "Epoch 88/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.3442 - mae: 8.2728 - val_loss: 58.8197 - val_mae: 5.4793\n",
      "Epoch 89/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.8535 - mae: 8.0235 - val_loss: 54.0943 - val_mae: 5.2780\n",
      "Epoch 90/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114.8144 - mae: 8.1804 - val_loss: 55.3827 - val_mae: 5.2995\n",
      "Epoch 91/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.6813 - mae: 8.0413 - val_loss: 55.7580 - val_mae: 5.3062\n",
      "Epoch 92/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.5845 - mae: 8.2454 - val_loss: 55.5549 - val_mae: 5.3429\n",
      "Epoch 93/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.7088 - mae: 8.3084 - val_loss: 69.4786 - val_mae: 6.1369\n",
      "Epoch 94/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.4385 - mae: 8.0439 - val_loss: 72.4197 - val_mae: 6.4014\n",
      "Epoch 95/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.6509 - mae: 8.0141 - val_loss: 54.5212 - val_mae: 5.3829\n",
      "Epoch 96/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110.7714 - mae: 7.9754 - val_loss: 55.0041 - val_mae: 5.2394\n",
      "Epoch 97/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.3409 - mae: 7.9130 - val_loss: 56.8118 - val_mae: 5.5282\n",
      "Epoch 98/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 106.6940 - mae: 7.8507 - val_loss: 58.3771 - val_mae: 5.4420\n",
      "Epoch 99/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.8519 - mae: 8.0004 - val_loss: 53.8743 - val_mae: 5.2439\n",
      "Epoch 100/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.4626 - mae: 8.0250 - val_loss: 56.0916 - val_mae: 5.3627\n",
      "Patience 30: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.8337 - mae: 5.3783\n",
      "Patience 30: Validation MAE: 5.24\n",
      "Patience 30: Validation Loss: 53.87\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 658.6506 - mae: 17.4553 - val_loss: 145.7847 - val_mae: 9.6577\n",
      "Epoch 2/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 252.1779 - mae: 12.5878 - val_loss: 118.2726 - val_mae: 7.9468\n",
      "Epoch 3/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 212.1272 - mae: 11.3222 - val_loss: 102.7191 - val_mae: 7.3889\n",
      "Epoch 4/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 187.8756 - mae: 10.6183 - val_loss: 73.4548 - val_mae: 6.3824\n",
      "Epoch 5/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 182.7182 - mae: 10.4449 - val_loss: 74.4869 - val_mae: 6.5602\n",
      "Epoch 6/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 177.3779 - mae: 10.1464 - val_loss: 71.4156 - val_mae: 6.2394\n",
      "Epoch 7/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 150.5974 - mae: 9.5458 - val_loss: 71.4669 - val_mae: 6.0671\n",
      "Epoch 8/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 171.4025 - mae: 10.1205 - val_loss: 102.5106 - val_mae: 7.7422\n",
      "Epoch 9/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.8331 - mae: 9.5965 - val_loss: 70.2189 - val_mae: 6.0339\n",
      "Epoch 10/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 154.8841 - mae: 9.6052 - val_loss: 67.2699 - val_mae: 6.1851\n",
      "Epoch 11/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.8160 - mae: 9.3177 - val_loss: 102.1364 - val_mae: 7.5950\n",
      "Epoch 12/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.5339 - mae: 9.2430 - val_loss: 120.6929 - val_mae: 8.5496\n",
      "Epoch 13/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.7388 - mae: 9.5378 - val_loss: 97.7198 - val_mae: 7.3949\n",
      "Epoch 14/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 150.8310 - mae: 9.4544 - val_loss: 64.3468 - val_mae: 5.8208\n",
      "Epoch 15/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.3356 - mae: 9.4012 - val_loss: 66.4712 - val_mae: 6.1445\n",
      "Epoch 16/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 149.5807 - mae: 9.3978 - val_loss: 63.9363 - val_mae: 5.8170\n",
      "Epoch 17/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.1100 - mae: 9.1891 - val_loss: 63.7200 - val_mae: 5.8225\n",
      "Epoch 18/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.1536 - mae: 9.0865 - val_loss: 80.3315 - val_mae: 7.0453\n",
      "Epoch 19/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.0737 - mae: 9.2828 - val_loss: 69.1295 - val_mae: 5.9860\n",
      "Epoch 20/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.6571 - mae: 9.0293 - val_loss: 66.6406 - val_mae: 6.0625\n",
      "Epoch 21/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.1717 - mae: 9.1928 - val_loss: 65.4048 - val_mae: 5.7992\n",
      "Epoch 22/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.0199 - mae: 9.2235 - val_loss: 63.6408 - val_mae: 5.8082\n",
      "Epoch 23/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141.0177 - mae: 9.1467 - val_loss: 78.1834 - val_mae: 6.5492\n",
      "Epoch 24/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.1499 - mae: 8.8922 - val_loss: 65.5214 - val_mae: 6.0927\n",
      "Epoch 25/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.4227 - mae: 9.2064 - val_loss: 61.8172 - val_mae: 5.6485\n",
      "Epoch 26/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.7735 - mae: 8.7989 - val_loss: 62.3869 - val_mae: 5.8679\n",
      "Epoch 27/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134.5714 - mae: 8.9556 - val_loss: 67.5784 - val_mae: 6.2042\n",
      "Epoch 28/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.1566 - mae: 8.7296 - val_loss: 68.0546 - val_mae: 6.0278\n",
      "Epoch 29/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.5314 - mae: 8.9413 - val_loss: 59.3342 - val_mae: 5.6392\n",
      "Epoch 30/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.0896 - mae: 8.6951 - val_loss: 59.1248 - val_mae: 5.5558\n",
      "Epoch 31/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.3188 - mae: 8.9441 - val_loss: 70.7737 - val_mae: 6.1188\n",
      "Epoch 32/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.1987 - mae: 8.8134 - val_loss: 59.2678 - val_mae: 5.5924\n",
      "Epoch 33/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.8875 - mae: 8.6626 - val_loss: 57.4322 - val_mae: 5.4295\n",
      "Epoch 34/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.4664 - mae: 8.8331 - val_loss: 61.8051 - val_mae: 5.6791\n",
      "Epoch 35/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.5399 - mae: 8.5007 - val_loss: 58.6693 - val_mae: 5.5267\n",
      "Epoch 36/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.3858 - mae: 8.4561 - val_loss: 58.0316 - val_mae: 5.4565\n",
      "Epoch 37/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.2181 - mae: 8.6459 - val_loss: 58.7763 - val_mae: 5.5793\n",
      "Epoch 38/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.7965 - mae: 8.6242 - val_loss: 58.8702 - val_mae: 5.5863\n",
      "Epoch 39/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.4813 - mae: 8.5973 - val_loss: 100.8788 - val_mae: 7.5190\n",
      "Epoch 40/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.3402 - mae: 8.8035 - val_loss: 60.1044 - val_mae: 5.6546\n",
      "Epoch 41/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.5874 - mae: 8.6173 - val_loss: 91.5237 - val_mae: 7.1374\n",
      "Epoch 42/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.5648 - mae: 8.6758 - val_loss: 56.9114 - val_mae: 5.3794\n",
      "Epoch 43/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.9762 - mae: 8.3824 - val_loss: 60.6111 - val_mae: 5.8086\n",
      "Epoch 44/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.1010 - mae: 8.5365 - val_loss: 60.6562 - val_mae: 5.7048\n",
      "Epoch 45/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.2062 - mae: 8.5510 - val_loss: 78.6905 - val_mae: 6.5492\n",
      "Epoch 46/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.1962 - mae: 8.7906 - val_loss: 62.0108 - val_mae: 5.6513\n",
      "Epoch 47/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.7356 - mae: 8.5668 - val_loss: 56.7876 - val_mae: 5.3441\n",
      "Epoch 48/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.0686 - mae: 8.2330 - val_loss: 61.8561 - val_mae: 5.6772\n",
      "Epoch 49/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.2373 - mae: 8.5117 - val_loss: 57.7715 - val_mae: 5.3785\n",
      "Epoch 50/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.7705 - mae: 8.6649 - val_loss: 61.8634 - val_mae: 5.6221\n",
      "Epoch 51/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.6270 - mae: 8.5031 - val_loss: 66.5363 - val_mae: 5.9163\n",
      "Epoch 52/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.8677 - mae: 8.1579 - val_loss: 56.8487 - val_mae: 5.3428\n",
      "Epoch 53/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.4589 - mae: 8.6327 - val_loss: 86.7383 - val_mae: 7.1021\n",
      "Epoch 54/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.9305 - mae: 8.7408 - val_loss: 57.7143 - val_mae: 5.3689\n",
      "Epoch 55/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.7718 - mae: 8.3647 - val_loss: 64.5247 - val_mae: 6.0101\n",
      "Epoch 56/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.9869 - mae: 8.5043 - val_loss: 59.3358 - val_mae: 5.4472\n",
      "Epoch 57/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.1314 - mae: 8.3544 - val_loss: 56.7418 - val_mae: 5.3544\n",
      "Epoch 58/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.7273 - mae: 8.3335 - val_loss: 62.0373 - val_mae: 5.6898\n",
      "Epoch 59/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.0617 - mae: 8.2266 - val_loss: 59.6460 - val_mae: 5.6130\n",
      "Epoch 60/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.7561 - mae: 8.5158 - val_loss: 64.3867 - val_mae: 5.7128\n",
      "Epoch 61/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.2494 - mae: 8.1865 - val_loss: 59.6304 - val_mae: 5.5616\n",
      "Epoch 62/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.0239 - mae: 8.2673 - val_loss: 59.4304 - val_mae: 5.5082\n",
      "Epoch 63/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120.2411 - mae: 8.3409 - val_loss: 63.6248 - val_mae: 5.6843\n",
      "Epoch 64/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.3094 - mae: 8.1841 - val_loss: 63.3930 - val_mae: 5.9124\n",
      "Epoch 65/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.9717 - mae: 8.5358 - val_loss: 86.2079 - val_mae: 7.0867\n",
      "Epoch 66/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.8578 - mae: 8.2743 - val_loss: 65.0886 - val_mae: 5.7763\n",
      "Epoch 67/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.3315 - mae: 8.1868 - val_loss: 57.8295 - val_mae: 5.4115\n",
      "Epoch 68/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.1904 - mae: 8.2505 - val_loss: 61.9554 - val_mae: 5.8479\n",
      "Epoch 69/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121.3437 - mae: 8.3400 - val_loss: 57.8270 - val_mae: 5.4263\n",
      "Epoch 70/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118.1819 - mae: 8.3232 - val_loss: 54.4409 - val_mae: 5.2716\n",
      "Epoch 71/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.4964 - mae: 8.0533 - val_loss: 55.9624 - val_mae: 5.3647\n",
      "Epoch 72/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.5920 - mae: 8.0236 - val_loss: 76.1600 - val_mae: 6.5510\n",
      "Epoch 73/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.9183 - mae: 8.1626 - val_loss: 55.5048 - val_mae: 5.3003\n",
      "Epoch 74/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.5616 - mae: 8.2042 - val_loss: 58.6085 - val_mae: 5.4100\n",
      "Epoch 75/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.1139 - mae: 8.1554 - val_loss: 56.1128 - val_mae: 5.3319\n",
      "Epoch 76/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.0207 - mae: 8.1176 - val_loss: 56.9360 - val_mae: 5.3617\n",
      "Epoch 77/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.7453 - mae: 8.1976 - val_loss: 56.6603 - val_mae: 5.3649\n",
      "Epoch 78/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.7219 - mae: 7.9569 - val_loss: 58.7642 - val_mae: 5.4726\n",
      "Epoch 79/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.7056 - mae: 8.1052 - val_loss: 55.4502 - val_mae: 5.3129\n",
      "Epoch 80/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.3914 - mae: 7.8544 - val_loss: 56.3161 - val_mae: 5.4451\n",
      "Epoch 81/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.1122 - mae: 8.2179 - val_loss: 53.5456 - val_mae: 5.2462\n",
      "Epoch 82/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.2288 - mae: 7.7945 - val_loss: 62.4016 - val_mae: 5.7172\n",
      "Epoch 83/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.8472 - mae: 7.8644 - val_loss: 63.3098 - val_mae: 5.7999\n",
      "Epoch 84/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.6499 - mae: 8.0382 - val_loss: 58.5368 - val_mae: 5.4137\n",
      "Epoch 85/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.9834 - mae: 7.9621 - val_loss: 71.9187 - val_mae: 6.1598\n",
      "Epoch 86/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.0469 - mae: 8.0888 - val_loss: 58.6159 - val_mae: 5.4921\n",
      "Epoch 87/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.9972 - mae: 7.8907 - val_loss: 53.8521 - val_mae: 5.2839\n",
      "Epoch 88/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.5386 - mae: 7.8148 - val_loss: 54.5971 - val_mae: 5.2579\n",
      "Epoch 89/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.3969 - mae: 7.9158 - val_loss: 66.1108 - val_mae: 5.9365\n",
      "Epoch 90/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.3359 - mae: 7.8755 - val_loss: 62.4611 - val_mae: 6.0035\n",
      "Epoch 91/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.3061 - mae: 8.0077 - val_loss: 54.1598 - val_mae: 5.2343\n",
      "Epoch 92/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.5229 - mae: 7.8516 - val_loss: 67.6166 - val_mae: 6.0280\n",
      "Epoch 93/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.8890 - mae: 7.9447 - val_loss: 69.5728 - val_mae: 6.1466\n",
      "Epoch 94/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.3245 - mae: 7.8446 - val_loss: 65.6166 - val_mae: 5.7807\n",
      "Epoch 95/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.9969 - mae: 7.7395 - val_loss: 58.3517 - val_mae: 5.5532\n",
      "Epoch 96/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.6740 - mae: 7.7653 - val_loss: 57.0292 - val_mae: 5.5696\n",
      "Epoch 97/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.1803 - mae: 8.0168 - val_loss: 55.9805 - val_mae: 5.3018\n",
      "Epoch 98/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.4139 - mae: 7.7048 - val_loss: 61.9442 - val_mae: 5.7252\n",
      "Epoch 99/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.2810 - mae: 7.7558 - val_loss: 58.0619 - val_mae: 5.6824\n",
      "Epoch 100/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.4438 - mae: 7.9343 - val_loss: 55.6037 - val_mae: 5.3673\n",
      "Patience 20: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60.8579 - mae: 5.3966\n",
      "Patience 20: Validation MAE: 5.25\n",
      "Patience 20: Validation Loss: 53.55\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 715.9344 - mae: 17.6271 - val_loss: 171.1015 - val_mae: 9.5696\n",
      "Epoch 2/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 267.5432 - mae: 12.8725 - val_loss: 149.5061 - val_mae: 8.8487\n",
      "Epoch 3/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 217.0899 - mae: 11.4798 - val_loss: 90.7355 - val_mae: 7.5784\n",
      "Epoch 4/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 189.4524 - mae: 10.7201 - val_loss: 117.7442 - val_mae: 8.8866\n",
      "Epoch 5/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 178.6877 - mae: 10.3376 - val_loss: 67.5870 - val_mae: 6.1306\n",
      "Epoch 6/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 168.1190 - mae: 10.0982 - val_loss: 78.2607 - val_mae: 6.7832\n",
      "Epoch 7/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 170.1596 - mae: 10.1517 - val_loss: 74.6913 - val_mae: 6.2731\n",
      "Epoch 8/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 160.9872 - mae: 9.7239 - val_loss: 87.7391 - val_mae: 6.9546\n",
      "Epoch 9/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158.1474 - mae: 9.6939 - val_loss: 65.9024 - val_mae: 5.8787\n",
      "Epoch 10/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158.2028 - mae: 9.6341 - val_loss: 66.1574 - val_mae: 5.8309\n",
      "Epoch 11/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 161.1024 - mae: 9.7900 - val_loss: 65.5755 - val_mae: 6.0805\n",
      "Epoch 12/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148.0564 - mae: 9.3885 - val_loss: 62.6692 - val_mae: 5.8360\n",
      "Epoch 13/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152.2121 - mae: 9.3511 - val_loss: 67.9303 - val_mae: 6.0216\n",
      "Epoch 14/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147.4303 - mae: 9.2801 - val_loss: 64.9517 - val_mae: 5.7569\n",
      "Epoch 15/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139.7508 - mae: 9.0876 - val_loss: 65.2055 - val_mae: 5.7651\n",
      "Epoch 16/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.7997 - mae: 9.0839 - val_loss: 92.1661 - val_mae: 7.2533\n",
      "Epoch 17/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.2716 - mae: 9.2157 - val_loss: 61.0453 - val_mae: 5.6237\n",
      "Epoch 18/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139.0866 - mae: 9.0124 - val_loss: 64.6807 - val_mae: 5.7881\n",
      "Epoch 19/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.6577 - mae: 9.0868 - val_loss: 61.2324 - val_mae: 5.6593\n",
      "Epoch 20/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139.8146 - mae: 8.9847 - val_loss: 62.1966 - val_mae: 5.7087\n",
      "Epoch 21/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.1768 - mae: 9.0300 - val_loss: 59.9646 - val_mae: 5.5666\n",
      "Epoch 22/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135.5592 - mae: 8.9448 - val_loss: 67.6751 - val_mae: 5.9176\n",
      "Epoch 23/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145.2439 - mae: 9.2324 - val_loss: 77.6626 - val_mae: 6.4094\n",
      "Epoch 24/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143.4804 - mae: 9.1476 - val_loss: 64.2201 - val_mae: 5.7193\n",
      "Epoch 25/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135.8868 - mae: 8.9913 - val_loss: 68.6770 - val_mae: 5.9777\n",
      "Epoch 26/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135.0094 - mae: 8.8421 - val_loss: 64.0532 - val_mae: 5.8848\n",
      "Epoch 27/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.2495 - mae: 8.8412 - val_loss: 63.6913 - val_mae: 5.7210\n",
      "Epoch 28/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.2529 - mae: 8.7469 - val_loss: 64.3753 - val_mae: 5.8178\n",
      "Epoch 29/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.5281 - mae: 9.1005 - val_loss: 60.7325 - val_mae: 5.5032\n",
      "Epoch 30/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.6228 - mae: 9.1013 - val_loss: 60.1265 - val_mae: 5.6489\n",
      "Epoch 31/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.1136 - mae: 8.6837 - val_loss: 64.4391 - val_mae: 5.8138\n",
      "Patience 10: Early stopping occurred at epoch 30\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65.8099 - mae: 5.7401\n",
      "Patience 10: Validation MAE: 5.57\n",
      "Patience 10: Validation Loss: 59.96\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 52.7448, MAE = 5.2128, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 53.8743, MAE = 5.2439, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 20: Loss = 53.5456, MAE = 5.2462, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 10: Loss = 59.9646, MAE = 5.5666, Early Stopping Occurred: True, Early Stopping Epoch: 30\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "bresults100 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    dbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    dbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'best_model_{patience}.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = dbp_model.fit(\n",
    "        X_train_combined, DBP_Y_train_combined,\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        validation_data=(X_test_combined, DBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = dbp_model.evaluate(X_test_combined, DBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    bresults100.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    # 학습 및 검증 손실 그래프 시각화\n",
    "    # plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.title(f'Patience = {patience}')\n",
    "    # plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in bresults100:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 555.4863 - mae: 16.9902 - val_loss: 148.9039 - val_mae: 9.6590\n",
      "Epoch 2/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 268.8852 - mae: 12.8377 - val_loss: 129.1943 - val_mae: 9.6976\n",
      "Epoch 3/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 227.1621 - mae: 11.8942 - val_loss: 107.2560 - val_mae: 8.3385\n",
      "Epoch 4/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.1817 - mae: 11.0465 - val_loss: 105.8113 - val_mae: 8.3230\n",
      "Epoch 5/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.6527 - mae: 11.2604 - val_loss: 106.1609 - val_mae: 7.5190\n",
      "Epoch 6/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.7766 - mae: 10.8262 - val_loss: 80.3006 - val_mae: 6.6025\n",
      "Epoch 7/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171.2174 - mae: 10.2028 - val_loss: 71.5470 - val_mae: 6.2193\n",
      "Epoch 8/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 168.3136 - mae: 10.1775 - val_loss: 68.2750 - val_mae: 6.0820\n",
      "Epoch 9/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 160.3285 - mae: 9.7691 - val_loss: 71.3537 - val_mae: 6.3256\n",
      "Epoch 10/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 162.2666 - mae: 9.8789 - val_loss: 70.5782 - val_mae: 6.2089\n",
      "Epoch 11/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 159.6683 - mae: 9.7791 - val_loss: 74.0765 - val_mae: 6.3503\n",
      "Epoch 12/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 167.9945 - mae: 10.0063 - val_loss: 70.3806 - val_mae: 6.2999\n",
      "Epoch 13/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 157.0057 - mae: 9.6984 - val_loss: 66.6632 - val_mae: 5.9989\n",
      "Epoch 14/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.2446 - mae: 9.5645 - val_loss: 78.5818 - val_mae: 6.5318\n",
      "Epoch 15/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.7654 - mae: 9.4364 - val_loss: 97.9833 - val_mae: 7.4939\n",
      "Epoch 16/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 150.8409 - mae: 9.4244 - val_loss: 73.6569 - val_mae: 6.6138\n",
      "Epoch 17/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153.9196 - mae: 9.5892 - val_loss: 72.3665 - val_mae: 6.0925\n",
      "Epoch 18/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.8707 - mae: 9.3520 - val_loss: 66.6469 - val_mae: 6.0404\n",
      "Epoch 19/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 154.0064 - mae: 9.4750 - val_loss: 63.7597 - val_mae: 5.9269\n",
      "Epoch 20/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 170.0216 - mae: 9.9553 - val_loss: 61.5815 - val_mae: 5.7272\n",
      "Epoch 21/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 155.3784 - mae: 9.6350 - val_loss: 64.4902 - val_mae: 5.9705\n",
      "Epoch 22/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.0033 - mae: 9.4960 - val_loss: 61.1444 - val_mae: 5.5967\n",
      "Epoch 23/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146.9146 - mae: 9.3224 - val_loss: 60.7946 - val_mae: 5.6008\n",
      "Epoch 24/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138.5603 - mae: 9.1478 - val_loss: 65.2954 - val_mae: 5.7893\n",
      "Epoch 25/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 152.6715 - mae: 9.4035 - val_loss: 58.9347 - val_mae: 5.5772\n",
      "Epoch 26/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.2328 - mae: 9.1274 - val_loss: 62.9873 - val_mae: 5.6597\n",
      "Epoch 27/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.6181 - mae: 9.3208 - val_loss: 59.9855 - val_mae: 5.6305\n",
      "Epoch 28/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.7732 - mae: 9.3193 - val_loss: 57.0368 - val_mae: 5.4349\n",
      "Epoch 29/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.1746 - mae: 9.2516 - val_loss: 64.7395 - val_mae: 5.7941\n",
      "Epoch 30/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 146.5347 - mae: 9.3565 - val_loss: 83.5578 - val_mae: 6.8260\n",
      "Epoch 31/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.9431 - mae: 9.2961 - val_loss: 72.6639 - val_mae: 6.2012\n",
      "Epoch 32/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.6820 - mae: 9.1120 - val_loss: 66.7719 - val_mae: 5.9227\n",
      "Epoch 33/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152.0358 - mae: 9.3347 - val_loss: 58.3399 - val_mae: 5.4669\n",
      "Epoch 34/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.4732 - mae: 8.9759 - val_loss: 57.3228 - val_mae: 5.4414\n",
      "Epoch 35/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.9121 - mae: 8.8415 - val_loss: 60.0962 - val_mae: 5.6532\n",
      "Epoch 36/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.6681 - mae: 9.0440 - val_loss: 65.4742 - val_mae: 5.8046\n",
      "Epoch 37/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.1746 - mae: 9.0569 - val_loss: 59.4546 - val_mae: 5.5207\n",
      "Epoch 38/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.6379 - mae: 8.8492 - val_loss: 56.7437 - val_mae: 5.3830\n",
      "Epoch 39/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.4363 - mae: 9.2337 - val_loss: 59.6812 - val_mae: 5.5016\n",
      "Epoch 40/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138.8578 - mae: 8.9214 - val_loss: 63.1255 - val_mae: 5.7257\n",
      "Epoch 41/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.5754 - mae: 8.9790 - val_loss: 60.6826 - val_mae: 5.5709\n",
      "Epoch 42/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.0720 - mae: 8.8264 - val_loss: 64.3382 - val_mae: 5.7697\n",
      "Epoch 43/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.5856 - mae: 8.7921 - val_loss: 64.7634 - val_mae: 5.8075\n",
      "Epoch 44/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.9104 - mae: 9.0300 - val_loss: 60.6037 - val_mae: 5.7115\n",
      "Epoch 45/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.4670 - mae: 8.7927 - val_loss: 71.4549 - val_mae: 6.2218\n",
      "Epoch 46/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.3239 - mae: 8.9562 - val_loss: 72.5438 - val_mae: 6.1505\n",
      "Epoch 47/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 142.1780 - mae: 9.0813 - val_loss: 60.0081 - val_mae: 5.7872\n",
      "Epoch 48/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 133.9083 - mae: 8.8373 - val_loss: 75.3224 - val_mae: 6.4568\n",
      "Epoch 49/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.9542 - mae: 8.7584 - val_loss: 62.7657 - val_mae: 5.6310\n",
      "Epoch 50/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.6377 - mae: 8.8913 - val_loss: 67.4316 - val_mae: 5.9597\n",
      "Epoch 51/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.4191 - mae: 8.8363 - val_loss: 60.1980 - val_mae: 5.6356\n",
      "Epoch 52/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.6765 - mae: 8.8482 - val_loss: 71.4166 - val_mae: 6.2043\n",
      "Epoch 53/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.7575 - mae: 8.8715 - val_loss: 60.6717 - val_mae: 5.5353\n",
      "Epoch 54/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 136.0849 - mae: 8.9951 - val_loss: 57.8566 - val_mae: 5.5120\n",
      "Epoch 55/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.8205 - mae: 8.7945 - val_loss: 61.7615 - val_mae: 5.6231\n",
      "Epoch 56/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 141.2435 - mae: 9.1029 - val_loss: 57.2583 - val_mae: 5.4005\n",
      "Epoch 57/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.4918 - mae: 8.8973 - val_loss: 61.1705 - val_mae: 5.6176\n",
      "Epoch 58/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.3811 - mae: 8.7908 - val_loss: 57.5162 - val_mae: 5.3889\n",
      "Epoch 59/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.8156 - mae: 8.4997 - val_loss: 59.8359 - val_mae: 5.5256\n",
      "Epoch 60/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.2304 - mae: 8.5470 - val_loss: 64.3547 - val_mae: 5.7438\n",
      "Epoch 61/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.4364 - mae: 8.6152 - val_loss: 58.6777 - val_mae: 5.6101\n",
      "Epoch 62/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.3615 - mae: 8.6741 - val_loss: 61.7464 - val_mae: 5.9011\n",
      "Epoch 63/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.6156 - mae: 8.5868 - val_loss: 55.6185 - val_mae: 5.3616\n",
      "Epoch 64/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.0217 - mae: 8.6902 - val_loss: 65.0155 - val_mae: 5.8455\n",
      "Epoch 65/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.7530 - mae: 8.6515 - val_loss: 62.4044 - val_mae: 5.6555\n",
      "Epoch 66/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.9274 - mae: 8.5370 - val_loss: 58.2061 - val_mae: 5.5245\n",
      "Epoch 67/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 126.3368 - mae: 8.5718 - val_loss: 58.9003 - val_mae: 5.4696\n",
      "Epoch 68/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.8042 - mae: 8.5118 - val_loss: 70.1310 - val_mae: 6.1809\n",
      "Epoch 69/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.7490 - mae: 8.5852 - val_loss: 56.8691 - val_mae: 5.3792\n",
      "Epoch 70/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 122.8267 - mae: 8.4874 - val_loss: 70.9351 - val_mae: 6.2190\n",
      "Epoch 71/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.0217 - mae: 8.5655 - val_loss: 61.7016 - val_mae: 5.6957\n",
      "Epoch 72/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.8069 - mae: 8.7137 - val_loss: 59.6561 - val_mae: 5.5873\n",
      "Epoch 73/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.1973 - mae: 8.5108 - val_loss: 55.7933 - val_mae: 5.3413\n",
      "Epoch 74/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124.7911 - mae: 8.5401 - val_loss: 57.4331 - val_mae: 5.5294\n",
      "Epoch 75/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.9893 - mae: 8.6376 - val_loss: 59.3568 - val_mae: 5.5598\n",
      "Epoch 76/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.8016 - mae: 8.4571 - val_loss: 57.4560 - val_mae: 5.5004\n",
      "Epoch 77/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.0087 - mae: 8.5053 - val_loss: 63.3870 - val_mae: 5.6794\n",
      "Epoch 78/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.6385 - mae: 8.2588 - val_loss: 55.9710 - val_mae: 5.3329\n",
      "Epoch 79/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.3893 - mae: 8.6590 - val_loss: 61.0029 - val_mae: 5.6833\n",
      "Epoch 80/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.3390 - mae: 8.7308 - val_loss: 58.6828 - val_mae: 5.5449\n",
      "Epoch 81/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.5571 - mae: 8.3658 - val_loss: 57.8742 - val_mae: 5.4048\n",
      "Epoch 82/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.7931 - mae: 8.5200 - val_loss: 54.8418 - val_mae: 5.3502\n",
      "Epoch 83/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.0895 - mae: 8.3445 - val_loss: 61.8266 - val_mae: 5.6571\n",
      "Epoch 84/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.7028 - mae: 8.4725 - val_loss: 58.2922 - val_mae: 5.4597\n",
      "Epoch 85/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.3574 - mae: 8.2699 - val_loss: 62.8265 - val_mae: 5.7175\n",
      "Epoch 86/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.4529 - mae: 8.3335 - val_loss: 68.8354 - val_mae: 6.0078\n",
      "Epoch 87/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.2407 - mae: 8.1113 - val_loss: 56.4200 - val_mae: 5.4579\n",
      "Epoch 88/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.9969 - mae: 8.2486 - val_loss: 58.7207 - val_mae: 5.5245\n",
      "Epoch 89/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.7741 - mae: 8.4811 - val_loss: 54.1577 - val_mae: 5.2251\n",
      "Epoch 90/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.7779 - mae: 8.3044 - val_loss: 64.1121 - val_mae: 5.8768\n",
      "Epoch 91/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.9648 - mae: 8.3502 - val_loss: 56.5749 - val_mae: 5.3725\n",
      "Epoch 92/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.5668 - mae: 8.3324 - val_loss: 59.7841 - val_mae: 5.4962\n",
      "Epoch 93/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.8138 - mae: 8.2551 - val_loss: 59.3092 - val_mae: 5.5490\n",
      "Epoch 94/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107.1479 - mae: 7.9098 - val_loss: 58.9735 - val_mae: 5.5319\n",
      "Epoch 95/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 120.0473 - mae: 8.3550 - val_loss: 61.6668 - val_mae: 5.5882\n",
      "Epoch 96/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.4922 - mae: 8.1985 - val_loss: 58.8432 - val_mae: 5.7185\n",
      "Epoch 97/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.3056 - mae: 8.4682 - val_loss: 56.3823 - val_mae: 5.4323\n",
      "Epoch 98/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.4287 - mae: 8.2024 - val_loss: 60.0735 - val_mae: 5.5756\n",
      "Epoch 99/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.7339 - mae: 8.2618 - val_loss: 58.4943 - val_mae: 5.4970\n",
      "Epoch 100/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.6313 - mae: 8.1262 - val_loss: 55.9297 - val_mae: 5.3222\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62.7124 - mae: 5.4387\n",
      "Patience 40: Validation MAE: 5.23\n",
      "Patience 40: Validation Loss: 54.16\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 630.7388 - mae: 17.8002 - val_loss: 143.7200 - val_mae: 9.2908\n",
      "Epoch 2/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 281.0204 - mae: 13.1653 - val_loss: 127.8571 - val_mae: 8.3511\n",
      "Epoch 3/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 248.1278 - mae: 12.3971 - val_loss: 124.0909 - val_mae: 8.0879\n",
      "Epoch 4/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 229.9468 - mae: 11.8170 - val_loss: 109.9909 - val_mae: 7.5679\n",
      "Epoch 5/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.9058 - mae: 11.3058 - val_loss: 89.3077 - val_mae: 6.8434\n",
      "Epoch 6/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 196.8233 - mae: 10.9700 - val_loss: 78.1728 - val_mae: 6.6956\n",
      "Epoch 7/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 193.9292 - mae: 10.7429 - val_loss: 72.3535 - val_mae: 6.5481\n",
      "Epoch 8/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 196.9763 - mae: 10.8567 - val_loss: 66.2839 - val_mae: 6.0491\n",
      "Epoch 9/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 199.4571 - mae: 10.8318 - val_loss: 68.1499 - val_mae: 5.9985\n",
      "Epoch 10/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 191.8853 - mae: 10.8427 - val_loss: 69.0267 - val_mae: 6.0627\n",
      "Epoch 11/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176.6497 - mae: 10.4452 - val_loss: 67.9623 - val_mae: 6.0833\n",
      "Epoch 12/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174.1974 - mae: 10.1610 - val_loss: 69.5384 - val_mae: 6.0212\n",
      "Epoch 13/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172.4814 - mae: 10.1516 - val_loss: 130.7896 - val_mae: 9.2495\n",
      "Epoch 14/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 176.0385 - mae: 10.3485 - val_loss: 64.8629 - val_mae: 6.0616\n",
      "Epoch 15/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 169.1282 - mae: 9.9873 - val_loss: 62.7481 - val_mae: 5.9478\n",
      "Epoch 16/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 157.0222 - mae: 9.6502 - val_loss: 68.1122 - val_mae: 6.0205\n",
      "Epoch 17/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 150.7299 - mae: 9.4815 - val_loss: 67.1992 - val_mae: 5.9923\n",
      "Epoch 18/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 161.1586 - mae: 9.8419 - val_loss: 66.4177 - val_mae: 6.1429\n",
      "Epoch 19/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 164.6207 - mae: 9.8977 - val_loss: 67.9611 - val_mae: 5.9988\n",
      "Epoch 20/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 162.3443 - mae: 9.6574 - val_loss: 65.1354 - val_mae: 5.8596\n",
      "Epoch 21/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.2176 - mae: 9.5964 - val_loss: 97.3260 - val_mae: 7.4008\n",
      "Epoch 22/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 160.0487 - mae: 9.8029 - val_loss: 70.0739 - val_mae: 6.0643\n",
      "Epoch 23/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 156.3548 - mae: 9.7071 - val_loss: 62.5877 - val_mae: 5.8755\n",
      "Epoch 24/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.6189 - mae: 9.6434 - val_loss: 70.6035 - val_mae: 6.1322\n",
      "Epoch 25/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.4006 - mae: 9.4796 - val_loss: 75.3432 - val_mae: 6.5037\n",
      "Epoch 26/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.2631 - mae: 9.3122 - val_loss: 111.1644 - val_mae: 8.3563\n",
      "Epoch 27/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 154.6579 - mae: 9.5409 - val_loss: 58.9904 - val_mae: 5.6117\n",
      "Epoch 28/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.2792 - mae: 9.5286 - val_loss: 67.2656 - val_mae: 6.0991\n",
      "Epoch 29/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142.2649 - mae: 9.2350 - val_loss: 71.8341 - val_mae: 6.2672\n",
      "Epoch 30/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 148.4015 - mae: 9.3753 - val_loss: 59.3663 - val_mae: 5.5730\n",
      "Epoch 31/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145.7506 - mae: 9.2348 - val_loss: 62.6991 - val_mae: 5.9498\n",
      "Epoch 32/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.9528 - mae: 9.4598 - val_loss: 58.9080 - val_mae: 5.6731\n",
      "Epoch 33/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 151.6307 - mae: 9.3716 - val_loss: 57.1941 - val_mae: 5.4292\n",
      "Epoch 34/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.2907 - mae: 9.1431 - val_loss: 65.0190 - val_mae: 5.7997\n",
      "Epoch 35/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.3199 - mae: 9.0271 - val_loss: 67.0294 - val_mae: 5.9812\n",
      "Epoch 36/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.2598 - mae: 9.4416 - val_loss: 58.5085 - val_mae: 5.5130\n",
      "Epoch 37/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153.6584 - mae: 9.5776 - val_loss: 81.9457 - val_mae: 6.7205\n",
      "Epoch 38/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.3443 - mae: 9.0282 - val_loss: 86.4619 - val_mae: 7.2092\n",
      "Epoch 39/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145.9151 - mae: 9.2946 - val_loss: 61.7346 - val_mae: 5.7688\n",
      "Epoch 40/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.9406 - mae: 9.1536 - val_loss: 66.9649 - val_mae: 5.9892\n",
      "Epoch 41/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.7370 - mae: 9.1797 - val_loss: 69.5738 - val_mae: 6.0206\n",
      "Epoch 42/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.4585 - mae: 9.4935 - val_loss: 96.1302 - val_mae: 7.5807\n",
      "Epoch 43/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.4405 - mae: 9.1315 - val_loss: 59.9206 - val_mae: 5.5849\n",
      "Epoch 44/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.0927 - mae: 8.9444 - val_loss: 60.3525 - val_mae: 5.7479\n",
      "Epoch 45/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.7450 - mae: 9.0762 - val_loss: 60.4272 - val_mae: 5.7259\n",
      "Epoch 46/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 140.7690 - mae: 9.1584 - val_loss: 61.5920 - val_mae: 5.6531\n",
      "Epoch 47/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 137.4730 - mae: 9.0014 - val_loss: 65.6458 - val_mae: 5.8994\n",
      "Epoch 48/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.6606 - mae: 8.9645 - val_loss: 59.6072 - val_mae: 5.5825\n",
      "Epoch 49/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.3509 - mae: 9.1643 - val_loss: 65.0614 - val_mae: 6.1546\n",
      "Epoch 50/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 142.5169 - mae: 9.2083 - val_loss: 58.1769 - val_mae: 5.4678\n",
      "Epoch 51/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.3745 - mae: 9.1239 - val_loss: 55.0849 - val_mae: 5.3117\n",
      "Epoch 52/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.4652 - mae: 9.2123 - val_loss: 56.6505 - val_mae: 5.3783\n",
      "Epoch 53/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.4295 - mae: 8.7528 - val_loss: 57.5633 - val_mae: 5.5126\n",
      "Epoch 54/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 136.5325 - mae: 8.9064 - val_loss: 57.3582 - val_mae: 5.4651\n",
      "Epoch 55/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.3135 - mae: 8.7960 - val_loss: 60.0535 - val_mae: 5.6781\n",
      "Epoch 56/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.4153 - mae: 8.9357 - val_loss: 57.7385 - val_mae: 5.4905\n",
      "Epoch 57/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.2249 - mae: 8.7311 - val_loss: 67.8770 - val_mae: 6.0678\n",
      "Epoch 58/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.6147 - mae: 8.9725 - val_loss: 95.1095 - val_mae: 7.5329\n",
      "Epoch 59/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.9664 - mae: 9.2398 - val_loss: 63.4011 - val_mae: 5.7169\n",
      "Epoch 60/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.5907 - mae: 8.7622 - val_loss: 60.5964 - val_mae: 5.7947\n",
      "Epoch 61/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.3283 - mae: 8.5673 - val_loss: 60.6728 - val_mae: 5.8015\n",
      "Epoch 62/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 128.1616 - mae: 8.7179 - val_loss: 68.4286 - val_mae: 6.0317\n",
      "Epoch 63/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.3410 - mae: 9.0028 - val_loss: 70.9534 - val_mae: 6.1157\n",
      "Epoch 64/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.1713 - mae: 8.7889 - val_loss: 70.5036 - val_mae: 6.0813\n",
      "Epoch 65/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.2167 - mae: 9.0640 - val_loss: 59.8174 - val_mae: 5.6436\n",
      "Epoch 66/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.6589 - mae: 8.8071 - val_loss: 55.2407 - val_mae: 5.3385\n",
      "Epoch 67/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.4206 - mae: 8.7190 - val_loss: 64.0954 - val_mae: 5.9002\n",
      "Epoch 68/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.6048 - mae: 8.8415 - val_loss: 58.5040 - val_mae: 5.5193\n",
      "Epoch 69/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.6254 - mae: 8.6947 - val_loss: 67.0427 - val_mae: 5.9613\n",
      "Epoch 70/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.1614 - mae: 8.7291 - val_loss: 54.4922 - val_mae: 5.2752\n",
      "Epoch 71/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.6849 - mae: 8.5068 - val_loss: 56.2708 - val_mae: 5.3920\n",
      "Epoch 72/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.5545 - mae: 8.6993 - val_loss: 77.5976 - val_mae: 6.5382\n",
      "Epoch 73/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.6926 - mae: 8.9260 - val_loss: 58.0326 - val_mae: 5.5247\n",
      "Epoch 74/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 122.9664 - mae: 8.4640 - val_loss: 58.6674 - val_mae: 5.6391\n",
      "Epoch 75/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.5367 - mae: 8.6803 - val_loss: 61.8185 - val_mae: 5.7431\n",
      "Epoch 76/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.3757 - mae: 8.4210 - val_loss: 55.9843 - val_mae: 5.3816\n",
      "Epoch 77/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.5410 - mae: 8.5471 - val_loss: 55.7049 - val_mae: 5.3454\n",
      "Epoch 78/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.4104 - mae: 8.5735 - val_loss: 62.3508 - val_mae: 5.7511\n",
      "Epoch 79/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.2995 - mae: 8.5446 - val_loss: 57.0924 - val_mae: 5.4842\n",
      "Epoch 80/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.7564 - mae: 8.5248 - val_loss: 56.1360 - val_mae: 5.4419\n",
      "Epoch 81/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.4602 - mae: 8.8410 - val_loss: 60.7389 - val_mae: 5.6541\n",
      "Epoch 82/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 126.7424 - mae: 8.5446 - val_loss: 59.0744 - val_mae: 5.5107\n",
      "Epoch 83/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.4618 - mae: 8.3929 - val_loss: 57.3755 - val_mae: 5.5193\n",
      "Epoch 84/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.8057 - mae: 8.6185 - val_loss: 61.1941 - val_mae: 5.6889\n",
      "Epoch 85/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127.0296 - mae: 8.6132 - val_loss: 54.6734 - val_mae: 5.3297\n",
      "Epoch 86/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.8756 - mae: 8.4881 - val_loss: 56.8971 - val_mae: 5.4856\n",
      "Epoch 87/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.6500 - mae: 8.5199 - val_loss: 55.1981 - val_mae: 5.3786\n",
      "Epoch 88/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.4157 - mae: 8.4809 - val_loss: 54.3697 - val_mae: 5.2682\n",
      "Epoch 89/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.0881 - mae: 8.7528 - val_loss: 58.3172 - val_mae: 5.6487\n",
      "Epoch 90/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.5942 - mae: 8.5312 - val_loss: 59.8813 - val_mae: 5.6055\n",
      "Epoch 91/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.8744 - mae: 8.4805 - val_loss: 66.7201 - val_mae: 5.9701\n",
      "Epoch 92/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 130.2752 - mae: 8.6394 - val_loss: 54.9927 - val_mae: 5.3847\n",
      "Epoch 93/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.7867 - mae: 8.7569 - val_loss: 61.2501 - val_mae: 5.6040\n",
      "Epoch 94/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.7383 - mae: 8.5953 - val_loss: 55.3881 - val_mae: 5.3696\n",
      "Epoch 95/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.7591 - mae: 8.4784 - val_loss: 56.6171 - val_mae: 5.5138\n",
      "Epoch 96/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.0110 - mae: 8.6595 - val_loss: 54.9680 - val_mae: 5.3229\n",
      "Epoch 97/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123.0802 - mae: 8.3859 - val_loss: 55.7597 - val_mae: 5.3445\n",
      "Epoch 98/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.0610 - mae: 8.4424 - val_loss: 55.7432 - val_mae: 5.4127\n",
      "Epoch 99/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.1912 - mae: 8.3770 - val_loss: 60.7578 - val_mae: 5.5704\n",
      "Epoch 100/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.7193 - mae: 8.6847 - val_loss: 60.1932 - val_mae: 5.5413\n",
      "Patience 30: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62.2745 - mae: 5.4784\n",
      "Patience 30: Validation MAE: 5.27\n",
      "Patience 30: Validation Loss: 54.37\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 769.1782 - mae: 18.8385 - val_loss: 144.5758 - val_mae: 9.8710\n",
      "Epoch 2/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 266.2803 - mae: 12.7967 - val_loss: 127.5178 - val_mae: 8.3105\n",
      "Epoch 3/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 225.0550 - mae: 11.7085 - val_loss: 105.1156 - val_mae: 7.4751\n",
      "Epoch 4/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 193.5658 - mae: 10.8330 - val_loss: 76.4329 - val_mae: 6.7838\n",
      "Epoch 5/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 181.9833 - mae: 10.4013 - val_loss: 68.5811 - val_mae: 6.2545\n",
      "Epoch 6/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 164.1637 - mae: 9.8081 - val_loss: 65.9780 - val_mae: 5.8914\n",
      "Epoch 7/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167.8354 - mae: 10.0515 - val_loss: 66.0494 - val_mae: 5.8704\n",
      "Epoch 8/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 151.5596 - mae: 9.4708 - val_loss: 74.0799 - val_mae: 6.2673\n",
      "Epoch 9/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 154.9129 - mae: 9.5101 - val_loss: 62.0283 - val_mae: 5.6410\n",
      "Epoch 10/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 155.1616 - mae: 9.5851 - val_loss: 61.7731 - val_mae: 5.6849\n",
      "Epoch 11/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 149.6387 - mae: 9.3499 - val_loss: 62.2404 - val_mae: 5.8314\n",
      "Epoch 12/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 151.2563 - mae: 9.4782 - val_loss: 78.1770 - val_mae: 6.4833\n",
      "Epoch 13/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.9707 - mae: 9.4593 - val_loss: 76.7530 - val_mae: 6.4230\n",
      "Epoch 14/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 155.5539 - mae: 9.5672 - val_loss: 66.4772 - val_mae: 6.1600\n",
      "Epoch 15/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 148.0286 - mae: 9.2526 - val_loss: 89.1390 - val_mae: 7.0980\n",
      "Epoch 16/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.7304 - mae: 9.1058 - val_loss: 71.0473 - val_mae: 6.1379\n",
      "Epoch 17/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 147.8052 - mae: 9.3684 - val_loss: 59.7774 - val_mae: 5.5491\n",
      "Epoch 18/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.3605 - mae: 9.0460 - val_loss: 77.0841 - val_mae: 6.5403\n",
      "Epoch 19/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 139.6881 - mae: 9.0364 - val_loss: 79.1502 - val_mae: 6.5735\n",
      "Epoch 20/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.2903 - mae: 9.3112 - val_loss: 69.7405 - val_mae: 6.0384\n",
      "Epoch 21/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.0065 - mae: 9.2903 - val_loss: 62.2058 - val_mae: 5.6667\n",
      "Epoch 22/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 142.0748 - mae: 9.0694 - val_loss: 62.7680 - val_mae: 5.9260\n",
      "Epoch 23/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.1102 - mae: 8.9660 - val_loss: 63.6501 - val_mae: 5.9867\n",
      "Epoch 24/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 145.2288 - mae: 9.2006 - val_loss: 58.5002 - val_mae: 5.5128\n",
      "Epoch 25/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 146.7538 - mae: 9.1967 - val_loss: 67.1162 - val_mae: 5.8962\n",
      "Epoch 26/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.2771 - mae: 9.1821 - val_loss: 64.2037 - val_mae: 5.7489\n",
      "Epoch 27/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.5683 - mae: 9.1555 - val_loss: 60.5394 - val_mae: 5.7415\n",
      "Epoch 28/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.6761 - mae: 9.0118 - val_loss: 66.8045 - val_mae: 5.9867\n",
      "Epoch 29/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.3516 - mae: 9.0686 - val_loss: 59.4437 - val_mae: 5.6422\n",
      "Epoch 30/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.0199 - mae: 9.0421 - val_loss: 61.6402 - val_mae: 5.6358\n",
      "Epoch 31/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 135.3226 - mae: 9.0501 - val_loss: 68.3990 - val_mae: 5.9720\n",
      "Epoch 32/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.4226 - mae: 9.0668 - val_loss: 77.1656 - val_mae: 6.4830\n",
      "Epoch 33/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.2378 - mae: 8.9631 - val_loss: 58.1563 - val_mae: 5.5437\n",
      "Epoch 34/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.3232 - mae: 9.0078 - val_loss: 57.2335 - val_mae: 5.4022\n",
      "Epoch 35/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.2850 - mae: 8.9414 - val_loss: 65.0144 - val_mae: 5.7917\n",
      "Epoch 36/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.3459 - mae: 8.9726 - val_loss: 59.7018 - val_mae: 5.5348\n",
      "Epoch 37/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.5724 - mae: 9.1255 - val_loss: 60.9873 - val_mae: 5.8107\n",
      "Epoch 38/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.5387 - mae: 8.7290 - val_loss: 63.4155 - val_mae: 5.9627\n",
      "Epoch 39/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.5835 - mae: 9.0514 - val_loss: 63.1949 - val_mae: 5.7056\n",
      "Epoch 40/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.5817 - mae: 8.6775 - val_loss: 65.6606 - val_mae: 5.8458\n",
      "Epoch 41/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.2874 - mae: 9.2711 - val_loss: 61.8668 - val_mae: 5.8145\n",
      "Epoch 42/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.7738 - mae: 9.0159 - val_loss: 61.4948 - val_mae: 5.8666\n",
      "Epoch 43/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.6124 - mae: 8.8472 - val_loss: 62.7294 - val_mae: 5.6611\n",
      "Epoch 44/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.6575 - mae: 8.4790 - val_loss: 61.4898 - val_mae: 5.5844\n",
      "Epoch 45/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.3018 - mae: 8.9852 - val_loss: 73.5569 - val_mae: 6.3456\n",
      "Epoch 46/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.6740 - mae: 8.9544 - val_loss: 57.9422 - val_mae: 5.5064\n",
      "Epoch 47/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.8548 - mae: 8.9473 - val_loss: 69.4664 - val_mae: 6.3482\n",
      "Epoch 48/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.0364 - mae: 8.9657 - val_loss: 56.4008 - val_mae: 5.3355\n",
      "Epoch 49/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134.6319 - mae: 8.9914 - val_loss: 68.7100 - val_mae: 5.9352\n",
      "Epoch 50/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.6996 - mae: 8.9401 - val_loss: 60.7910 - val_mae: 5.6232\n",
      "Epoch 51/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 132.4549 - mae: 8.8596 - val_loss: 57.2284 - val_mae: 5.4242\n",
      "Epoch 52/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.9609 - mae: 8.8647 - val_loss: 60.3099 - val_mae: 5.7682\n",
      "Epoch 53/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.8395 - mae: 9.0975 - val_loss: 62.6490 - val_mae: 5.6714\n",
      "Epoch 54/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.5488 - mae: 8.8141 - val_loss: 82.9374 - val_mae: 6.8178\n",
      "Epoch 55/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.8562 - mae: 8.8508 - val_loss: 64.1966 - val_mae: 5.7421\n",
      "Epoch 56/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.3332 - mae: 8.8263 - val_loss: 58.1532 - val_mae: 5.5498\n",
      "Epoch 57/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.6146 - mae: 8.8117 - val_loss: 63.6512 - val_mae: 5.7508\n",
      "Epoch 58/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.7042 - mae: 8.6153 - val_loss: 59.9790 - val_mae: 5.5993\n",
      "Epoch 59/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.5181 - mae: 8.6643 - val_loss: 68.2553 - val_mae: 5.9561\n",
      "Epoch 60/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.0107 - mae: 8.7330 - val_loss: 61.6007 - val_mae: 5.8725\n",
      "Epoch 61/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 139.0484 - mae: 9.0231 - val_loss: 55.7201 - val_mae: 5.3463\n",
      "Epoch 62/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.8172 - mae: 8.7035 - val_loss: 73.6331 - val_mae: 6.2095\n",
      "Epoch 63/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 125.3165 - mae: 8.6469 - val_loss: 56.0243 - val_mae: 5.3547\n",
      "Epoch 64/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.2923 - mae: 8.7341 - val_loss: 55.9110 - val_mae: 5.3830\n",
      "Epoch 65/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.0955 - mae: 9.0255 - val_loss: 57.9657 - val_mae: 5.5389\n",
      "Epoch 66/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.9929 - mae: 8.7458 - val_loss: 62.6422 - val_mae: 5.6962\n",
      "Epoch 67/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.7407 - mae: 8.4497 - val_loss: 57.0658 - val_mae: 5.4615\n",
      "Epoch 68/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.3044 - mae: 8.7585 - val_loss: 56.3457 - val_mae: 5.3539\n",
      "Epoch 69/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.8478 - mae: 8.6303 - val_loss: 66.1646 - val_mae: 5.8946\n",
      "Epoch 70/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 123.7701 - mae: 8.4639 - val_loss: 54.5979 - val_mae: 5.2554\n",
      "Epoch 71/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.0554 - mae: 8.6551 - val_loss: 57.2259 - val_mae: 5.4363\n",
      "Epoch 72/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.4397 - mae: 8.5297 - val_loss: 62.5452 - val_mae: 5.6565\n",
      "Epoch 73/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.7531 - mae: 8.3678 - val_loss: 63.1012 - val_mae: 5.7348\n",
      "Epoch 74/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.6322 - mae: 8.6081 - val_loss: 60.1783 - val_mae: 5.5171\n",
      "Epoch 75/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.6678 - mae: 8.5238 - val_loss: 58.8382 - val_mae: 5.4369\n",
      "Epoch 76/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.5084 - mae: 8.3434 - val_loss: 57.7227 - val_mae: 5.4244\n",
      "Epoch 77/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.9383 - mae: 8.3575 - val_loss: 57.6231 - val_mae: 5.4392\n",
      "Epoch 78/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 123.1841 - mae: 8.4181 - val_loss: 63.1830 - val_mae: 5.7677\n",
      "Epoch 79/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.7183 - mae: 8.4101 - val_loss: 58.0926 - val_mae: 5.4940\n",
      "Epoch 80/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.0164 - mae: 8.3353 - val_loss: 55.9268 - val_mae: 5.3146\n",
      "Epoch 81/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.8316 - mae: 8.6668 - val_loss: 58.0749 - val_mae: 5.5312\n",
      "Epoch 82/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.0874 - mae: 8.5591 - val_loss: 57.8947 - val_mae: 5.4021\n",
      "Epoch 83/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.6816 - mae: 8.5749 - val_loss: 62.0297 - val_mae: 5.6390\n",
      "Epoch 84/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.5935 - mae: 8.1836 - val_loss: 75.7032 - val_mae: 6.4659\n",
      "Epoch 85/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.5147 - mae: 8.5710 - val_loss: 55.2759 - val_mae: 5.3317\n",
      "Epoch 86/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.4132 - mae: 8.3575 - val_loss: 56.8066 - val_mae: 5.3092\n",
      "Epoch 87/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.0916 - mae: 8.3539 - val_loss: 57.4494 - val_mae: 5.3754\n",
      "Epoch 88/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.8074 - mae: 8.3575 - val_loss: 54.4647 - val_mae: 5.2260\n",
      "Epoch 89/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.4476 - mae: 8.3235 - val_loss: 64.8784 - val_mae: 5.7489\n",
      "Epoch 90/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.0514 - mae: 8.4928 - val_loss: 56.1587 - val_mae: 5.4296\n",
      "Epoch 91/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.7651 - mae: 8.5583 - val_loss: 72.5153 - val_mae: 6.2862\n",
      "Epoch 92/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.4895 - mae: 8.6892 - val_loss: 59.3752 - val_mae: 5.6400\n",
      "Epoch 93/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.3397 - mae: 8.4474 - val_loss: 63.3071 - val_mae: 5.6837\n",
      "Epoch 94/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.6766 - mae: 8.2506 - val_loss: 58.7817 - val_mae: 5.6744\n",
      "Epoch 95/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.7535 - mae: 8.2630 - val_loss: 62.2954 - val_mae: 5.7231\n",
      "Epoch 96/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 119.9126 - mae: 8.3315 - val_loss: 54.2705 - val_mae: 5.3276\n",
      "Epoch 97/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.7891 - mae: 8.3542 - val_loss: 60.0095 - val_mae: 5.5509\n",
      "Epoch 98/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.5416 - mae: 8.1971 - val_loss: 68.3245 - val_mae: 5.9336\n",
      "Epoch 99/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 130.1077 - mae: 8.6682 - val_loss: 53.3733 - val_mae: 5.1637\n",
      "Epoch 100/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.8551 - mae: 8.2530 - val_loss: 54.2711 - val_mae: 5.2109\n",
      "Patience 20: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.8163 - mae: 5.3280\n",
      "Patience 20: Validation MAE: 5.16\n",
      "Patience 20: Validation Loss: 53.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1573.1506 - mae: 25.3937 - val_loss: 172.6289 - val_mae: 10.0357\n",
      "Epoch 2/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 287.5920 - mae: 13.4688 - val_loss: 151.5732 - val_mae: 9.4762\n",
      "Epoch 3/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 250.3113 - mae: 12.5292 - val_loss: 153.1334 - val_mae: 8.9572\n",
      "Epoch 4/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 248.7108 - mae: 12.3773 - val_loss: 114.0399 - val_mae: 7.9087\n",
      "Epoch 5/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 217.8877 - mae: 11.4751 - val_loss: 97.6278 - val_mae: 7.8368\n",
      "Epoch 6/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 206.3486 - mae: 11.1842 - val_loss: 85.8041 - val_mae: 7.2782\n",
      "Epoch 7/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.2691 - mae: 10.9295 - val_loss: 76.8175 - val_mae: 6.4317\n",
      "Epoch 8/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 183.7799 - mae: 10.5861 - val_loss: 75.5870 - val_mae: 6.3407\n",
      "Epoch 9/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 191.1217 - mae: 10.6722 - val_loss: 82.8959 - val_mae: 7.2799\n",
      "Epoch 10/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 180.2698 - mae: 10.4265 - val_loss: 161.6903 - val_mae: 10.4515\n",
      "Epoch 11/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 186.4132 - mae: 10.5236 - val_loss: 81.5402 - val_mae: 6.6935\n",
      "Epoch 12/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 166.7802 - mae: 9.8936 - val_loss: 63.8696 - val_mae: 5.9571\n",
      "Epoch 13/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 178.8198 - mae: 10.3017 - val_loss: 65.2897 - val_mae: 5.8319\n",
      "Epoch 14/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 165.8075 - mae: 9.8279 - val_loss: 64.6054 - val_mae: 5.9837\n",
      "Epoch 15/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 161.3606 - mae: 9.8325 - val_loss: 65.3866 - val_mae: 5.7876\n",
      "Epoch 16/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 167.7112 - mae: 9.8752 - val_loss: 67.3855 - val_mae: 5.8980\n",
      "Epoch 17/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 168.1387 - mae: 9.8789 - val_loss: 71.3558 - val_mae: 6.4329\n",
      "Epoch 18/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 161.3968 - mae: 9.8700 - val_loss: 60.6813 - val_mae: 5.6931\n",
      "Epoch 19/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158.9822 - mae: 9.6861 - val_loss: 60.8005 - val_mae: 5.7815\n",
      "Epoch 20/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 175.3047 - mae: 10.1914 - val_loss: 66.5119 - val_mae: 5.8766\n",
      "Epoch 21/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 160.9491 - mae: 9.7747 - val_loss: 60.2285 - val_mae: 5.6089\n",
      "Epoch 22/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160.6702 - mae: 9.8142 - val_loss: 63.3935 - val_mae: 5.7262\n",
      "Epoch 23/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158.8743 - mae: 9.6571 - val_loss: 59.9667 - val_mae: 5.5867\n",
      "Epoch 24/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 152.1079 - mae: 9.5307 - val_loss: 63.4110 - val_mae: 5.7346\n",
      "Epoch 25/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 157.2982 - mae: 9.6080 - val_loss: 64.6389 - val_mae: 5.8158\n",
      "Epoch 26/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 163.9852 - mae: 9.8827 - val_loss: 61.2009 - val_mae: 5.6657\n",
      "Epoch 27/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.1950 - mae: 9.5531 - val_loss: 59.6217 - val_mae: 5.6443\n",
      "Epoch 28/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 150.8111 - mae: 9.4332 - val_loss: 61.8567 - val_mae: 5.6287\n",
      "Epoch 29/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 154.7075 - mae: 9.6088 - val_loss: 88.0511 - val_mae: 7.0020\n",
      "Epoch 30/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 149.0634 - mae: 9.4450 - val_loss: 63.1463 - val_mae: 5.6929\n",
      "Epoch 31/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 151.6631 - mae: 9.4488 - val_loss: 63.9692 - val_mae: 5.8113\n",
      "Epoch 32/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.3788 - mae: 9.1941 - val_loss: 68.9967 - val_mae: 5.9972\n",
      "Epoch 33/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.5435 - mae: 9.2963 - val_loss: 61.0474 - val_mae: 5.7648\n",
      "Epoch 34/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.4848 - mae: 9.2269 - val_loss: 70.7892 - val_mae: 6.1894\n",
      "Epoch 35/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 155.5086 - mae: 9.4792 - val_loss: 58.1540 - val_mae: 5.4548\n",
      "Epoch 36/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 153.9292 - mae: 9.4757 - val_loss: 78.3128 - val_mae: 6.6692\n",
      "Epoch 37/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.1980 - mae: 9.1565 - val_loss: 89.9102 - val_mae: 7.0886\n",
      "Epoch 38/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.2434 - mae: 9.4825 - val_loss: 65.6360 - val_mae: 6.1134\n",
      "Epoch 39/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.5901 - mae: 9.2528 - val_loss: 61.7101 - val_mae: 5.6747\n",
      "Epoch 40/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.8017 - mae: 9.3494 - val_loss: 60.6837 - val_mae: 5.5742\n",
      "Epoch 41/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.1127 - mae: 9.3829 - val_loss: 61.5268 - val_mae: 5.6517\n",
      "Epoch 42/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.5200 - mae: 9.0591 - val_loss: 61.0556 - val_mae: 5.5949\n",
      "Epoch 43/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.5952 - mae: 9.1481 - val_loss: 63.3390 - val_mae: 5.7478\n",
      "Epoch 44/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.7302 - mae: 9.1238 - val_loss: 57.0100 - val_mae: 5.4832\n",
      "Epoch 45/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.1506 - mae: 9.1864 - val_loss: 60.3502 - val_mae: 5.7537\n",
      "Epoch 46/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 149.2250 - mae: 9.3942 - val_loss: 58.4406 - val_mae: 5.5235\n",
      "Epoch 47/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.2685 - mae: 9.1797 - val_loss: 106.0534 - val_mae: 7.9036\n",
      "Epoch 48/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.7236 - mae: 9.4564 - val_loss: 70.1378 - val_mae: 6.1653\n",
      "Epoch 49/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.7255 - mae: 9.1943 - val_loss: 60.3271 - val_mae: 5.5712\n",
      "Epoch 50/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148.2241 - mae: 9.2739 - val_loss: 79.5222 - val_mae: 6.5904\n",
      "Epoch 51/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.9739 - mae: 8.9430 - val_loss: 63.6496 - val_mae: 5.8764\n",
      "Epoch 52/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 144.1250 - mae: 9.1786 - val_loss: 57.6785 - val_mae: 5.4860\n",
      "Epoch 53/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.5347 - mae: 8.8595 - val_loss: 55.9461 - val_mae: 5.4039\n",
      "Epoch 54/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.1328 - mae: 9.2263 - val_loss: 67.8767 - val_mae: 6.0288\n",
      "Epoch 55/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.4498 - mae: 9.1410 - val_loss: 59.7378 - val_mae: 5.5669\n",
      "Epoch 56/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.7416 - mae: 8.9757 - val_loss: 66.3699 - val_mae: 5.9546\n",
      "Epoch 57/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.9498 - mae: 8.9609 - val_loss: 56.7818 - val_mae: 5.4197\n",
      "Epoch 58/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.6736 - mae: 9.0294 - val_loss: 65.0765 - val_mae: 5.8452\n",
      "Epoch 59/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.5998 - mae: 9.1708 - val_loss: 55.8324 - val_mae: 5.3765\n",
      "Epoch 60/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 147.1918 - mae: 9.2242 - val_loss: 60.5857 - val_mae: 5.6267\n",
      "Epoch 61/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.6608 - mae: 8.8771 - val_loss: 69.9547 - val_mae: 6.0530\n",
      "Epoch 62/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.9515 - mae: 8.9663 - val_loss: 88.8715 - val_mae: 7.2415\n",
      "Epoch 63/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.8052 - mae: 8.9610 - val_loss: 67.0355 - val_mae: 5.9762\n",
      "Epoch 64/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.0814 - mae: 9.0392 - val_loss: 56.9310 - val_mae: 5.3999\n",
      "Epoch 65/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.7857 - mae: 9.1003 - val_loss: 55.6302 - val_mae: 5.3303\n",
      "Epoch 66/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.8852 - mae: 8.9725 - val_loss: 56.9000 - val_mae: 5.4551\n",
      "Epoch 67/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.8677 - mae: 8.8108 - val_loss: 68.9732 - val_mae: 6.0787\n",
      "Epoch 68/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.7870 - mae: 8.9247 - val_loss: 66.3576 - val_mae: 6.1807\n",
      "Epoch 69/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 141.5219 - mae: 9.0206 - val_loss: 55.4956 - val_mae: 5.3511\n",
      "Epoch 70/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 137.9328 - mae: 8.8888 - val_loss: 63.3172 - val_mae: 5.7398\n",
      "Epoch 71/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 132.9132 - mae: 8.8849 - val_loss: 55.5657 - val_mae: 5.3184\n",
      "Epoch 72/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.6527 - mae: 8.9723 - val_loss: 59.6626 - val_mae: 5.5337\n",
      "Epoch 73/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 139.5411 - mae: 8.9807 - val_loss: 70.7085 - val_mae: 6.1558\n",
      "Epoch 74/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 136.0156 - mae: 8.9366 - val_loss: 58.0165 - val_mae: 5.5568\n",
      "Epoch 75/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.4413 - mae: 8.8734 - val_loss: 62.6283 - val_mae: 5.7107\n",
      "Epoch 76/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.3072 - mae: 8.7617 - val_loss: 59.4466 - val_mae: 5.5442\n",
      "Epoch 77/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 132.8471 - mae: 8.8330 - val_loss: 63.0466 - val_mae: 5.7719\n",
      "Epoch 78/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.1823 - mae: 8.8947 - val_loss: 55.7039 - val_mae: 5.3427\n",
      "Epoch 79/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.2379 - mae: 8.7866 - val_loss: 60.9988 - val_mae: 5.6432\n",
      "Patience 10: Early stopping occurred at epoch 78\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63.6359 - mae: 5.5539 \n",
      "Patience 10: Validation MAE: 5.35\n",
      "Patience 10: Validation Loss: 55.50\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 54.1577, MAE = 5.2251, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 54.3697, MAE = 5.2682, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 20: Loss = 53.3733, MAE = 5.1637, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 10: Loss = 55.4956, MAE = 5.3511, Early Stopping Occurred: True, Early Stopping Epoch: 78\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "bresults100_1 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    dbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    dbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'best_model_{patience}.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = dbp_model.fit(\n",
    "        X_train_combined, DBP_Y_train_combined,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_combined, DBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = dbp_model.evaluate(X_test_combined, DBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    bresults100_1.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    # 학습 및 검증 손실 그래프 시각화\n",
    "    # plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.title(f'Patience = {patience}')\n",
    "    # plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in bresults100_1:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 960.2516 - mae: 19.0718 - val_loss: 131.9015 - val_mae: 8.5437\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 211.8270 - mae: 11.3395 - val_loss: 110.3355 - val_mae: 7.5056\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 189.5093 - mae: 10.6594 - val_loss: 76.6517 - val_mae: 6.3525\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 165.0126 - mae: 9.9425 - val_loss: 126.9579 - val_mae: 8.8862\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152.3813 - mae: 9.5054 - val_loss: 99.3189 - val_mae: 7.6798\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 150.9297 - mae: 9.4315 - val_loss: 66.3227 - val_mae: 5.8862\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151.0085 - mae: 9.5190 - val_loss: 64.6298 - val_mae: 5.8486\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158.3296 - mae: 9.7187 - val_loss: 68.5537 - val_mae: 5.9783\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.2134 - mae: 9.1511 - val_loss: 68.4593 - val_mae: 5.9234\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139.7578 - mae: 9.1228 - val_loss: 91.1373 - val_mae: 7.1498\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140.0645 - mae: 9.0391 - val_loss: 62.5292 - val_mae: 5.8075\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.8645 - mae: 8.9157 - val_loss: 101.5555 - val_mae: 7.7567\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140.8468 - mae: 9.0771 - val_loss: 65.1461 - val_mae: 5.8433\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.3118 - mae: 9.0230 - val_loss: 105.9322 - val_mae: 7.8101\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.8621 - mae: 9.3066 - val_loss: 85.8665 - val_mae: 6.8052\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135.3251 - mae: 8.9634 - val_loss: 63.1166 - val_mae: 5.6660\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.7987 - mae: 8.8851 - val_loss: 65.1254 - val_mae: 6.0567\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.2250 - mae: 8.9477 - val_loss: 75.3452 - val_mae: 6.3209\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.3940 - mae: 8.9598 - val_loss: 68.4849 - val_mae: 6.0232\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.1621 - mae: 8.9036 - val_loss: 71.3433 - val_mae: 6.1573\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.7066 - mae: 8.9495 - val_loss: 66.8479 - val_mae: 5.9416\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.1252 - mae: 8.7618 - val_loss: 65.7799 - val_mae: 5.7624\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139.8662 - mae: 9.0470 - val_loss: 68.1217 - val_mae: 5.9633\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.7388 - mae: 8.8839 - val_loss: 62.5270 - val_mae: 5.6363\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.6126 - mae: 8.7243 - val_loss: 60.6949 - val_mae: 5.7370\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.9647 - mae: 8.6426 - val_loss: 61.3112 - val_mae: 5.5741\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.8930 - mae: 8.6248 - val_loss: 61.7747 - val_mae: 5.6227\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.2444 - mae: 8.6170 - val_loss: 65.9795 - val_mae: 6.1343\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.2267 - mae: 8.7270 - val_loss: 64.3319 - val_mae: 5.7602\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.0102 - mae: 8.7668 - val_loss: 77.9661 - val_mae: 6.7721\n",
      "Epoch 31/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.0795 - mae: 8.6354 - val_loss: 58.3930 - val_mae: 5.4677\n",
      "Epoch 32/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.6979 - mae: 8.7618 - val_loss: 62.2285 - val_mae: 5.6103\n",
      "Epoch 33/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.1599 - mae: 8.2229 - val_loss: 61.9486 - val_mae: 5.6420\n",
      "Epoch 34/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.4716 - mae: 8.5497 - val_loss: 80.6047 - val_mae: 7.0377\n",
      "Epoch 35/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.1491 - mae: 8.5634 - val_loss: 60.2588 - val_mae: 5.5646\n",
      "Epoch 36/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.8623 - mae: 8.3674 - val_loss: 63.8191 - val_mae: 5.6829\n",
      "Epoch 37/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.5617 - mae: 8.6145 - val_loss: 60.9696 - val_mae: 5.5773\n",
      "Epoch 38/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.6153 - mae: 8.5676 - val_loss: 63.3174 - val_mae: 5.9476\n",
      "Epoch 39/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.8540 - mae: 8.5349 - val_loss: 59.4330 - val_mae: 5.5679\n",
      "Epoch 40/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.6135 - mae: 8.5128 - val_loss: 61.5589 - val_mae: 5.6026\n",
      "Epoch 41/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.3957 - mae: 8.3879 - val_loss: 66.3893 - val_mae: 6.1056\n",
      "Epoch 42/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121.8256 - mae: 8.5113 - val_loss: 60.9779 - val_mae: 5.5559\n",
      "Epoch 43/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.2485 - mae: 8.4915 - val_loss: 78.8371 - val_mae: 6.4671\n",
      "Epoch 44/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120.0379 - mae: 8.4031 - val_loss: 57.2612 - val_mae: 5.4276\n",
      "Epoch 45/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.6236 - mae: 8.3249 - val_loss: 65.6368 - val_mae: 5.8199\n",
      "Epoch 46/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118.2929 - mae: 8.2663 - val_loss: 57.2416 - val_mae: 5.4038\n",
      "Epoch 47/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.3174 - mae: 8.3433 - val_loss: 65.4421 - val_mae: 6.1452\n",
      "Epoch 48/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.1309 - mae: 8.6095 - val_loss: 67.4374 - val_mae: 5.9456\n",
      "Epoch 49/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.4334 - mae: 8.2762 - val_loss: 59.1522 - val_mae: 5.4663\n",
      "Epoch 50/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.0926 - mae: 8.2758 - val_loss: 59.8091 - val_mae: 5.5245\n",
      "Epoch 51/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.9821 - mae: 7.9611 - val_loss: 64.9399 - val_mae: 5.7590\n",
      "Epoch 52/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.3825 - mae: 8.1726 - val_loss: 67.9978 - val_mae: 6.3316\n",
      "Epoch 53/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.4860 - mae: 8.2771 - val_loss: 66.4496 - val_mae: 5.8131\n",
      "Epoch 54/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.6711 - mae: 8.3260 - val_loss: 60.2403 - val_mae: 5.6546\n",
      "Epoch 55/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.0280 - mae: 8.0569 - val_loss: 59.5293 - val_mae: 5.6518\n",
      "Epoch 56/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120.4461 - mae: 8.3352 - val_loss: 63.9908 - val_mae: 5.7758\n",
      "Epoch 57/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.8541 - mae: 8.2770 - val_loss: 67.5504 - val_mae: 5.9078\n",
      "Epoch 58/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.5860 - mae: 8.0246 - val_loss: 57.3503 - val_mae: 5.4874\n",
      "Epoch 59/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.5992 - mae: 8.3068 - val_loss: 57.3257 - val_mae: 5.3636\n",
      "Epoch 60/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.1394 - mae: 8.1665 - val_loss: 60.8310 - val_mae: 5.5486\n",
      "Epoch 61/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118.0111 - mae: 8.1653 - val_loss: 69.3553 - val_mae: 6.0073\n",
      "Epoch 62/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.6435 - mae: 8.0562 - val_loss: 63.9957 - val_mae: 5.8146\n",
      "Epoch 63/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.1938 - mae: 8.1663 - val_loss: 62.5131 - val_mae: 5.7000\n",
      "Epoch 64/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.4483 - mae: 8.0095 - val_loss: 60.1702 - val_mae: 5.5891\n",
      "Epoch 65/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.6725 - mae: 8.0752 - val_loss: 60.2781 - val_mae: 5.5314\n",
      "Epoch 66/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.4170 - mae: 8.0390 - val_loss: 55.8862 - val_mae: 5.3123\n",
      "Epoch 67/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.1923 - mae: 7.9346 - val_loss: 63.6515 - val_mae: 5.6507\n",
      "Epoch 68/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.0113 - mae: 8.2286 - val_loss: 54.7421 - val_mae: 5.2842\n",
      "Epoch 69/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.5875 - mae: 8.2029 - val_loss: 58.1796 - val_mae: 5.4146\n",
      "Epoch 70/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.8386 - mae: 7.9108 - val_loss: 60.1253 - val_mae: 5.6843\n",
      "Epoch 71/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.1182 - mae: 8.0642 - val_loss: 55.5095 - val_mae: 5.3219\n",
      "Epoch 72/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.4633 - mae: 8.0529 - val_loss: 56.9353 - val_mae: 5.3868\n",
      "Epoch 73/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.7111 - mae: 8.0711 - val_loss: 65.2027 - val_mae: 5.8406\n",
      "Epoch 74/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.3430 - mae: 7.9358 - val_loss: 61.8777 - val_mae: 5.8105\n",
      "Epoch 75/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.9502 - mae: 7.7846 - val_loss: 55.2413 - val_mae: 5.2535\n",
      "Epoch 76/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.9764 - mae: 8.0304 - val_loss: 56.7019 - val_mae: 5.3801\n",
      "Epoch 77/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121.3815 - mae: 8.2966 - val_loss: 59.3908 - val_mae: 5.4940\n",
      "Epoch 78/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.9143 - mae: 8.0218 - val_loss: 67.1542 - val_mae: 5.9196\n",
      "Epoch 79/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.6051 - mae: 7.8295 - val_loss: 67.0469 - val_mae: 5.8725\n",
      "Epoch 80/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.4227 - mae: 7.9637 - val_loss: 58.4781 - val_mae: 5.5055\n",
      "Epoch 81/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.0112 - mae: 7.8139 - val_loss: 59.7513 - val_mae: 5.5235\n",
      "Epoch 82/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.3558 - mae: 7.8929 - val_loss: 58.4442 - val_mae: 5.6675\n",
      "Epoch 83/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.3602 - mae: 7.9318 - val_loss: 57.0157 - val_mae: 5.3364\n",
      "Epoch 84/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.3649 - mae: 7.9238 - val_loss: 57.7053 - val_mae: 5.4308\n",
      "Epoch 85/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.7605 - mae: 7.9131 - val_loss: 80.7089 - val_mae: 6.8102\n",
      "Epoch 86/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.7103 - mae: 7.8617 - val_loss: 71.8525 - val_mae: 6.2442\n",
      "Epoch 87/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.0292 - mae: 7.7201 - val_loss: 60.0573 - val_mae: 5.5475\n",
      "Epoch 88/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.9066 - mae: 7.9676 - val_loss: 62.3420 - val_mae: 6.0342\n",
      "Epoch 89/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.6535 - mae: 7.9086 - val_loss: 58.6286 - val_mae: 5.4904\n",
      "Epoch 90/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.3912 - mae: 7.8170 - val_loss: 67.9630 - val_mae: 6.0327\n",
      "Epoch 91/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.2605 - mae: 7.7944 - val_loss: 54.2833 - val_mae: 5.2815\n",
      "Epoch 92/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.5617 - mae: 7.8928 - val_loss: 57.3602 - val_mae: 5.4230\n",
      "Epoch 93/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.0888 - mae: 7.9052 - val_loss: 68.9705 - val_mae: 6.0377\n",
      "Epoch 94/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.1334 - mae: 7.8464 - val_loss: 65.9690 - val_mae: 5.8478\n",
      "Epoch 95/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.2176 - mae: 7.8742 - val_loss: 55.1740 - val_mae: 5.3219\n",
      "Epoch 96/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.6867 - mae: 7.9424 - val_loss: 53.0670 - val_mae: 5.2293\n",
      "Epoch 97/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.1101 - mae: 7.7096 - val_loss: 55.5609 - val_mae: 5.4123\n",
      "Epoch 98/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.3913 - mae: 7.8344 - val_loss: 56.4761 - val_mae: 5.3242\n",
      "Epoch 99/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.5119 - mae: 7.6898 - val_loss: 68.6807 - val_mae: 5.9948\n",
      "Epoch 100/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.5173 - mae: 7.7998 - val_loss: 53.6306 - val_mae: 5.1961\n",
      "Epoch 101/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.7905 - mae: 7.7872 - val_loss: 55.9678 - val_mae: 5.4152\n",
      "Epoch 102/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.5269 - mae: 7.7458 - val_loss: 55.6876 - val_mae: 5.3182\n",
      "Epoch 103/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.0744 - mae: 7.8088 - val_loss: 55.3854 - val_mae: 5.3250\n",
      "Epoch 104/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.9359 - mae: 7.7270 - val_loss: 56.4342 - val_mae: 5.3559\n",
      "Epoch 105/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.9790 - mae: 7.5638 - val_loss: 53.4179 - val_mae: 5.1813\n",
      "Epoch 106/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.2227 - mae: 7.6273 - val_loss: 53.8157 - val_mae: 5.2781\n",
      "Epoch 107/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.4015 - mae: 7.5789 - val_loss: 55.7360 - val_mae: 5.3447\n",
      "Epoch 108/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.1886 - mae: 7.7057 - val_loss: 68.5991 - val_mae: 6.1071\n",
      "Epoch 109/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.6948 - mae: 7.7731 - val_loss: 58.1248 - val_mae: 5.4801\n",
      "Epoch 110/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.6516 - mae: 7.6062 - val_loss: 54.9595 - val_mae: 5.3100\n",
      "Epoch 111/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.8216 - mae: 7.6550 - val_loss: 61.4882 - val_mae: 5.8592\n",
      "Epoch 112/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.9166 - mae: 7.4116 - val_loss: 54.8744 - val_mae: 5.2712\n",
      "Epoch 113/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.6781 - mae: 7.7294 - val_loss: 53.7455 - val_mae: 5.2621\n",
      "Epoch 114/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.2672 - mae: 7.7736 - val_loss: 61.6799 - val_mae: 5.6555\n",
      "Epoch 115/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.6759 - mae: 7.6710 - val_loss: 55.2443 - val_mae: 5.2742\n",
      "Epoch 116/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.4543 - mae: 7.6830 - val_loss: 60.3877 - val_mae: 5.6019\n",
      "Epoch 117/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.7719 - mae: 7.4406 - val_loss: 54.1509 - val_mae: 5.3480\n",
      "Epoch 118/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.6982 - mae: 7.4226 - val_loss: 53.7058 - val_mae: 5.2026\n",
      "Epoch 119/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.2005 - mae: 7.4523 - val_loss: 57.6944 - val_mae: 5.3931\n",
      "Epoch 120/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.8599 - mae: 7.4981 - val_loss: 53.9572 - val_mae: 5.1624\n",
      "Epoch 121/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.3624 - mae: 7.6849 - val_loss: 52.5120 - val_mae: 5.1191\n",
      "Epoch 122/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.0991 - mae: 7.4276 - val_loss: 53.7055 - val_mae: 5.1907\n",
      "Epoch 123/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.4564 - mae: 7.4510 - val_loss: 64.2037 - val_mae: 5.8013\n",
      "Epoch 124/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.8212 - mae: 7.3263 - val_loss: 54.3570 - val_mae: 5.1798\n",
      "Epoch 125/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.0338 - mae: 7.5929 - val_loss: 56.3313 - val_mae: 5.4185\n",
      "Epoch 126/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.6626 - mae: 7.4433 - val_loss: 62.5996 - val_mae: 5.6512\n",
      "Epoch 127/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.0148 - mae: 7.3641 - val_loss: 55.8363 - val_mae: 5.3251\n",
      "Epoch 128/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.3863 - mae: 7.3655 - val_loss: 54.0490 - val_mae: 5.2298\n",
      "Epoch 129/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89.1068 - mae: 7.0778 - val_loss: 53.2052 - val_mae: 5.1914\n",
      "Epoch 130/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.0438 - mae: 7.4704 - val_loss: 54.3535 - val_mae: 5.2959\n",
      "Epoch 131/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.5562 - mae: 7.2201 - val_loss: 59.3842 - val_mae: 5.5325\n",
      "Epoch 132/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.6695 - mae: 7.2118 - val_loss: 53.2341 - val_mae: 5.1984\n",
      "Epoch 133/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.7913 - mae: 7.2900 - val_loss: 53.4331 - val_mae: 5.2079\n",
      "Epoch 134/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.2585 - mae: 7.3869 - val_loss: 52.8305 - val_mae: 5.1979\n",
      "Epoch 135/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.0344 - mae: 7.2302 - val_loss: 56.4649 - val_mae: 5.4963\n",
      "Epoch 136/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.9760 - mae: 7.3491 - val_loss: 57.7081 - val_mae: 5.4150\n",
      "Epoch 137/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.1714 - mae: 7.2511 - val_loss: 68.7156 - val_mae: 6.1165\n",
      "Epoch 138/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.3133 - mae: 7.4088 - val_loss: 71.1380 - val_mae: 6.1780\n",
      "Epoch 139/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.2688 - mae: 7.1827 - val_loss: 53.8610 - val_mae: 5.2003\n",
      "Epoch 140/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 87.8094 - mae: 7.0667 - val_loss: 53.7911 - val_mae: 5.2783\n",
      "Epoch 141/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.7431 - mae: 7.4079 - val_loss: 62.5852 - val_mae: 5.7354\n",
      "Epoch 142/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.9322 - mae: 7.1960 - val_loss: 56.5881 - val_mae: 5.4812\n",
      "Epoch 143/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89.5702 - mae: 7.0276 - val_loss: 52.5597 - val_mae: 5.1633\n",
      "Epoch 144/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.4530 - mae: 7.1890 - val_loss: 56.3169 - val_mae: 5.4133\n",
      "Epoch 145/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 88.9041 - mae: 6.9826 - val_loss: 55.6006 - val_mae: 5.3640\n",
      "Epoch 146/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90.3090 - mae: 7.1389 - val_loss: 53.2404 - val_mae: 5.2216\n",
      "Epoch 147/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.9134 - mae: 7.1487 - val_loss: 64.2311 - val_mae: 5.8256\n",
      "Epoch 148/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.6370 - mae: 7.3932 - val_loss: 54.9072 - val_mae: 5.2979\n",
      "Epoch 149/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.9054 - mae: 7.2546 - val_loss: 52.7526 - val_mae: 5.1745\n",
      "Epoch 150/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 85.9052 - mae: 6.9132 - val_loss: 54.6123 - val_mae: 5.2548\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61.1157 - mae: 5.3022\n",
      "Patience 40: Validation MAE: 5.12\n",
      "Patience 40: Validation Loss: 52.51\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 943.2968 - mae: 19.1877 - val_loss: 206.9715 - val_mae: 10.1594\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 254.6236 - mae: 12.5564 - val_loss: 161.5681 - val_mae: 9.8866\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 250.7625 - mae: 12.3668 - val_loss: 118.0348 - val_mae: 8.9323\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 228.7723 - mae: 11.8754 - val_loss: 95.5443 - val_mae: 7.8488\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 184.7767 - mae: 10.5922 - val_loss: 82.1116 - val_mae: 7.1460\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 184.3400 - mae: 10.4632 - val_loss: 87.1543 - val_mae: 6.8777\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 171.3210 - mae: 10.2401 - val_loss: 65.8238 - val_mae: 6.0634\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 169.7846 - mae: 10.0109 - val_loss: 69.9279 - val_mae: 6.0603\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 168.4728 - mae: 10.0817 - val_loss: 69.7295 - val_mae: 6.0121\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153.7455 - mae: 9.7014 - val_loss: 66.9168 - val_mae: 5.9104\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154.1552 - mae: 9.6246 - val_loss: 62.7615 - val_mae: 5.7041\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.3643 - mae: 9.6255 - val_loss: 63.5830 - val_mae: 5.7903\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 164.5138 - mae: 9.9993 - val_loss: 81.8812 - val_mae: 6.5828\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157.4861 - mae: 9.6858 - val_loss: 64.7316 - val_mae: 5.8483\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159.8066 - mae: 9.6448 - val_loss: 63.8193 - val_mae: 5.7849\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 161.5292 - mae: 9.7244 - val_loss: 60.6341 - val_mae: 5.5885\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155.4504 - mae: 9.6255 - val_loss: 59.8816 - val_mae: 5.6422\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144.2795 - mae: 9.3590 - val_loss: 66.2394 - val_mae: 6.1831\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153.1155 - mae: 9.4691 - val_loss: 69.7445 - val_mae: 6.0239\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145.1083 - mae: 9.3422 - val_loss: 60.8279 - val_mae: 5.7402\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153.5169 - mae: 9.5704 - val_loss: 62.1760 - val_mae: 5.6447\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147.3506 - mae: 9.3172 - val_loss: 79.5264 - val_mae: 6.4835\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146.2392 - mae: 9.2281 - val_loss: 69.4259 - val_mae: 6.2071\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146.0725 - mae: 9.2674 - val_loss: 66.3732 - val_mae: 5.7761\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140.2762 - mae: 8.9736 - val_loss: 59.0299 - val_mae: 5.5800\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.9213 - mae: 8.9020 - val_loss: 66.8616 - val_mae: 5.9560\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141.2737 - mae: 9.0024 - val_loss: 68.9346 - val_mae: 6.0869\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.7751 - mae: 8.8505 - val_loss: 67.4955 - val_mae: 6.1192\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.0283 - mae: 8.7651 - val_loss: 58.3025 - val_mae: 5.4696\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140.2404 - mae: 9.0828 - val_loss: 60.3820 - val_mae: 5.6000\n",
      "Epoch 31/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.3479 - mae: 8.9853 - val_loss: 61.3272 - val_mae: 5.8281\n",
      "Epoch 32/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.2044 - mae: 8.9140 - val_loss: 67.2574 - val_mae: 5.9131\n",
      "Epoch 33/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.6677 - mae: 8.8255 - val_loss: 72.5377 - val_mae: 6.1253\n",
      "Epoch 34/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131.9865 - mae: 8.8801 - val_loss: 58.6451 - val_mae: 5.4990\n",
      "Epoch 35/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135.0708 - mae: 8.8826 - val_loss: 60.0750 - val_mae: 5.6770\n",
      "Epoch 36/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134.2100 - mae: 8.8719 - val_loss: 59.2297 - val_mae: 5.4992\n",
      "Epoch 37/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.6938 - mae: 8.7680 - val_loss: 62.6350 - val_mae: 5.7740\n",
      "Epoch 38/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131.4099 - mae: 8.8212 - val_loss: 64.7442 - val_mae: 6.0995\n",
      "Epoch 39/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.2730 - mae: 8.7444 - val_loss: 65.1282 - val_mae: 5.8029\n",
      "Epoch 40/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.1640 - mae: 8.8581 - val_loss: 62.1055 - val_mae: 5.7632\n",
      "Epoch 41/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.6385 - mae: 8.8181 - val_loss: 59.1541 - val_mae: 5.5930\n",
      "Epoch 42/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.3848 - mae: 8.5239 - val_loss: 68.0163 - val_mae: 5.9719\n",
      "Epoch 43/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.7138 - mae: 8.7539 - val_loss: 59.6677 - val_mae: 5.5669\n",
      "Epoch 44/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.8687 - mae: 8.5941 - val_loss: 60.0114 - val_mae: 5.5864\n",
      "Epoch 45/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.7822 - mae: 8.8524 - val_loss: 64.0216 - val_mae: 5.7821\n",
      "Epoch 46/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131.5195 - mae: 8.7039 - val_loss: 58.7597 - val_mae: 5.6347\n",
      "Epoch 47/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.4493 - mae: 8.7863 - val_loss: 69.4595 - val_mae: 6.1260\n",
      "Epoch 48/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.3986 - mae: 8.6134 - val_loss: 66.6578 - val_mae: 6.3010\n",
      "Epoch 49/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.0011 - mae: 8.6321 - val_loss: 59.7026 - val_mae: 5.6569\n",
      "Epoch 50/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.8425 - mae: 8.6415 - val_loss: 62.7264 - val_mae: 6.0066\n",
      "Epoch 51/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.5167 - mae: 8.4852 - val_loss: 58.2677 - val_mae: 5.4685\n",
      "Epoch 52/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.9176 - mae: 8.5227 - val_loss: 59.6969 - val_mae: 5.7080\n",
      "Epoch 53/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.6445 - mae: 8.2421 - val_loss: 58.0554 - val_mae: 5.5721\n",
      "Epoch 54/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121.6554 - mae: 8.4723 - val_loss: 58.6011 - val_mae: 5.6149\n",
      "Epoch 55/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.9078 - mae: 8.4433 - val_loss: 61.3852 - val_mae: 5.5957\n",
      "Epoch 56/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.1613 - mae: 8.4413 - val_loss: 61.7890 - val_mae: 5.7025\n",
      "Epoch 57/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.4735 - mae: 8.4039 - val_loss: 56.2037 - val_mae: 5.3503\n",
      "Epoch 58/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.1719 - mae: 8.5214 - val_loss: 58.1747 - val_mae: 5.4475\n",
      "Epoch 59/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.6548 - mae: 8.4902 - val_loss: 57.3553 - val_mae: 5.4685\n",
      "Epoch 60/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120.3268 - mae: 8.4168 - val_loss: 87.4932 - val_mae: 7.5151\n",
      "Epoch 61/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.7383 - mae: 8.5469 - val_loss: 59.3942 - val_mae: 5.5389\n",
      "Epoch 62/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.6369 - mae: 8.6909 - val_loss: 80.2098 - val_mae: 6.5967\n",
      "Epoch 63/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.1153 - mae: 8.4367 - val_loss: 64.6474 - val_mae: 5.8423\n",
      "Epoch 64/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.8219 - mae: 8.2267 - val_loss: 83.4156 - val_mae: 6.7075\n",
      "Epoch 65/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.3105 - mae: 8.3545 - val_loss: 57.6267 - val_mae: 5.4656\n",
      "Epoch 66/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.2014 - mae: 8.4012 - val_loss: 68.8941 - val_mae: 6.0053\n",
      "Epoch 67/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.5038 - mae: 8.2688 - val_loss: 57.5313 - val_mae: 5.3712\n",
      "Epoch 68/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.1196 - mae: 8.1763 - val_loss: 57.0053 - val_mae: 5.4708\n",
      "Epoch 69/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.1128 - mae: 8.1179 - val_loss: 62.0278 - val_mae: 5.5669\n",
      "Epoch 70/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.9881 - mae: 8.0905 - val_loss: 57.6773 - val_mae: 5.5346\n",
      "Epoch 71/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.7934 - mae: 8.1944 - val_loss: 62.4028 - val_mae: 5.7610\n",
      "Epoch 72/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.4743 - mae: 8.2471 - val_loss: 62.8052 - val_mae: 5.7788\n",
      "Epoch 73/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.0402 - mae: 8.1142 - val_loss: 56.4854 - val_mae: 5.3990\n",
      "Epoch 74/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.5602 - mae: 7.9969 - val_loss: 55.6777 - val_mae: 5.3512\n",
      "Epoch 75/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.9122 - mae: 7.9529 - val_loss: 57.4271 - val_mae: 5.4423\n",
      "Epoch 76/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.6978 - mae: 8.0866 - val_loss: 66.6312 - val_mae: 5.9404\n",
      "Epoch 77/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.7426 - mae: 8.2473 - val_loss: 71.4167 - val_mae: 6.1137\n",
      "Epoch 78/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.2149 - mae: 7.9773 - val_loss: 76.4282 - val_mae: 6.5261\n",
      "Epoch 79/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120.6404 - mae: 8.3234 - val_loss: 55.0009 - val_mae: 5.3331\n",
      "Epoch 80/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.7033 - mae: 8.1395 - val_loss: 55.9539 - val_mae: 5.4245\n",
      "Epoch 81/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.1496 - mae: 8.0142 - val_loss: 67.6929 - val_mae: 6.0010\n",
      "Epoch 82/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.0490 - mae: 8.2191 - val_loss: 63.9247 - val_mae: 5.7801\n",
      "Epoch 83/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.5059 - mae: 7.9914 - val_loss: 65.4347 - val_mae: 6.0439\n",
      "Epoch 84/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.8709 - mae: 7.9548 - val_loss: 65.3518 - val_mae: 6.2413\n",
      "Epoch 85/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.4216 - mae: 7.9296 - val_loss: 54.2542 - val_mae: 5.2162\n",
      "Epoch 86/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.0845 - mae: 7.9543 - val_loss: 56.7747 - val_mae: 5.4436\n",
      "Epoch 87/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.1461 - mae: 8.0308 - val_loss: 54.5361 - val_mae: 5.2882\n",
      "Epoch 88/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.0439 - mae: 7.9381 - val_loss: 54.9936 - val_mae: 5.3324\n",
      "Epoch 89/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.5575 - mae: 7.8663 - val_loss: 57.9489 - val_mae: 5.4127\n",
      "Epoch 90/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.2511 - mae: 8.2377 - val_loss: 59.6194 - val_mae: 5.5743\n",
      "Epoch 91/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.1498 - mae: 7.9183 - val_loss: 63.0791 - val_mae: 5.7139\n",
      "Epoch 92/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.4833 - mae: 8.0025 - val_loss: 59.8705 - val_mae: 5.5019\n",
      "Epoch 93/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.5928 - mae: 7.9942 - val_loss: 54.2485 - val_mae: 5.2495\n",
      "Epoch 94/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.6521 - mae: 7.8188 - val_loss: 58.5305 - val_mae: 5.5509\n",
      "Epoch 95/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.3404 - mae: 7.8491 - val_loss: 56.7884 - val_mae: 5.3449\n",
      "Epoch 96/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.8506 - mae: 8.0638 - val_loss: 57.4782 - val_mae: 5.4478\n",
      "Epoch 97/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.0469 - mae: 7.7946 - val_loss: 54.2746 - val_mae: 5.3610\n",
      "Epoch 98/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.7986 - mae: 7.7263 - val_loss: 57.9839 - val_mae: 5.4780\n",
      "Epoch 99/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.6465 - mae: 7.6714 - val_loss: 54.8739 - val_mae: 5.3072\n",
      "Epoch 100/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.0081 - mae: 7.7772 - val_loss: 56.3622 - val_mae: 5.3438\n",
      "Epoch 101/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.1242 - mae: 7.8175 - val_loss: 53.3567 - val_mae: 5.2540\n",
      "Epoch 102/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.4023 - mae: 7.7363 - val_loss: 63.3442 - val_mae: 5.7396\n",
      "Epoch 103/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.2191 - mae: 8.0083 - val_loss: 57.2516 - val_mae: 5.4113\n",
      "Epoch 104/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.6186 - mae: 7.7706 - val_loss: 54.5837 - val_mae: 5.3754\n",
      "Epoch 105/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.9791 - mae: 7.8180 - val_loss: 54.6380 - val_mae: 5.2919\n",
      "Epoch 106/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.4383 - mae: 7.5628 - val_loss: 53.3156 - val_mae: 5.2664\n",
      "Epoch 107/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.3243 - mae: 7.5260 - val_loss: 57.0779 - val_mae: 5.4015\n",
      "Epoch 108/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.7864 - mae: 7.5539 - val_loss: 53.1025 - val_mae: 5.1688\n",
      "Epoch 109/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.2629 - mae: 7.6662 - val_loss: 56.4780 - val_mae: 5.3539\n",
      "Epoch 110/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.7132 - mae: 7.5120 - val_loss: 57.5296 - val_mae: 5.3616\n",
      "Epoch 111/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.2408 - mae: 7.8001 - val_loss: 58.0868 - val_mae: 5.4227\n",
      "Epoch 112/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.1112 - mae: 7.8338 - val_loss: 58.7695 - val_mae: 5.5156\n",
      "Epoch 113/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.0266 - mae: 7.5563 - val_loss: 77.5643 - val_mae: 6.5373\n",
      "Epoch 114/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.0025 - mae: 7.6989 - val_loss: 53.6408 - val_mae: 5.2728\n",
      "Epoch 115/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.7565 - mae: 7.4370 - val_loss: 54.5895 - val_mae: 5.3361\n",
      "Epoch 116/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.3126 - mae: 7.6230 - val_loss: 53.5184 - val_mae: 5.2182\n",
      "Epoch 117/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.9969 - mae: 7.5827 - val_loss: 58.1710 - val_mae: 5.6336\n",
      "Epoch 118/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.9586 - mae: 7.4405 - val_loss: 61.4971 - val_mae: 5.7154\n",
      "Epoch 119/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.4949 - mae: 7.4596 - val_loss: 54.6829 - val_mae: 5.2762\n",
      "Epoch 120/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.6509 - mae: 7.4600 - val_loss: 53.1348 - val_mae: 5.2220\n",
      "Epoch 121/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.9716 - mae: 7.6119 - val_loss: 69.1803 - val_mae: 6.0262\n",
      "Epoch 122/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.1723 - mae: 7.3774 - val_loss: 76.9443 - val_mae: 6.9648\n",
      "Epoch 123/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.4772 - mae: 7.6239 - val_loss: 54.0961 - val_mae: 5.2710\n",
      "Epoch 124/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.4975 - mae: 7.4593 - val_loss: 58.1882 - val_mae: 5.4566\n",
      "Epoch 125/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.7234 - mae: 7.5327 - val_loss: 57.6389 - val_mae: 5.4277\n",
      "Epoch 126/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.3885 - mae: 7.5757 - val_loss: 64.6742 - val_mae: 5.8572\n",
      "Epoch 127/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.8031 - mae: 7.3066 - val_loss: 53.7349 - val_mae: 5.3090\n",
      "Epoch 128/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.6551 - mae: 7.3972 - val_loss: 60.8172 - val_mae: 5.5684\n",
      "Epoch 129/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.9281 - mae: 7.4395 - val_loss: 63.6208 - val_mae: 5.6961\n",
      "Epoch 130/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.7945 - mae: 7.4051 - val_loss: 53.5033 - val_mae: 5.2090\n",
      "Epoch 131/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.3412 - mae: 7.3968 - val_loss: 53.4913 - val_mae: 5.2069\n",
      "Epoch 132/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.0541 - mae: 7.4433 - val_loss: 55.0514 - val_mae: 5.2875\n",
      "Epoch 133/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.0810 - mae: 7.5721 - val_loss: 53.6748 - val_mae: 5.2427\n",
      "Epoch 134/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.6802 - mae: 7.2881 - val_loss: 56.7428 - val_mae: 5.4837\n",
      "Epoch 135/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.9061 - mae: 7.1925 - val_loss: 72.9532 - val_mae: 6.2310\n",
      "Epoch 136/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.1822 - mae: 7.3057 - val_loss: 54.6241 - val_mae: 5.3347\n",
      "Epoch 137/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.6419 - mae: 7.2648 - val_loss: 54.6803 - val_mae: 5.2654\n",
      "Epoch 138/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.2731 - mae: 7.3191 - val_loss: 58.5348 - val_mae: 5.5086\n",
      "Patience 30: Early stopping occurred at epoch 137\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60.6066 - mae: 5.3647  \n",
      "Patience 30: Validation MAE: 5.17\n",
      "Patience 30: Validation Loss: 53.10\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 585.6331 - mae: 17.5755 - val_loss: 148.1655 - val_mae: 10.7149\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 260.3099 - mae: 12.6482 - val_loss: 109.5090 - val_mae: 8.6446\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 229.2014 - mae: 11.7772 - val_loss: 93.0440 - val_mae: 7.0008\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 192.0109 - mae: 10.7163 - val_loss: 68.6292 - val_mae: 6.2017\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 174.4788 - mae: 10.2589 - val_loss: 107.5245 - val_mae: 7.8838\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 172.1566 - mae: 10.1681 - val_loss: 65.2600 - val_mae: 5.9271\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158.7246 - mae: 9.6654 - val_loss: 147.4216 - val_mae: 9.6407\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 165.6708 - mae: 9.9371 - val_loss: 66.2443 - val_mae: 6.0593\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158.9693 - mae: 9.7386 - val_loss: 67.0031 - val_mae: 5.8895\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153.7955 - mae: 9.3925 - val_loss: 93.3594 - val_mae: 7.8553\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 174.9796 - mae: 10.1286 - val_loss: 75.6836 - val_mae: 6.2914\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 164.3189 - mae: 9.8398 - val_loss: 65.9310 - val_mae: 6.0143\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146.5371 - mae: 9.3281 - val_loss: 61.6005 - val_mae: 5.6212\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144.2439 - mae: 9.2007 - val_loss: 60.2213 - val_mae: 5.5137\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.1924 - mae: 9.1473 - val_loss: 59.4611 - val_mae: 5.5729\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146.4928 - mae: 9.2974 - val_loss: 109.9514 - val_mae: 8.1711\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 150.5005 - mae: 9.4168 - val_loss: 75.0229 - val_mae: 6.6636\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149.9738 - mae: 9.3079 - val_loss: 61.5606 - val_mae: 5.5576\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141.2658 - mae: 9.1324 - val_loss: 88.4659 - val_mae: 7.0683\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147.8800 - mae: 9.3355 - val_loss: 63.2437 - val_mae: 5.6722\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134.4632 - mae: 8.8662 - val_loss: 77.4913 - val_mae: 6.4415\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146.1828 - mae: 9.2986 - val_loss: 59.3637 - val_mae: 5.6147\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.6909 - mae: 9.1690 - val_loss: 79.1986 - val_mae: 6.5497\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140.9263 - mae: 9.0408 - val_loss: 58.3236 - val_mae: 5.4764\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.8045 - mae: 9.0026 - val_loss: 59.0361 - val_mae: 5.5485\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.2755 - mae: 9.1707 - val_loss: 58.9695 - val_mae: 5.4830\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.9681 - mae: 8.9293 - val_loss: 63.2200 - val_mae: 5.6883\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.8806 - mae: 8.9233 - val_loss: 63.0277 - val_mae: 5.6620\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.8176 - mae: 8.9883 - val_loss: 57.2133 - val_mae: 5.4209\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.1877 - mae: 8.9460 - val_loss: 59.5834 - val_mae: 5.4887\n",
      "Epoch 31/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.4964 - mae: 9.0325 - val_loss: 60.1485 - val_mae: 5.5114\n",
      "Epoch 32/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139.8578 - mae: 9.0815 - val_loss: 59.7642 - val_mae: 5.7087\n",
      "Epoch 33/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.9509 - mae: 8.7206 - val_loss: 60.1235 - val_mae: 5.4924\n",
      "Epoch 34/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.4367 - mae: 8.5954 - val_loss: 74.2278 - val_mae: 6.2123\n",
      "Epoch 35/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134.9681 - mae: 8.8132 - val_loss: 57.4478 - val_mae: 5.4347\n",
      "Epoch 36/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135.1102 - mae: 8.8667 - val_loss: 64.3463 - val_mae: 5.7718\n",
      "Epoch 37/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.7535 - mae: 8.7896 - val_loss: 57.5993 - val_mae: 5.5329\n",
      "Epoch 38/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131.6615 - mae: 8.7596 - val_loss: 57.9962 - val_mae: 5.5084\n",
      "Epoch 39/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.8780 - mae: 8.6556 - val_loss: 92.9223 - val_mae: 7.3625\n",
      "Epoch 40/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.8251 - mae: 8.8322 - val_loss: 57.8404 - val_mae: 5.5373\n",
      "Epoch 41/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.1150 - mae: 8.9666 - val_loss: 57.5330 - val_mae: 5.4184\n",
      "Epoch 42/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.2979 - mae: 8.5551 - val_loss: 63.4614 - val_mae: 5.6351\n",
      "Epoch 43/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.8469 - mae: 8.6726 - val_loss: 57.6536 - val_mae: 5.4699\n",
      "Epoch 44/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.5789 - mae: 8.5093 - val_loss: 62.4563 - val_mae: 5.6511\n",
      "Epoch 45/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.5791 - mae: 8.5561 - val_loss: 60.8004 - val_mae: 5.7654\n",
      "Epoch 46/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.6582 - mae: 8.6819 - val_loss: 57.4882 - val_mae: 5.4313\n",
      "Epoch 47/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.8221 - mae: 8.5951 - val_loss: 60.1849 - val_mae: 5.7371\n",
      "Epoch 48/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.5538 - mae: 8.6110 - val_loss: 57.5376 - val_mae: 5.5133\n",
      "Epoch 49/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.6331 - mae: 8.5051 - val_loss: 56.6080 - val_mae: 5.3575\n",
      "Epoch 50/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.9985 - mae: 8.5092 - val_loss: 79.2902 - val_mae: 6.6728\n",
      "Epoch 51/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.3794 - mae: 8.4102 - val_loss: 65.9853 - val_mae: 5.9233\n",
      "Epoch 52/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.7341 - mae: 8.4850 - val_loss: 59.5813 - val_mae: 5.5272\n",
      "Epoch 53/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.3207 - mae: 8.5130 - val_loss: 65.5564 - val_mae: 5.8616\n",
      "Epoch 54/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.6735 - mae: 8.1669 - val_loss: 56.6100 - val_mae: 5.3450\n",
      "Epoch 55/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.4315 - mae: 8.6318 - val_loss: 59.5244 - val_mae: 5.5343\n",
      "Epoch 56/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.9196 - mae: 8.4006 - val_loss: 60.5624 - val_mae: 5.5395\n",
      "Epoch 57/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.3051 - mae: 8.3514 - val_loss: 69.5030 - val_mae: 6.1469\n",
      "Epoch 58/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.8183 - mae: 8.1246 - val_loss: 63.3003 - val_mae: 5.7123\n",
      "Epoch 59/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.3679 - mae: 8.2299 - val_loss: 55.4423 - val_mae: 5.3224\n",
      "Epoch 60/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.6149 - mae: 8.6087 - val_loss: 71.3767 - val_mae: 6.3649\n",
      "Epoch 61/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121.0520 - mae: 8.3547 - val_loss: 73.1342 - val_mae: 6.3382\n",
      "Epoch 62/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.9119 - mae: 8.5996 - val_loss: 57.3090 - val_mae: 5.5423\n",
      "Epoch 63/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.7483 - mae: 8.3537 - val_loss: 62.4972 - val_mae: 5.9209\n",
      "Epoch 64/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.7089 - mae: 8.2389 - val_loss: 58.5745 - val_mae: 5.4731\n",
      "Epoch 65/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.4591 - mae: 8.1853 - val_loss: 59.1462 - val_mae: 5.5071\n",
      "Epoch 66/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.2774 - mae: 8.1827 - val_loss: 57.4890 - val_mae: 5.3421\n",
      "Epoch 67/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.8646 - mae: 8.4690 - val_loss: 55.9107 - val_mae: 5.3466\n",
      "Epoch 68/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.1872 - mae: 8.3689 - val_loss: 54.7100 - val_mae: 5.2866\n",
      "Epoch 69/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.8432 - mae: 8.4218 - val_loss: 62.0314 - val_mae: 5.6727\n",
      "Epoch 70/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.8055 - mae: 8.1747 - val_loss: 56.2950 - val_mae: 5.4486\n",
      "Epoch 71/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.1484 - mae: 8.0203 - val_loss: 61.1060 - val_mae: 5.5465\n",
      "Epoch 72/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.2168 - mae: 8.1051 - val_loss: 55.4949 - val_mae: 5.2742\n",
      "Epoch 73/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.2795 - mae: 8.3111 - val_loss: 57.6750 - val_mae: 5.3943\n",
      "Epoch 74/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118.8608 - mae: 8.2365 - val_loss: 54.9637 - val_mae: 5.3049\n",
      "Epoch 75/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.0118 - mae: 8.2184 - val_loss: 56.1650 - val_mae: 5.4368\n",
      "Epoch 76/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.7899 - mae: 7.9047 - val_loss: 67.2827 - val_mae: 5.9584\n",
      "Epoch 77/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.1699 - mae: 8.2379 - val_loss: 56.0387 - val_mae: 5.3215\n",
      "Epoch 78/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110.3828 - mae: 8.0011 - val_loss: 55.3229 - val_mae: 5.3175\n",
      "Epoch 79/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.8536 - mae: 8.2755 - val_loss: 55.2327 - val_mae: 5.3071\n",
      "Epoch 80/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.2529 - mae: 7.6962 - val_loss: 54.1729 - val_mae: 5.1677\n",
      "Epoch 81/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.1643 - mae: 7.9773 - val_loss: 54.4121 - val_mae: 5.2192\n",
      "Epoch 82/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.1671 - mae: 7.9614 - val_loss: 57.8528 - val_mae: 5.5988\n",
      "Epoch 83/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.1895 - mae: 8.0187 - val_loss: 63.6156 - val_mae: 5.8373\n",
      "Epoch 84/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.9192 - mae: 7.8093 - val_loss: 61.6308 - val_mae: 5.8590\n",
      "Epoch 85/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.5213 - mae: 7.7396 - val_loss: 56.3716 - val_mae: 5.3956\n",
      "Epoch 86/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.6034 - mae: 7.9477 - val_loss: 53.7080 - val_mae: 5.2672\n",
      "Epoch 87/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.3188 - mae: 7.7609 - val_loss: 57.3254 - val_mae: 5.4209\n",
      "Epoch 88/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.2249 - mae: 7.8155 - val_loss: 75.5884 - val_mae: 6.4116\n",
      "Epoch 89/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.9881 - mae: 7.8891 - val_loss: 55.1920 - val_mae: 5.2677\n",
      "Epoch 90/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.7798 - mae: 7.9917 - val_loss: 55.1744 - val_mae: 5.3271\n",
      "Epoch 91/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.0317 - mae: 7.6705 - val_loss: 56.4618 - val_mae: 5.4059\n",
      "Epoch 92/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.8122 - mae: 7.8818 - val_loss: 53.7629 - val_mae: 5.2443\n",
      "Epoch 93/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.8291 - mae: 7.6382 - val_loss: 52.9973 - val_mae: 5.1897\n",
      "Epoch 94/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.4533 - mae: 7.6983 - val_loss: 56.3757 - val_mae: 5.3526\n",
      "Epoch 95/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.5828 - mae: 7.8776 - val_loss: 61.7333 - val_mae: 5.7107\n",
      "Epoch 96/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.1065 - mae: 7.8022 - val_loss: 54.2720 - val_mae: 5.2410\n",
      "Epoch 97/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.0865 - mae: 7.5993 - val_loss: 54.1569 - val_mae: 5.2231\n",
      "Epoch 98/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.1170 - mae: 7.5318 - val_loss: 58.7168 - val_mae: 5.6526\n",
      "Epoch 99/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.8717 - mae: 7.7902 - val_loss: 52.8826 - val_mae: 5.1833\n",
      "Epoch 100/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 99.8877 - mae: 7.4788 - val_loss: 59.3850 - val_mae: 5.5290\n",
      "Epoch 101/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.4575 - mae: 7.7552 - val_loss: 57.7807 - val_mae: 5.4417\n",
      "Epoch 102/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.6854 - mae: 7.5414 - val_loss: 57.5640 - val_mae: 5.4408\n",
      "Epoch 103/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.8414 - mae: 7.7326 - val_loss: 57.1989 - val_mae: 5.3961\n",
      "Epoch 104/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.7622 - mae: 7.6016 - val_loss: 54.6488 - val_mae: 5.2953\n",
      "Epoch 105/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.5241 - mae: 7.5522 - val_loss: 55.1958 - val_mae: 5.3450\n",
      "Epoch 106/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.9001 - mae: 7.8394 - val_loss: 64.2012 - val_mae: 5.7904\n",
      "Epoch 107/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.8677 - mae: 7.7492 - val_loss: 53.6527 - val_mae: 5.2140\n",
      "Epoch 108/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.4351 - mae: 7.5385 - val_loss: 53.8906 - val_mae: 5.2510\n",
      "Epoch 109/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.1180 - mae: 7.3300 - val_loss: 56.4230 - val_mae: 5.3774\n",
      "Epoch 110/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.8750 - mae: 7.4253 - val_loss: 60.4550 - val_mae: 5.7124\n",
      "Epoch 111/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.9752 - mae: 7.6579 - val_loss: 53.7735 - val_mae: 5.2082\n",
      "Epoch 112/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.1535 - mae: 7.6408 - val_loss: 56.7557 - val_mae: 5.4451\n",
      "Epoch 113/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.2669 - mae: 7.5696 - val_loss: 55.6242 - val_mae: 5.2735\n",
      "Epoch 114/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 96.4565 - mae: 7.3408 - val_loss: 54.4623 - val_mae: 5.2610\n",
      "Epoch 115/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.3419 - mae: 7.5807 - val_loss: 55.9596 - val_mae: 5.3666\n",
      "Epoch 116/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.4897 - mae: 7.6754 - val_loss: 61.3729 - val_mae: 5.6512\n",
      "Epoch 117/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.8505 - mae: 7.4403 - val_loss: 52.1628 - val_mae: 5.1445\n",
      "Epoch 118/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.4276 - mae: 7.4180 - val_loss: 54.0915 - val_mae: 5.2368\n",
      "Epoch 119/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.6503 - mae: 7.4901 - val_loss: 54.3710 - val_mae: 5.2163\n",
      "Epoch 120/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.0582 - mae: 7.3902 - val_loss: 63.6311 - val_mae: 5.8249\n",
      "Epoch 121/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.8857 - mae: 7.5403 - val_loss: 54.4969 - val_mae: 5.2950\n",
      "Epoch 122/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.2082 - mae: 7.5695 - val_loss: 53.3141 - val_mae: 5.2436\n",
      "Epoch 123/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.4217 - mae: 7.2974 - val_loss: 54.4877 - val_mae: 5.2631\n",
      "Epoch 124/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.2035 - mae: 7.2186 - val_loss: 56.1605 - val_mae: 5.3426\n",
      "Epoch 125/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.0202 - mae: 7.4762 - val_loss: 53.5224 - val_mae: 5.2417\n",
      "Epoch 126/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.7760 - mae: 7.2949 - val_loss: 53.5136 - val_mae: 5.2297\n",
      "Epoch 127/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.9136 - mae: 7.2984 - val_loss: 53.0078 - val_mae: 5.1532\n",
      "Epoch 128/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.3468 - mae: 7.3999 - val_loss: 61.2094 - val_mae: 5.6231\n",
      "Epoch 129/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.1981 - mae: 7.4385 - val_loss: 57.8985 - val_mae: 5.4170\n",
      "Epoch 130/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.2147 - mae: 7.3555 - val_loss: 53.8417 - val_mae: 5.2275\n",
      "Epoch 131/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.4773 - mae: 7.2151 - val_loss: 56.3534 - val_mae: 5.3734\n",
      "Epoch 132/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.1019 - mae: 7.2592 - val_loss: 55.3272 - val_mae: 5.3455\n",
      "Epoch 133/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.9882 - mae: 7.3942 - val_loss: 54.3931 - val_mae: 5.2262\n",
      "Epoch 134/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.9881 - mae: 7.3540 - val_loss: 54.5746 - val_mae: 5.2574\n",
      "Epoch 135/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.7207 - mae: 7.3195 - val_loss: 53.2015 - val_mae: 5.1884\n",
      "Epoch 136/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.5392 - mae: 7.2555 - val_loss: 57.5663 - val_mae: 5.3922\n",
      "Epoch 137/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.8107 - mae: 7.2589 - val_loss: 52.9006 - val_mae: 5.1933\n",
      "Patience 20: Early stopping occurred at epoch 136\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59.7020 - mae: 5.3033\n",
      "Patience 20: Validation MAE: 5.14\n",
      "Patience 20: Validation Loss: 52.16\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 673.2272 - mae: 17.9380 - val_loss: 135.4534 - val_mae: 9.3657\n",
      "Epoch 2/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 245.7476 - mae: 12.2784 - val_loss: 109.3473 - val_mae: 8.0121\n",
      "Epoch 3/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 229.6516 - mae: 11.8711 - val_loss: 97.7940 - val_mae: 7.4516\n",
      "Epoch 4/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 189.9594 - mae: 10.7271 - val_loss: 123.9466 - val_mae: 9.1726\n",
      "Epoch 5/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 182.7317 - mae: 10.5171 - val_loss: 101.9783 - val_mae: 7.5372\n",
      "Epoch 6/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 177.9776 - mae: 10.3432 - val_loss: 77.1932 - val_mae: 6.7385\n",
      "Epoch 7/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156.9493 - mae: 9.6707 - val_loss: 68.9833 - val_mae: 5.9786\n",
      "Epoch 8/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157.0288 - mae: 9.6996 - val_loss: 66.3532 - val_mae: 6.0411\n",
      "Epoch 9/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151.7910 - mae: 9.4731 - val_loss: 64.4025 - val_mae: 5.7425\n",
      "Epoch 10/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151.4476 - mae: 9.5098 - val_loss: 62.7003 - val_mae: 5.7401\n",
      "Epoch 11/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154.3044 - mae: 9.5106 - val_loss: 64.1934 - val_mae: 5.7736\n",
      "Epoch 12/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.0392 - mae: 9.2171 - val_loss: 62.7149 - val_mae: 5.7982\n",
      "Epoch 13/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.8437 - mae: 9.1937 - val_loss: 65.8858 - val_mae: 5.9347\n",
      "Epoch 14/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.9301 - mae: 9.0168 - val_loss: 60.8052 - val_mae: 5.6241\n",
      "Epoch 15/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.1019 - mae: 9.1170 - val_loss: 94.2737 - val_mae: 7.2364\n",
      "Epoch 16/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147.5001 - mae: 9.1763 - val_loss: 61.2529 - val_mae: 5.5720\n",
      "Epoch 17/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.7274 - mae: 9.1121 - val_loss: 60.3159 - val_mae: 5.6505\n",
      "Epoch 18/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.1707 - mae: 8.9175 - val_loss: 59.7422 - val_mae: 5.6711\n",
      "Epoch 19/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.9055 - mae: 9.0710 - val_loss: 72.2344 - val_mae: 6.3130\n",
      "Epoch 20/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.9618 - mae: 9.0212 - val_loss: 58.3427 - val_mae: 5.5590\n",
      "Epoch 21/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134.5702 - mae: 8.9199 - val_loss: 77.1386 - val_mae: 6.4363\n",
      "Epoch 22/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.7534 - mae: 9.0108 - val_loss: 68.7392 - val_mae: 5.9889\n",
      "Epoch 23/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.6153 - mae: 8.9200 - val_loss: 61.2148 - val_mae: 5.6133\n",
      "Epoch 24/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.7082 - mae: 8.7570 - val_loss: 60.5025 - val_mae: 5.5846\n",
      "Epoch 25/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135.4291 - mae: 8.8848 - val_loss: 59.2370 - val_mae: 5.5338\n",
      "Epoch 26/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.4188 - mae: 8.7394 - val_loss: 60.4011 - val_mae: 5.5858\n",
      "Epoch 27/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.6247 - mae: 8.6330 - val_loss: 68.2413 - val_mae: 6.0220\n",
      "Epoch 28/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.9341 - mae: 8.6650 - val_loss: 70.6660 - val_mae: 6.0605\n",
      "Epoch 29/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.0353 - mae: 8.5547 - val_loss: 61.2710 - val_mae: 5.6015\n",
      "Epoch 30/150\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.8368 - mae: 8.7937 - val_loss: 96.1012 - val_mae: 7.4547\n",
      "Patience 10: Early stopping occurred at epoch 29\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65.6997 - mae: 5.7281\n",
      "Patience 10: Validation MAE: 5.56\n",
      "Patience 10: Validation Loss: 58.34\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 52.5120, MAE = 5.1191, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 53.1025, MAE = 5.1688, Early Stopping Occurred: True, Early Stopping Epoch: 137\n",
      "Patience 20: Loss = 52.1628, MAE = 5.1445, Early Stopping Occurred: True, Early Stopping Epoch: 136\n",
      "Patience 10: Loss = 58.3427, MAE = 5.5590, Early Stopping Occurred: True, Early Stopping Epoch: 29\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "bresults150 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    dbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    dbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'best_model_{patience}.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = dbp_model.fit(\n",
    "        X_train_combined, DBP_Y_train_combined,\n",
    "        epochs=150,\n",
    "        batch_size=16,\n",
    "        validation_data=(X_test_combined, DBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = dbp_model.evaluate(X_test_combined, DBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    bresults150.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    # 학습 및 검증 손실 그래프 시각화\n",
    "    # plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.title(f'Patience = {patience}')\n",
    "    # plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in bresults150:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 766.2192 - mae: 18.9734 - val_loss: 174.2132 - val_mae: 9.9177\n",
      "Epoch 2/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 272.3779 - mae: 13.1450 - val_loss: 130.6557 - val_mae: 9.2608\n",
      "Epoch 3/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 241.8940 - mae: 12.2327 - val_loss: 115.4508 - val_mae: 8.3873\n",
      "Epoch 4/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.3883 - mae: 11.5229 - val_loss: 104.3422 - val_mae: 8.4437\n",
      "Epoch 5/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.3293 - mae: 10.7522 - val_loss: 86.6302 - val_mae: 6.9055\n",
      "Epoch 6/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 182.1288 - mae: 10.3715 - val_loss: 77.5266 - val_mae: 6.5157\n",
      "Epoch 7/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.3837 - mae: 10.3823 - val_loss: 76.4733 - val_mae: 6.6176\n",
      "Epoch 8/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 169.9435 - mae: 10.1152 - val_loss: 77.6296 - val_mae: 6.4264\n",
      "Epoch 9/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171.8444 - mae: 10.1508 - val_loss: 74.9984 - val_mae: 6.5857\n",
      "Epoch 10/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 169.7339 - mae: 9.9504 - val_loss: 66.9983 - val_mae: 6.0623\n",
      "Epoch 11/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 165.0835 - mae: 9.9848 - val_loss: 65.4372 - val_mae: 5.9049\n",
      "Epoch 12/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.4468 - mae: 9.3555 - val_loss: 80.1150 - val_mae: 6.6107\n",
      "Epoch 13/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.1066 - mae: 9.5298 - val_loss: 67.9815 - val_mae: 6.2744\n",
      "Epoch 14/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.4190 - mae: 9.5515 - val_loss: 81.6397 - val_mae: 6.6758\n",
      "Epoch 15/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.1109 - mae: 9.3156 - val_loss: 66.0575 - val_mae: 6.0781\n",
      "Epoch 16/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.0237 - mae: 9.3715 - val_loss: 63.5899 - val_mae: 5.8139\n",
      "Epoch 17/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.2001 - mae: 9.6297 - val_loss: 66.3908 - val_mae: 6.1535\n",
      "Epoch 18/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.6298 - mae: 9.3235 - val_loss: 62.9370 - val_mae: 5.7414\n",
      "Epoch 19/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.7665 - mae: 9.2543 - val_loss: 69.3851 - val_mae: 6.3565\n",
      "Epoch 20/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.8976 - mae: 9.2700 - val_loss: 60.9573 - val_mae: 5.5671\n",
      "Epoch 21/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.1749 - mae: 9.1647 - val_loss: 59.8594 - val_mae: 5.5744\n",
      "Epoch 22/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.2761 - mae: 9.1645 - val_loss: 66.4234 - val_mae: 5.8927\n",
      "Epoch 23/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.0202 - mae: 8.9113 - val_loss: 73.0474 - val_mae: 6.2627\n",
      "Epoch 24/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.6844 - mae: 8.9405 - val_loss: 69.1358 - val_mae: 6.0392\n",
      "Epoch 25/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.6279 - mae: 8.9929 - val_loss: 79.8761 - val_mae: 6.6146\n",
      "Epoch 26/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.4454 - mae: 9.1910 - val_loss: 65.4056 - val_mae: 5.8124\n",
      "Epoch 27/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.3231 - mae: 9.0400 - val_loss: 66.5639 - val_mae: 5.9110\n",
      "Epoch 28/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.0798 - mae: 9.1116 - val_loss: 60.9235 - val_mae: 5.7113\n",
      "Epoch 29/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.1373 - mae: 8.7521 - val_loss: 64.7309 - val_mae: 5.7694\n",
      "Epoch 30/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.4704 - mae: 9.0609 - val_loss: 59.4790 - val_mae: 5.4930\n",
      "Epoch 31/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.6531 - mae: 8.7407 - val_loss: 72.3698 - val_mae: 6.5434\n",
      "Epoch 32/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.5265 - mae: 8.7878 - val_loss: 61.4320 - val_mae: 5.7780\n",
      "Epoch 33/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.7317 - mae: 8.8641 - val_loss: 62.0974 - val_mae: 5.8078\n",
      "Epoch 34/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.4209 - mae: 8.7132 - val_loss: 59.5734 - val_mae: 5.5979\n",
      "Epoch 35/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.8468 - mae: 8.8998 - val_loss: 60.2732 - val_mae: 5.6229\n",
      "Epoch 36/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.2966 - mae: 8.6419 - val_loss: 71.3450 - val_mae: 6.2327\n",
      "Epoch 37/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.6357 - mae: 8.9603 - val_loss: 64.1458 - val_mae: 6.0302\n",
      "Epoch 38/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.1291 - mae: 9.1124 - val_loss: 58.3373 - val_mae: 5.5225\n",
      "Epoch 39/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.7879 - mae: 8.7593 - val_loss: 69.6722 - val_mae: 6.1387\n",
      "Epoch 40/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.6359 - mae: 8.9126 - val_loss: 63.8606 - val_mae: 6.0547\n",
      "Epoch 41/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.1859 - mae: 8.8597 - val_loss: 61.5310 - val_mae: 5.6047\n",
      "Epoch 42/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.7551 - mae: 8.8415 - val_loss: 60.5931 - val_mae: 5.5598\n",
      "Epoch 43/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.8887 - mae: 8.9340 - val_loss: 58.8297 - val_mae: 5.4863\n",
      "Epoch 44/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.9799 - mae: 8.7085 - val_loss: 64.0535 - val_mae: 5.7919\n",
      "Epoch 45/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.1996 - mae: 8.6180 - val_loss: 62.7122 - val_mae: 5.7291\n",
      "Epoch 46/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.2998 - mae: 8.4749 - val_loss: 56.2729 - val_mae: 5.3775\n",
      "Epoch 47/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.6773 - mae: 8.6770 - val_loss: 72.3959 - val_mae: 6.1986\n",
      "Epoch 48/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.3441 - mae: 8.6716 - val_loss: 61.9505 - val_mae: 5.8081\n",
      "Epoch 49/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.8500 - mae: 8.6844 - val_loss: 61.2668 - val_mae: 5.7316\n",
      "Epoch 50/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.5208 - mae: 8.2557 - val_loss: 60.8048 - val_mae: 5.7052\n",
      "Epoch 51/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.5237 - mae: 8.6204 - val_loss: 66.3858 - val_mae: 5.8651\n",
      "Epoch 52/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.5103 - mae: 8.6204 - val_loss: 70.8488 - val_mae: 6.2428\n",
      "Epoch 53/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.6358 - mae: 8.7164 - val_loss: 63.1332 - val_mae: 5.7038\n",
      "Epoch 54/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.2686 - mae: 8.5423 - val_loss: 57.8951 - val_mae: 5.5880\n",
      "Epoch 55/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.4884 - mae: 8.4723 - val_loss: 60.9279 - val_mae: 5.8522\n",
      "Epoch 56/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.9548 - mae: 8.4910 - val_loss: 61.5324 - val_mae: 5.6348\n",
      "Epoch 57/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.2331 - mae: 8.2311 - val_loss: 56.1834 - val_mae: 5.3584\n",
      "Epoch 58/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.8886 - mae: 8.3714 - val_loss: 56.0343 - val_mae: 5.4044\n",
      "Epoch 59/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.9463 - mae: 8.4322 - val_loss: 56.1870 - val_mae: 5.4120\n",
      "Epoch 60/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.2644 - mae: 8.3737 - val_loss: 56.2136 - val_mae: 5.3757\n",
      "Epoch 61/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.7741 - mae: 8.4848 - val_loss: 56.1215 - val_mae: 5.3558\n",
      "Epoch 62/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.3568 - mae: 8.2242 - val_loss: 56.9597 - val_mae: 5.4662\n",
      "Epoch 63/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.5009 - mae: 8.2545 - val_loss: 55.9313 - val_mae: 5.4667\n",
      "Epoch 64/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.7882 - mae: 8.2546 - val_loss: 56.7378 - val_mae: 5.4013\n",
      "Epoch 65/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.0378 - mae: 8.4112 - val_loss: 57.4304 - val_mae: 5.4553\n",
      "Epoch 66/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.1710 - mae: 8.1588 - val_loss: 56.6826 - val_mae: 5.4350\n",
      "Epoch 67/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.6956 - mae: 8.3400 - val_loss: 59.3922 - val_mae: 5.5839\n",
      "Epoch 68/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.2604 - mae: 8.4681 - val_loss: 55.6803 - val_mae: 5.3461\n",
      "Epoch 69/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.0233 - mae: 8.0725 - val_loss: 54.3989 - val_mae: 5.2950\n",
      "Epoch 70/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.4006 - mae: 8.0652 - val_loss: 55.8622 - val_mae: 5.3558\n",
      "Epoch 71/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.5896 - mae: 8.2639 - val_loss: 59.7250 - val_mae: 5.5867\n",
      "Epoch 72/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.5364 - mae: 8.4267 - val_loss: 62.4732 - val_mae: 5.7271\n",
      "Epoch 73/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.6224 - mae: 8.2119 - val_loss: 57.4528 - val_mae: 5.4621\n",
      "Epoch 74/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.4119 - mae: 8.1949 - val_loss: 57.8642 - val_mae: 5.5256\n",
      "Epoch 75/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.5383 - mae: 8.2160 - val_loss: 58.0037 - val_mae: 5.5028\n",
      "Epoch 76/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114.1734 - mae: 8.1354 - val_loss: 54.8845 - val_mae: 5.3615\n",
      "Epoch 77/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.7519 - mae: 8.1603 - val_loss: 59.6924 - val_mae: 5.7793\n",
      "Epoch 78/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.9564 - mae: 8.2229 - val_loss: 66.1651 - val_mae: 5.9947\n",
      "Epoch 79/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.7743 - mae: 8.0821 - val_loss: 57.8492 - val_mae: 5.5219\n",
      "Epoch 80/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 121.5895 - mae: 8.3098 - val_loss: 57.1729 - val_mae: 5.4331\n",
      "Epoch 81/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.7480 - mae: 8.1248 - val_loss: 56.2274 - val_mae: 5.3311\n",
      "Epoch 82/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.6983 - mae: 7.8996 - val_loss: 64.8114 - val_mae: 5.8653\n",
      "Epoch 83/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.7092 - mae: 7.9762 - val_loss: 58.5708 - val_mae: 5.5954\n",
      "Epoch 84/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.0768 - mae: 8.1972 - val_loss: 57.0597 - val_mae: 5.3841\n",
      "Epoch 85/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.7555 - mae: 8.0068 - val_loss: 62.3917 - val_mae: 5.9966\n",
      "Epoch 86/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.1946 - mae: 8.0733 - val_loss: 53.7773 - val_mae: 5.2944\n",
      "Epoch 87/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.4867 - mae: 8.0513 - val_loss: 56.8652 - val_mae: 5.4509\n",
      "Epoch 88/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.2062 - mae: 8.0865 - val_loss: 54.3334 - val_mae: 5.3810\n",
      "Epoch 89/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 120.1208 - mae: 8.1533 - val_loss: 55.3819 - val_mae: 5.3781\n",
      "Epoch 90/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 105.1972 - mae: 7.7729 - val_loss: 55.9068 - val_mae: 5.5080\n",
      "Epoch 91/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 111.3778 - mae: 8.0446 - val_loss: 59.7653 - val_mae: 5.5694\n",
      "Epoch 92/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.0391 - mae: 7.9527 - val_loss: 55.5927 - val_mae: 5.4241\n",
      "Epoch 93/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 106.7832 - mae: 7.8180 - val_loss: 55.6544 - val_mae: 5.3915\n",
      "Epoch 94/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.7158 - mae: 8.0048 - val_loss: 54.9867 - val_mae: 5.3602\n",
      "Epoch 95/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110.8228 - mae: 7.8946 - val_loss: 62.1729 - val_mae: 5.6910\n",
      "Epoch 96/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110.8607 - mae: 7.9217 - val_loss: 62.6807 - val_mae: 5.7369\n",
      "Epoch 97/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107.8352 - mae: 7.8832 - val_loss: 57.4764 - val_mae: 5.4490\n",
      "Epoch 98/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.0046 - mae: 8.0924 - val_loss: 60.8708 - val_mae: 5.8163\n",
      "Epoch 99/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.6750 - mae: 7.9215 - val_loss: 52.6904 - val_mae: 5.2068\n",
      "Epoch 100/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109.0654 - mae: 7.9125 - val_loss: 52.3878 - val_mae: 5.1573\n",
      "Epoch 101/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.3790 - mae: 7.8317 - val_loss: 59.0909 - val_mae: 5.7868\n",
      "Epoch 102/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.2828 - mae: 7.9259 - val_loss: 61.4036 - val_mae: 5.6920\n",
      "Epoch 103/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 103.9728 - mae: 7.7182 - val_loss: 52.5910 - val_mae: 5.1553\n",
      "Epoch 104/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.4870 - mae: 8.0030 - val_loss: 63.8639 - val_mae: 5.7759\n",
      "Epoch 105/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.8553 - mae: 8.0311 - val_loss: 53.9103 - val_mae: 5.2559\n",
      "Epoch 106/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107.0489 - mae: 7.9023 - val_loss: 55.3285 - val_mae: 5.4516\n",
      "Epoch 107/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.7738 - mae: 7.9119 - val_loss: 64.8877 - val_mae: 5.8715\n",
      "Epoch 108/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.4108 - mae: 7.9212 - val_loss: 54.2766 - val_mae: 5.3201\n",
      "Epoch 109/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107.7643 - mae: 7.8349 - val_loss: 53.1108 - val_mae: 5.2489\n",
      "Epoch 110/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110.9212 - mae: 7.9277 - val_loss: 61.5772 - val_mae: 5.7120\n",
      "Epoch 111/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 106.3355 - mae: 7.7894 - val_loss: 56.8477 - val_mae: 5.3909\n",
      "Epoch 112/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100.6669 - mae: 7.6545 - val_loss: 69.9353 - val_mae: 6.1553\n",
      "Epoch 113/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 105.3271 - mae: 7.7627 - val_loss: 58.1958 - val_mae: 5.6017\n",
      "Epoch 114/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.4386 - mae: 7.8226 - val_loss: 54.8186 - val_mae: 5.2966\n",
      "Epoch 115/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109.9494 - mae: 7.8619 - val_loss: 56.1884 - val_mae: 5.5487\n",
      "Epoch 116/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.2649 - mae: 7.6764 - val_loss: 53.5242 - val_mae: 5.2181\n",
      "Epoch 117/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 105.5700 - mae: 7.7701 - val_loss: 59.7855 - val_mae: 5.8021\n",
      "Epoch 118/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 101.5337 - mae: 7.6864 - val_loss: 59.5065 - val_mae: 5.6472\n",
      "Epoch 119/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 99.4504 - mae: 7.5752 - val_loss: 61.8343 - val_mae: 5.7533\n",
      "Epoch 120/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.6866 - mae: 7.6490 - val_loss: 52.6423 - val_mae: 5.1942\n",
      "Epoch 121/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.1696 - mae: 8.0166 - val_loss: 53.9747 - val_mae: 5.3747\n",
      "Epoch 122/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107.1028 - mae: 7.8797 - val_loss: 58.4786 - val_mae: 5.6056\n",
      "Epoch 123/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 97.9120 - mae: 7.4526 - val_loss: 55.0088 - val_mae: 5.3289\n",
      "Epoch 124/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.3879 - mae: 7.6072 - val_loss: 54.3548 - val_mae: 5.2705\n",
      "Epoch 125/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.9440 - mae: 7.9192 - val_loss: 57.8458 - val_mae: 5.4424\n",
      "Epoch 126/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.9058 - mae: 7.7693 - val_loss: 54.5224 - val_mae: 5.2873\n",
      "Epoch 127/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.0496 - mae: 7.9853 - val_loss: 61.4746 - val_mae: 5.6382\n",
      "Epoch 128/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109.1503 - mae: 7.8623 - val_loss: 57.4559 - val_mae: 5.6501\n",
      "Epoch 129/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.6195 - mae: 7.9459 - val_loss: 54.4904 - val_mae: 5.3929\n",
      "Epoch 130/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.3141 - mae: 7.7949 - val_loss: 55.2363 - val_mae: 5.3620\n",
      "Epoch 131/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 101.7634 - mae: 7.6889 - val_loss: 53.0283 - val_mae: 5.2670\n",
      "Epoch 132/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107.8230 - mae: 7.7958 - val_loss: 55.9130 - val_mae: 5.4109\n",
      "Epoch 133/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 102.3778 - mae: 7.6096 - val_loss: 58.3973 - val_mae: 5.5260\n",
      "Epoch 134/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 106.9485 - mae: 7.8086 - val_loss: 54.4447 - val_mae: 5.3160\n",
      "Epoch 135/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 105.9583 - mae: 7.6770 - val_loss: 52.7980 - val_mae: 5.2239\n",
      "Epoch 136/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.5047 - mae: 7.8488 - val_loss: 59.8698 - val_mae: 5.7329\n",
      "Epoch 137/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 106.3720 - mae: 7.7269 - val_loss: 51.8532 - val_mae: 5.1465\n",
      "Epoch 138/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 106.8113 - mae: 7.8125 - val_loss: 53.5008 - val_mae: 5.2225\n",
      "Epoch 139/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107.9910 - mae: 7.8920 - val_loss: 51.7592 - val_mae: 5.1197\n",
      "Epoch 140/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 101.4261 - mae: 7.5719 - val_loss: 64.8934 - val_mae: 5.9356\n",
      "Epoch 141/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.6034 - mae: 7.7689 - val_loss: 68.8783 - val_mae: 6.0489\n",
      "Epoch 142/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 105.4499 - mae: 7.7258 - val_loss: 54.1349 - val_mae: 5.2753\n",
      "Epoch 143/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 98.8528 - mae: 7.4947 - val_loss: 56.1409 - val_mae: 5.4149\n",
      "Epoch 144/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 106.4399 - mae: 7.6448 - val_loss: 51.3458 - val_mae: 5.0749\n",
      "Epoch 145/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 103.4374 - mae: 7.6410 - val_loss: 53.8421 - val_mae: 5.2623\n",
      "Epoch 146/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 103.4164 - mae: 7.5824 - val_loss: 56.6678 - val_mae: 5.5629\n",
      "Epoch 147/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 98.9417 - mae: 7.5555 - val_loss: 54.5953 - val_mae: 5.3182\n",
      "Epoch 148/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 98.8206 - mae: 7.4460 - val_loss: 59.7700 - val_mae: 5.9081\n",
      "Epoch 149/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 97.9305 - mae: 7.4650 - val_loss: 51.1310 - val_mae: 5.0696\n",
      "Epoch 150/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110.4058 - mae: 7.9193 - val_loss: 51.6488 - val_mae: 5.2088\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.8855 - mae: 5.2644\n",
      "Patience 40: Validation MAE: 5.07\n",
      "Patience 40: Validation Loss: 51.13\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 618.8251 - mae: 18.3632 - val_loss: 133.7070 - val_mae: 9.0855\n",
      "Epoch 2/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 214.8693 - mae: 11.4592 - val_loss: 109.8668 - val_mae: 8.8330\n",
      "Epoch 3/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 192.3908 - mae: 10.8943 - val_loss: 70.1334 - val_mae: 6.3039\n",
      "Epoch 4/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158.2427 - mae: 9.6997 - val_loss: 67.8470 - val_mae: 5.9388\n",
      "Epoch 5/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 148.7661 - mae: 9.3746 - val_loss: 67.5789 - val_mae: 5.8604\n",
      "Epoch 6/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.5916 - mae: 9.3585 - val_loss: 61.1172 - val_mae: 5.5691\n",
      "Epoch 7/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.0682 - mae: 9.2279 - val_loss: 121.4745 - val_mae: 8.5363\n",
      "Epoch 8/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 161.2916 - mae: 9.7720 - val_loss: 62.9866 - val_mae: 5.6054\n",
      "Epoch 9/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 140.6115 - mae: 9.0648 - val_loss: 63.2113 - val_mae: 5.7459\n",
      "Epoch 10/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.9129 - mae: 9.2581 - val_loss: 61.1061 - val_mae: 5.6085\n",
      "Epoch 11/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142.8489 - mae: 9.1367 - val_loss: 84.3466 - val_mae: 6.9643\n",
      "Epoch 12/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.8354 - mae: 9.1875 - val_loss: 62.1855 - val_mae: 5.7992\n",
      "Epoch 13/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.4036 - mae: 9.0258 - val_loss: 62.0659 - val_mae: 5.5283\n",
      "Epoch 14/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 140.0418 - mae: 9.1475 - val_loss: 71.7393 - val_mae: 6.1353\n",
      "Epoch 15/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.2337 - mae: 9.0306 - val_loss: 67.3646 - val_mae: 5.8903\n",
      "Epoch 16/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.2505 - mae: 8.8893 - val_loss: 69.5474 - val_mae: 6.0599\n",
      "Epoch 17/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.5373 - mae: 9.0925 - val_loss: 62.9082 - val_mae: 5.6516\n",
      "Epoch 18/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.3867 - mae: 9.0608 - val_loss: 109.2968 - val_mae: 8.1872\n",
      "Epoch 19/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.9667 - mae: 8.8380 - val_loss: 58.6204 - val_mae: 5.3907\n",
      "Epoch 20/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.2453 - mae: 8.9786 - val_loss: 68.1051 - val_mae: 5.9090\n",
      "Epoch 21/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.2950 - mae: 8.9304 - val_loss: 56.4540 - val_mae: 5.3227\n",
      "Epoch 22/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.1884 - mae: 8.8504 - val_loss: 57.2906 - val_mae: 5.4587\n",
      "Epoch 23/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.6406 - mae: 9.2017 - val_loss: 68.4372 - val_mae: 5.9264\n",
      "Epoch 24/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.1281 - mae: 8.8764 - val_loss: 57.0173 - val_mae: 5.4012\n",
      "Epoch 25/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.6883 - mae: 8.9347 - val_loss: 61.9403 - val_mae: 5.6643\n",
      "Epoch 26/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135.2752 - mae: 8.8191 - val_loss: 57.9100 - val_mae: 5.4054\n",
      "Epoch 27/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.8289 - mae: 8.6498 - val_loss: 58.2144 - val_mae: 5.4674\n",
      "Epoch 28/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.8132 - mae: 8.6428 - val_loss: 62.0969 - val_mae: 5.6394\n",
      "Epoch 29/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.0249 - mae: 8.9378 - val_loss: 57.2343 - val_mae: 5.4435\n",
      "Epoch 30/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.2320 - mae: 9.0521 - val_loss: 56.9914 - val_mae: 5.3366\n",
      "Epoch 31/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.7047 - mae: 8.6380 - val_loss: 71.2540 - val_mae: 6.1232\n",
      "Epoch 32/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138.2224 - mae: 8.9950 - val_loss: 68.9819 - val_mae: 5.9691\n",
      "Epoch 33/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.5699 - mae: 8.5880 - val_loss: 60.3900 - val_mae: 5.7195\n",
      "Epoch 34/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 136.3442 - mae: 8.9378 - val_loss: 70.7463 - val_mae: 6.1771\n",
      "Epoch 35/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.2646 - mae: 8.7553 - val_loss: 60.4605 - val_mae: 5.6456\n",
      "Epoch 36/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 121.4600 - mae: 8.3817 - val_loss: 72.0710 - val_mae: 6.1410\n",
      "Epoch 37/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.9119 - mae: 8.7060 - val_loss: 58.7327 - val_mae: 5.6016\n",
      "Epoch 38/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 131.6399 - mae: 8.8889 - val_loss: 83.3930 - val_mae: 6.9073\n",
      "Epoch 39/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.2521 - mae: 8.5900 - val_loss: 56.2303 - val_mae: 5.3307\n",
      "Epoch 40/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.3591 - mae: 8.7374 - val_loss: 61.0963 - val_mae: 5.5552\n",
      "Epoch 41/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.8026 - mae: 8.3924 - val_loss: 66.5535 - val_mae: 5.8991\n",
      "Epoch 42/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.4737 - mae: 8.6018 - val_loss: 82.2851 - val_mae: 6.7263\n",
      "Epoch 43/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.2094 - mae: 8.6386 - val_loss: 68.5175 - val_mae: 6.1083\n",
      "Epoch 44/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.6387 - mae: 8.5758 - val_loss: 58.4531 - val_mae: 5.3748\n",
      "Epoch 45/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.9841 - mae: 8.5157 - val_loss: 58.7292 - val_mae: 5.4186\n",
      "Epoch 46/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.0679 - mae: 8.5364 - val_loss: 55.5447 - val_mae: 5.3001\n",
      "Epoch 47/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.9342 - mae: 8.7033 - val_loss: 54.8134 - val_mae: 5.2679\n",
      "Epoch 48/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.8521 - mae: 8.6126 - val_loss: 61.3110 - val_mae: 5.7999\n",
      "Epoch 49/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.5492 - mae: 8.7078 - val_loss: 58.3335 - val_mae: 5.5416\n",
      "Epoch 50/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.5388 - mae: 8.6625 - val_loss: 57.6507 - val_mae: 5.5046\n",
      "Epoch 51/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.9963 - mae: 8.4303 - val_loss: 60.1091 - val_mae: 5.7177\n",
      "Epoch 52/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.8254 - mae: 8.5176 - val_loss: 57.3860 - val_mae: 5.5451\n",
      "Epoch 53/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.0120 - mae: 8.4432 - val_loss: 57.9705 - val_mae: 5.4674\n",
      "Epoch 54/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.8068 - mae: 8.4965 - val_loss: 56.5608 - val_mae: 5.3591\n",
      "Epoch 55/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.0574 - mae: 8.4384 - val_loss: 57.0378 - val_mae: 5.4578\n",
      "Epoch 56/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.1950 - mae: 8.3952 - val_loss: 82.0734 - val_mae: 6.8745\n",
      "Epoch 57/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127.4066 - mae: 8.6199 - val_loss: 57.4194 - val_mae: 5.4882\n",
      "Epoch 58/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.1304 - mae: 8.7333 - val_loss: 55.7136 - val_mae: 5.2979\n",
      "Epoch 59/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.9371 - mae: 8.7475 - val_loss: 55.4251 - val_mae: 5.3182\n",
      "Epoch 60/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.8970 - mae: 8.3237 - val_loss: 59.8040 - val_mae: 5.4854\n",
      "Epoch 61/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 119.8768 - mae: 8.3397 - val_loss: 65.5011 - val_mae: 5.8085\n",
      "Epoch 62/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 118.8392 - mae: 8.2685 - val_loss: 56.1904 - val_mae: 5.3594\n",
      "Epoch 63/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.4256 - mae: 8.5215 - val_loss: 55.7101 - val_mae: 5.3764\n",
      "Epoch 64/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.0730 - mae: 8.4340 - val_loss: 57.5322 - val_mae: 5.4237\n",
      "Epoch 65/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.5680 - mae: 8.1348 - val_loss: 55.7209 - val_mae: 5.2785\n",
      "Epoch 66/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.8268 - mae: 8.3451 - val_loss: 57.7033 - val_mae: 5.5468\n",
      "Epoch 67/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.3256 - mae: 8.3754 - val_loss: 56.0906 - val_mae: 5.3503\n",
      "Epoch 68/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.8823 - mae: 8.1444 - val_loss: 59.1150 - val_mae: 5.5890\n",
      "Epoch 69/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.9504 - mae: 8.3581 - val_loss: 57.6245 - val_mae: 5.4413\n",
      "Epoch 70/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.3837 - mae: 8.1498 - val_loss: 55.6207 - val_mae: 5.3543\n",
      "Epoch 71/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.9036 - mae: 8.3398 - val_loss: 58.2266 - val_mae: 5.6008\n",
      "Epoch 72/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.0990 - mae: 8.0198 - val_loss: 57.5266 - val_mae: 5.4349\n",
      "Epoch 73/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.8481 - mae: 8.2034 - val_loss: 55.9331 - val_mae: 5.2722\n",
      "Epoch 74/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.1155 - mae: 8.2111 - val_loss: 61.5195 - val_mae: 5.7079\n",
      "Epoch 75/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.7946 - mae: 8.2275 - val_loss: 56.4729 - val_mae: 5.3282\n",
      "Epoch 76/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.3547 - mae: 8.2485 - val_loss: 56.9516 - val_mae: 5.3434\n",
      "Epoch 77/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.5741 - mae: 8.3931 - val_loss: 60.3548 - val_mae: 5.5693\n",
      "Patience 30: Early stopping occurred at epoch 76\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61.1990 - mae: 5.4078\n",
      "Patience 30: Validation MAE: 5.27\n",
      "Patience 30: Validation Loss: 54.81\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 702.0585 - mae: 19.4053 - val_loss: 181.0675 - val_mae: 9.9518\n",
      "Epoch 2/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240.6061 - mae: 12.2388 - val_loss: 126.3651 - val_mae: 9.0460\n",
      "Epoch 3/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 212.5040 - mae: 11.4429 - val_loss: 98.8065 - val_mae: 7.6978\n",
      "Epoch 4/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.4992 - mae: 10.8357 - val_loss: 80.2612 - val_mae: 6.8257\n",
      "Epoch 5/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 174.2190 - mae: 10.2870 - val_loss: 74.6474 - val_mae: 6.6534\n",
      "Epoch 6/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165.6481 - mae: 9.9128 - val_loss: 75.8219 - val_mae: 6.6707\n",
      "Epoch 7/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156.1864 - mae: 9.6989 - val_loss: 65.3404 - val_mae: 5.8496\n",
      "Epoch 8/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157.0666 - mae: 9.5329 - val_loss: 69.4001 - val_mae: 6.2163\n",
      "Epoch 9/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.2065 - mae: 9.4750 - val_loss: 75.0593 - val_mae: 6.6962\n",
      "Epoch 10/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148.6235 - mae: 9.3097 - val_loss: 70.8884 - val_mae: 6.3948\n",
      "Epoch 11/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.2627 - mae: 9.2895 - val_loss: 65.1148 - val_mae: 5.9634\n",
      "Epoch 12/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.8925 - mae: 9.1926 - val_loss: 86.2524 - val_mae: 6.8417\n",
      "Epoch 13/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.0536 - mae: 9.4319 - val_loss: 76.7492 - val_mae: 6.2384\n",
      "Epoch 14/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.2641 - mae: 9.1101 - val_loss: 67.5796 - val_mae: 5.8756\n",
      "Epoch 15/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142.4819 - mae: 9.1952 - val_loss: 78.7706 - val_mae: 6.4822\n",
      "Epoch 16/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.9714 - mae: 9.2960 - val_loss: 65.3549 - val_mae: 5.7303\n",
      "Epoch 17/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 142.0007 - mae: 9.0772 - val_loss: 61.3192 - val_mae: 5.6080\n",
      "Epoch 18/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163.2170 - mae: 9.8616 - val_loss: 70.1136 - val_mae: 6.0129\n",
      "Epoch 19/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.0336 - mae: 9.0156 - val_loss: 64.5087 - val_mae: 5.7029\n",
      "Epoch 20/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.7435 - mae: 9.2100 - val_loss: 67.6329 - val_mae: 5.9469\n",
      "Epoch 21/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.3914 - mae: 9.1307 - val_loss: 59.7791 - val_mae: 5.5428\n",
      "Epoch 22/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135.0459 - mae: 8.9503 - val_loss: 64.0287 - val_mae: 5.7765\n",
      "Epoch 23/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.5155 - mae: 8.9012 - val_loss: 64.4417 - val_mae: 5.6784\n",
      "Epoch 24/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.1185 - mae: 9.3048 - val_loss: 68.3485 - val_mae: 6.1911\n",
      "Epoch 25/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.5095 - mae: 8.8242 - val_loss: 61.2312 - val_mae: 5.7208\n",
      "Epoch 26/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134.6258 - mae: 8.9015 - val_loss: 58.3394 - val_mae: 5.4970\n",
      "Epoch 27/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.6612 - mae: 8.9748 - val_loss: 62.4433 - val_mae: 5.5870\n",
      "Epoch 28/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.3142 - mae: 9.0275 - val_loss: 61.9996 - val_mae: 5.6042\n",
      "Epoch 29/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.8477 - mae: 8.9941 - val_loss: 60.2264 - val_mae: 5.5505\n",
      "Epoch 30/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138.0798 - mae: 9.0105 - val_loss: 59.2663 - val_mae: 5.5467\n",
      "Epoch 31/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.1648 - mae: 9.0498 - val_loss: 63.9340 - val_mae: 5.6749\n",
      "Epoch 32/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.3130 - mae: 9.0348 - val_loss: 90.4354 - val_mae: 7.1825\n",
      "Epoch 33/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.0899 - mae: 9.0214 - val_loss: 64.2263 - val_mae: 5.7308\n",
      "Epoch 34/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.4193 - mae: 8.8284 - val_loss: 59.1654 - val_mae: 5.6259\n",
      "Epoch 35/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.8602 - mae: 8.6859 - val_loss: 75.2983 - val_mae: 6.3943\n",
      "Epoch 36/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.4534 - mae: 8.7009 - val_loss: 68.2771 - val_mae: 6.0150\n",
      "Epoch 37/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.1423 - mae: 8.8287 - val_loss: 63.2710 - val_mae: 5.7153\n",
      "Epoch 38/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.4810 - mae: 8.7723 - val_loss: 82.9783 - val_mae: 6.9007\n",
      "Epoch 39/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.7344 - mae: 9.0673 - val_loss: 76.0530 - val_mae: 6.5326\n",
      "Epoch 40/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.5200 - mae: 8.8519 - val_loss: 64.7703 - val_mae: 5.7532\n",
      "Epoch 41/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.3305 - mae: 8.9761 - val_loss: 66.2662 - val_mae: 5.8904\n",
      "Epoch 42/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 132.9669 - mae: 8.7963 - val_loss: 59.2137 - val_mae: 5.5103\n",
      "Epoch 43/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.9406 - mae: 8.6681 - val_loss: 58.4739 - val_mae: 5.5999\n",
      "Epoch 44/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.5596 - mae: 8.5934 - val_loss: 60.3329 - val_mae: 5.5966\n",
      "Epoch 45/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.1595 - mae: 8.7110 - val_loss: 64.9386 - val_mae: 5.7328\n",
      "Epoch 46/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.4953 - mae: 8.8139 - val_loss: 63.6909 - val_mae: 5.7859\n",
      "Patience 20: Early stopping occurred at epoch 45\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64.9287 - mae: 5.6521\n",
      "Patience 20: Validation MAE: 5.50\n",
      "Patience 20: Validation Loss: 58.34\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 821.6874 - mae: 19.8395 - val_loss: 162.7195 - val_mae: 9.9967\n",
      "Epoch 2/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 265.3344 - mae: 12.8511 - val_loss: 147.7170 - val_mae: 9.0416\n",
      "Epoch 3/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 259.8339 - mae: 12.6080 - val_loss: 129.0415 - val_mae: 8.3033\n",
      "Epoch 4/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.5952 - mae: 11.9923 - val_loss: 121.3163 - val_mae: 8.0004\n",
      "Epoch 5/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.2608 - mae: 11.0298 - val_loss: 79.3035 - val_mae: 6.6084\n",
      "Epoch 6/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180.2407 - mae: 10.3447 - val_loss: 83.4660 - val_mae: 7.1928\n",
      "Epoch 7/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172.1727 - mae: 10.2154 - val_loss: 69.1206 - val_mae: 6.1339\n",
      "Epoch 8/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164.3025 - mae: 9.9955 - val_loss: 68.2533 - val_mae: 5.9124\n",
      "Epoch 9/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174.2647 - mae: 10.0657 - val_loss: 68.4851 - val_mae: 5.9376\n",
      "Epoch 10/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156.1319 - mae: 9.7744 - val_loss: 88.6693 - val_mae: 7.0999\n",
      "Epoch 11/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 172.0333 - mae: 10.0718 - val_loss: 61.4965 - val_mae: 5.7470\n",
      "Epoch 12/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.0694 - mae: 9.5704 - val_loss: 64.2148 - val_mae: 5.7989\n",
      "Epoch 13/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.5350 - mae: 9.5239 - val_loss: 64.1976 - val_mae: 5.8280\n",
      "Epoch 14/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.3387 - mae: 9.5790 - val_loss: 63.6439 - val_mae: 5.6849\n",
      "Epoch 15/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 156.7106 - mae: 9.6395 - val_loss: 83.1833 - val_mae: 6.7698\n",
      "Epoch 16/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.0218 - mae: 9.5155 - val_loss: 84.1521 - val_mae: 6.8855\n",
      "Epoch 17/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163.9043 - mae: 9.8443 - val_loss: 63.3239 - val_mae: 5.8289\n",
      "Epoch 18/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156.2676 - mae: 9.5948 - val_loss: 59.3988 - val_mae: 5.6093\n",
      "Epoch 19/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 151.7327 - mae: 9.4871 - val_loss: 58.4436 - val_mae: 5.5170\n",
      "Epoch 20/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.4208 - mae: 9.3538 - val_loss: 59.7559 - val_mae: 5.6416\n",
      "Epoch 21/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.1138 - mae: 9.4065 - val_loss: 58.9927 - val_mae: 5.5734\n",
      "Epoch 22/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.4682 - mae: 9.3224 - val_loss: 66.1212 - val_mae: 5.9479\n",
      "Epoch 23/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.2441 - mae: 9.3167 - val_loss: 63.3506 - val_mae: 5.8655\n",
      "Epoch 24/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.8740 - mae: 9.3833 - val_loss: 59.6610 - val_mae: 5.6581\n",
      "Epoch 25/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.2724 - mae: 9.3278 - val_loss: 69.1996 - val_mae: 6.3997\n",
      "Epoch 26/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.7752 - mae: 9.3856 - val_loss: 61.7657 - val_mae: 5.7251\n",
      "Epoch 27/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.1021 - mae: 9.3164 - val_loss: 60.6963 - val_mae: 5.6142\n",
      "Epoch 28/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.5858 - mae: 9.1565 - val_loss: 59.8438 - val_mae: 5.6561\n",
      "Epoch 29/150\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.1775 - mae: 9.2698 - val_loss: 62.4909 - val_mae: 5.6250\n",
      "Patience 10: Early stopping occurred at epoch 28\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66.7682 - mae: 5.7020 \n",
      "Patience 10: Validation MAE: 5.52\n",
      "Patience 10: Validation Loss: 58.44\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 51.1310, MAE = 5.0696, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 54.8134, MAE = 5.2679, Early Stopping Occurred: True, Early Stopping Epoch: 76\n",
      "Patience 20: Loss = 58.3394, MAE = 5.4970, Early Stopping Occurred: True, Early Stopping Epoch: 45\n",
      "Patience 10: Loss = 58.4436, MAE = 5.5170, Early Stopping Occurred: True, Early Stopping Epoch: 28\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "bresults150_1 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    dbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    dbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'best_model_{patience}.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = dbp_model.fit(\n",
    "        X_train_combined, DBP_Y_train_combined,\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_combined, DBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = dbp_model.evaluate(X_test_combined, DBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    bresults150_1.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    # 학습 및 검증 손실 그래프 시각화\n",
    "    # plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.title(f'Patience = {patience}')\n",
    "    # plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in bresults150_1:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 432.1176 - mae: 15.4776 - val_loss: 116.5427 - val_mae: 8.2795\n",
      "Epoch 2/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 196.1088 - mae: 11.0207 - val_loss: 79.7958 - val_mae: 7.0491\n",
      "Epoch 3/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 167.6366 - mae: 10.0111 - val_loss: 160.6591 - val_mae: 10.2487\n",
      "Epoch 4/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154.5564 - mae: 9.4862 - val_loss: 69.1551 - val_mae: 6.0946\n",
      "Epoch 5/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.1142 - mae: 8.9874 - val_loss: 67.0564 - val_mae: 5.8848\n",
      "Epoch 6/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145.7617 - mae: 9.3264 - val_loss: 72.4160 - val_mae: 6.1653\n",
      "Epoch 7/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.8107 - mae: 8.9881 - val_loss: 73.6631 - val_mae: 6.1933\n",
      "Epoch 8/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.9891 - mae: 8.7376 - val_loss: 65.5623 - val_mae: 5.9827\n",
      "Epoch 9/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148.2091 - mae: 9.3066 - val_loss: 68.4768 - val_mae: 5.8424\n",
      "Epoch 10/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.9860 - mae: 9.0996 - val_loss: 77.9334 - val_mae: 6.6701\n",
      "Epoch 11/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.6933 - mae: 8.8962 - val_loss: 62.4705 - val_mae: 5.6489\n",
      "Epoch 12/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.1037 - mae: 8.9391 - val_loss: 76.3270 - val_mae: 6.2899\n",
      "Epoch 13/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135.6236 - mae: 8.8546 - val_loss: 61.2428 - val_mae: 5.5755\n",
      "Epoch 14/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.6356 - mae: 8.8368 - val_loss: 63.0431 - val_mae: 5.7206\n",
      "Epoch 15/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.4601 - mae: 8.7539 - val_loss: 68.9903 - val_mae: 6.1744\n",
      "Epoch 16/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.9586 - mae: 8.9455 - val_loss: 59.6648 - val_mae: 5.4953\n",
      "Epoch 17/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.2765 - mae: 8.8005 - val_loss: 72.0859 - val_mae: 6.2228\n",
      "Epoch 18/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134.7371 - mae: 8.8198 - val_loss: 60.1578 - val_mae: 5.5977\n",
      "Epoch 19/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.2053 - mae: 8.5742 - val_loss: 81.1099 - val_mae: 6.5726\n",
      "Epoch 20/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.3959 - mae: 8.6172 - val_loss: 74.2098 - val_mae: 6.3092\n",
      "Epoch 21/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.2991 - mae: 8.7517 - val_loss: 129.9348 - val_mae: 9.3654\n",
      "Epoch 22/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.9152 - mae: 8.6823 - val_loss: 68.4907 - val_mae: 5.9610\n",
      "Epoch 23/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.9411 - mae: 8.4771 - val_loss: 84.7895 - val_mae: 7.3585\n",
      "Epoch 24/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.2947 - mae: 8.6273 - val_loss: 62.0136 - val_mae: 5.6086\n",
      "Epoch 25/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.4882 - mae: 8.4309 - val_loss: 57.9642 - val_mae: 5.4774\n",
      "Epoch 26/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120.3501 - mae: 8.4027 - val_loss: 58.4017 - val_mae: 5.3973\n",
      "Epoch 27/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.7345 - mae: 8.2062 - val_loss: 58.1520 - val_mae: 5.4959\n",
      "Epoch 28/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.3695 - mae: 8.1200 - val_loss: 60.2202 - val_mae: 5.5417\n",
      "Epoch 29/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.4257 - mae: 8.4422 - val_loss: 58.9223 - val_mae: 5.4336\n",
      "Epoch 30/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.4208 - mae: 8.4014 - val_loss: 66.9962 - val_mae: 5.8226\n",
      "Epoch 31/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118.7431 - mae: 8.2469 - val_loss: 56.9613 - val_mae: 5.3222\n",
      "Epoch 32/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.6770 - mae: 8.5202 - val_loss: 56.5488 - val_mae: 5.3770\n",
      "Epoch 33/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.7351 - mae: 8.3722 - val_loss: 68.6602 - val_mae: 5.9009\n",
      "Epoch 34/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.4004 - mae: 8.2552 - val_loss: 60.9674 - val_mae: 5.5040\n",
      "Epoch 35/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.2659 - mae: 8.1528 - val_loss: 57.0397 - val_mae: 5.4197\n",
      "Epoch 36/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.5798 - mae: 8.3656 - val_loss: 63.4787 - val_mae: 5.6740\n",
      "Epoch 37/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.2664 - mae: 8.1000 - val_loss: 58.8044 - val_mae: 5.4258\n",
      "Epoch 38/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118.0924 - mae: 8.3378 - val_loss: 56.6357 - val_mae: 5.4041\n",
      "Epoch 39/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.0217 - mae: 8.2728 - val_loss: 58.8947 - val_mae: 5.4338\n",
      "Epoch 40/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.0266 - mae: 8.1175 - val_loss: 59.7218 - val_mae: 5.5156\n",
      "Epoch 41/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.3666 - mae: 8.0330 - val_loss: 93.0768 - val_mae: 7.2657\n",
      "Epoch 42/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.8483 - mae: 8.3098 - val_loss: 57.4579 - val_mae: 5.4823\n",
      "Epoch 43/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.6964 - mae: 8.3027 - val_loss: 60.1712 - val_mae: 5.5497\n",
      "Epoch 44/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.9528 - mae: 8.1302 - val_loss: 58.8011 - val_mae: 5.4770\n",
      "Epoch 45/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.6440 - mae: 8.0270 - val_loss: 61.7466 - val_mae: 5.6050\n",
      "Epoch 46/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.1363 - mae: 8.0776 - val_loss: 56.1018 - val_mae: 5.3956\n",
      "Epoch 47/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.0641 - mae: 8.1527 - val_loss: 54.3008 - val_mae: 5.2110\n",
      "Epoch 48/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.2424 - mae: 7.8678 - val_loss: 61.4653 - val_mae: 5.7126\n",
      "Epoch 49/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.0055 - mae: 8.0869 - val_loss: 55.9112 - val_mae: 5.2986\n",
      "Epoch 50/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.4099 - mae: 7.7928 - val_loss: 53.8494 - val_mae: 5.2236\n",
      "Epoch 51/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.1144 - mae: 7.8731 - val_loss: 65.4915 - val_mae: 5.8071\n",
      "Epoch 52/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.1115 - mae: 7.8768 - val_loss: 58.3347 - val_mae: 5.4110\n",
      "Epoch 53/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.4700 - mae: 8.0830 - val_loss: 70.0257 - val_mae: 6.1030\n",
      "Epoch 54/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.4790 - mae: 7.7117 - val_loss: 59.4821 - val_mae: 5.8015\n",
      "Epoch 55/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.9492 - mae: 8.0720 - val_loss: 58.4321 - val_mae: 5.4203\n",
      "Epoch 56/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.2524 - mae: 8.1628 - val_loss: 55.9420 - val_mae: 5.3277\n",
      "Epoch 57/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.3002 - mae: 7.8814 - val_loss: 54.2385 - val_mae: 5.2177\n",
      "Epoch 58/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.2423 - mae: 7.9193 - val_loss: 54.9351 - val_mae: 5.2621\n",
      "Epoch 59/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.4187 - mae: 7.9857 - val_loss: 58.6309 - val_mae: 5.3774\n",
      "Epoch 60/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.7204 - mae: 7.7560 - val_loss: 54.3190 - val_mae: 5.2257\n",
      "Epoch 61/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.0405 - mae: 7.8120 - val_loss: 56.7463 - val_mae: 5.3300\n",
      "Epoch 62/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.9365 - mae: 7.7109 - val_loss: 60.8466 - val_mae: 5.5222\n",
      "Epoch 63/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.8380 - mae: 7.9034 - val_loss: 56.7511 - val_mae: 5.2801\n",
      "Epoch 64/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.3844 - mae: 7.9991 - val_loss: 56.6045 - val_mae: 5.2715\n",
      "Epoch 65/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.9202 - mae: 7.7490 - val_loss: 60.3699 - val_mae: 5.4769\n",
      "Epoch 66/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.4584 - mae: 7.7763 - val_loss: 63.5821 - val_mae: 5.7020\n",
      "Epoch 67/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.5883 - mae: 7.6707 - val_loss: 59.2402 - val_mae: 5.4862\n",
      "Epoch 68/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.4649 - mae: 7.6659 - val_loss: 59.4188 - val_mae: 5.4631\n",
      "Epoch 69/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.3792 - mae: 7.8493 - val_loss: 54.7829 - val_mae: 5.2699\n",
      "Epoch 70/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.5813 - mae: 7.9601 - val_loss: 54.8546 - val_mae: 5.2356\n",
      "Epoch 71/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.3212 - mae: 7.5002 - val_loss: 67.9921 - val_mae: 5.8889\n",
      "Epoch 72/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.4139 - mae: 7.6162 - val_loss: 57.0677 - val_mae: 5.3782\n",
      "Epoch 73/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.0651 - mae: 7.5858 - val_loss: 76.5166 - val_mae: 6.6803\n",
      "Epoch 74/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.9469 - mae: 7.5542 - val_loss: 51.5722 - val_mae: 5.0560\n",
      "Epoch 75/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.2768 - mae: 7.6889 - val_loss: 61.0458 - val_mae: 5.6662\n",
      "Epoch 76/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.9570 - mae: 7.9079 - val_loss: 54.8655 - val_mae: 5.3178\n",
      "Epoch 77/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.2030 - mae: 7.6609 - val_loss: 52.8103 - val_mae: 5.1622\n",
      "Epoch 78/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.8928 - mae: 7.3770 - val_loss: 62.6026 - val_mae: 5.6565\n",
      "Epoch 79/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.4434 - mae: 7.5306 - val_loss: 52.5626 - val_mae: 5.2015\n",
      "Epoch 80/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.8109 - mae: 7.6167 - val_loss: 57.0266 - val_mae: 5.3398\n",
      "Epoch 81/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.5296 - mae: 7.5010 - val_loss: 62.3932 - val_mae: 5.9599\n",
      "Epoch 82/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.6972 - mae: 7.6613 - val_loss: 55.1215 - val_mae: 5.2565\n",
      "Epoch 83/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.9433 - mae: 7.4744 - val_loss: 52.2351 - val_mae: 5.1971\n",
      "Epoch 84/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.8108 - mae: 7.6817 - val_loss: 53.9875 - val_mae: 5.1837\n",
      "Epoch 85/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.3367 - mae: 7.3444 - val_loss: 56.8371 - val_mae: 5.3379\n",
      "Epoch 86/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.0901 - mae: 7.6736 - val_loss: 77.7962 - val_mae: 6.5476\n",
      "Epoch 87/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.6217 - mae: 7.6295 - val_loss: 55.6881 - val_mae: 5.3540\n",
      "Epoch 88/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.3332 - mae: 7.6874 - val_loss: 62.8847 - val_mae: 5.7513\n",
      "Epoch 89/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.0334 - mae: 7.6040 - val_loss: 55.6236 - val_mae: 5.3101\n",
      "Epoch 90/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.7345 - mae: 7.6021 - val_loss: 57.2815 - val_mae: 5.4112\n",
      "Epoch 91/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.6397 - mae: 7.4645 - val_loss: 57.5566 - val_mae: 5.4202\n",
      "Epoch 92/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.3640 - mae: 7.4693 - val_loss: 53.4558 - val_mae: 5.1590\n",
      "Epoch 93/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.4049 - mae: 7.4206 - val_loss: 59.8589 - val_mae: 5.6617\n",
      "Epoch 94/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.0041 - mae: 7.5183 - val_loss: 52.4274 - val_mae: 5.1073\n",
      "Epoch 95/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.3089 - mae: 7.3800 - val_loss: 54.4062 - val_mae: 5.1789\n",
      "Epoch 96/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.8409 - mae: 7.5688 - val_loss: 65.3964 - val_mae: 5.7126\n",
      "Epoch 97/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.7771 - mae: 7.2925 - val_loss: 53.6640 - val_mae: 5.2169\n",
      "Epoch 98/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.7920 - mae: 7.3202 - val_loss: 55.3061 - val_mae: 5.2700\n",
      "Epoch 99/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.2412 - mae: 7.1946 - val_loss: 54.5859 - val_mae: 5.2723\n",
      "Epoch 100/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.0129 - mae: 7.3417 - val_loss: 59.0749 - val_mae: 5.4930\n",
      "Epoch 101/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.6076 - mae: 7.3422 - val_loss: 54.0006 - val_mae: 5.1603\n",
      "Epoch 102/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.9984 - mae: 7.2950 - val_loss: 54.2618 - val_mae: 5.2675\n",
      "Epoch 103/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.3121 - mae: 7.2293 - val_loss: 58.2107 - val_mae: 5.3855\n",
      "Epoch 104/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.2175 - mae: 7.2619 - val_loss: 55.6834 - val_mae: 5.3309\n",
      "Epoch 105/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.4821 - mae: 7.3489 - val_loss: 73.7246 - val_mae: 6.4997\n",
      "Epoch 106/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.7267 - mae: 7.4330 - val_loss: 52.1143 - val_mae: 5.0675\n",
      "Epoch 107/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 88.8813 - mae: 7.1170 - val_loss: 53.3081 - val_mae: 5.1659\n",
      "Epoch 108/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.2502 - mae: 7.2270 - val_loss: 53.0892 - val_mae: 5.0707\n",
      "Epoch 109/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.4414 - mae: 7.3756 - val_loss: 55.4046 - val_mae: 5.4592\n",
      "Epoch 110/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.1102 - mae: 7.1944 - val_loss: 55.9713 - val_mae: 5.3296\n",
      "Epoch 111/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.1099 - mae: 7.5315 - val_loss: 52.8006 - val_mae: 5.0978\n",
      "Epoch 112/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.9617 - mae: 7.3680 - val_loss: 53.1260 - val_mae: 5.2533\n",
      "Epoch 113/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.2664 - mae: 7.1852 - val_loss: 52.2772 - val_mae: 5.0985\n",
      "Epoch 114/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.0144 - mae: 7.1881 - val_loss: 53.6927 - val_mae: 5.1005\n",
      "Patience 40: Early stopping occurred at epoch 113\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59.0244 - mae: 5.2302 \n",
      "Patience 40: Validation MAE: 5.06\n",
      "Patience 40: Validation Loss: 51.57\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 601.6375 - mae: 17.1025 - val_loss: 138.1674 - val_mae: 9.6939\n",
      "Epoch 2/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 246.7440 - mae: 12.4718 - val_loss: 161.6378 - val_mae: 9.2289\n",
      "Epoch 3/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 221.1175 - mae: 11.5721 - val_loss: 107.8775 - val_mae: 7.4175\n",
      "Epoch 4/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 190.9642 - mae: 10.6369 - val_loss: 75.6417 - val_mae: 6.6044\n",
      "Epoch 5/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 176.1020 - mae: 10.2813 - val_loss: 86.2216 - val_mae: 6.7303\n",
      "Epoch 6/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 166.5064 - mae: 10.0412 - val_loss: 66.6715 - val_mae: 5.9311\n",
      "Epoch 7/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156.7197 - mae: 9.5925 - val_loss: 66.9487 - val_mae: 5.9382\n",
      "Epoch 8/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152.4152 - mae: 9.4581 - val_loss: 63.5799 - val_mae: 5.8411\n",
      "Epoch 9/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 161.9798 - mae: 9.7045 - val_loss: 63.5064 - val_mae: 5.8169\n",
      "Epoch 10/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.9009 - mae: 9.0611 - val_loss: 82.5445 - val_mae: 6.6059\n",
      "Epoch 11/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.6202 - mae: 9.1501 - val_loss: 81.3694 - val_mae: 6.4990\n",
      "Epoch 12/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141.2592 - mae: 9.2044 - val_loss: 71.9688 - val_mae: 6.1807\n",
      "Epoch 13/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.1796 - mae: 9.2056 - val_loss: 62.1419 - val_mae: 5.7600\n",
      "Epoch 14/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139.1128 - mae: 9.0341 - val_loss: 68.3388 - val_mae: 5.9690\n",
      "Epoch 15/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.5699 - mae: 8.9899 - val_loss: 78.9353 - val_mae: 6.8686\n",
      "Epoch 16/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.1301 - mae: 9.1530 - val_loss: 60.4582 - val_mae: 5.5966\n",
      "Epoch 17/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.7325 - mae: 8.9957 - val_loss: 60.2862 - val_mae: 5.6230\n",
      "Epoch 18/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.5674 - mae: 8.8284 - val_loss: 60.9218 - val_mae: 5.6232\n",
      "Epoch 19/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.5797 - mae: 8.8722 - val_loss: 61.5028 - val_mae: 5.6615\n",
      "Epoch 20/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.1662 - mae: 8.8538 - val_loss: 67.7685 - val_mae: 5.9393\n",
      "Epoch 21/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.7155 - mae: 8.7823 - val_loss: 61.2419 - val_mae: 5.7986\n",
      "Epoch 22/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134.8964 - mae: 8.9035 - val_loss: 83.7726 - val_mae: 6.7005\n",
      "Epoch 23/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131.3896 - mae: 8.7014 - val_loss: 69.3462 - val_mae: 5.9744\n",
      "Epoch 24/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.4395 - mae: 8.5755 - val_loss: 59.6774 - val_mae: 5.5414\n",
      "Epoch 25/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.9994 - mae: 8.8625 - val_loss: 58.5035 - val_mae: 5.5239\n",
      "Epoch 26/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145.8075 - mae: 9.1127 - val_loss: 59.0130 - val_mae: 5.5422\n",
      "Epoch 27/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.0226 - mae: 8.6679 - val_loss: 75.0348 - val_mae: 6.3671\n",
      "Epoch 28/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131.9005 - mae: 8.7151 - val_loss: 77.5961 - val_mae: 6.4299\n",
      "Epoch 29/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.9975 - mae: 8.5455 - val_loss: 58.7246 - val_mae: 5.5526\n",
      "Epoch 30/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.5469 - mae: 8.6613 - val_loss: 60.3683 - val_mae: 5.7019\n",
      "Epoch 31/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.9871 - mae: 8.8312 - val_loss: 60.2961 - val_mae: 5.5834\n",
      "Epoch 32/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.5900 - mae: 8.4995 - val_loss: 67.3063 - val_mae: 5.9493\n",
      "Epoch 33/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.3854 - mae: 8.5341 - val_loss: 58.1386 - val_mae: 5.4498\n",
      "Epoch 34/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.7457 - mae: 8.4331 - val_loss: 63.2380 - val_mae: 5.9228\n",
      "Epoch 35/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.9700 - mae: 8.8651 - val_loss: 57.5583 - val_mae: 5.3753\n",
      "Epoch 36/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.6996 - mae: 8.7088 - val_loss: 64.7815 - val_mae: 5.8752\n",
      "Epoch 37/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.8877 - mae: 8.5870 - val_loss: 99.7522 - val_mae: 7.4720\n",
      "Epoch 38/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.4668 - mae: 8.5553 - val_loss: 67.4731 - val_mae: 6.3313\n",
      "Epoch 39/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.6120 - mae: 8.5259 - val_loss: 61.5684 - val_mae: 5.6950\n",
      "Epoch 40/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.6332 - mae: 8.5484 - val_loss: 56.6222 - val_mae: 5.4001\n",
      "Epoch 41/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.5815 - mae: 8.0098 - val_loss: 67.5868 - val_mae: 6.2080\n",
      "Epoch 42/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118.3589 - mae: 8.2162 - val_loss: 61.6061 - val_mae: 5.6362\n",
      "Epoch 43/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.1158 - mae: 8.4130 - val_loss: 61.1043 - val_mae: 5.6614\n",
      "Epoch 44/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.8516 - mae: 8.2912 - val_loss: 65.4895 - val_mae: 5.8219\n",
      "Epoch 45/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.4678 - mae: 8.5056 - val_loss: 59.8183 - val_mae: 5.5826\n",
      "Epoch 46/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.3537 - mae: 8.4101 - val_loss: 59.8715 - val_mae: 5.5015\n",
      "Epoch 47/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.3518 - mae: 8.3059 - val_loss: 58.6216 - val_mae: 5.4611\n",
      "Epoch 48/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.7470 - mae: 8.5207 - val_loss: 61.1851 - val_mae: 5.8563\n",
      "Epoch 49/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.7966 - mae: 8.3538 - val_loss: 60.6695 - val_mae: 5.7436\n",
      "Epoch 50/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118.9861 - mae: 8.2629 - val_loss: 79.8308 - val_mae: 6.5494\n",
      "Epoch 51/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.6163 - mae: 8.3839 - val_loss: 60.4862 - val_mae: 5.7098\n",
      "Epoch 52/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.7582 - mae: 8.2358 - val_loss: 60.7071 - val_mae: 5.6778\n",
      "Epoch 53/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120.0760 - mae: 8.3603 - val_loss: 58.1726 - val_mae: 5.4651\n",
      "Epoch 54/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.4646 - mae: 8.2816 - val_loss: 57.0608 - val_mae: 5.5045\n",
      "Epoch 55/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.5651 - mae: 8.1417 - val_loss: 58.9795 - val_mae: 5.4815\n",
      "Epoch 56/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.4256 - mae: 8.4146 - val_loss: 74.9228 - val_mae: 6.2197\n",
      "Epoch 57/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 120.5676 - mae: 8.3383 - val_loss: 56.6273 - val_mae: 5.3579\n",
      "Epoch 58/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 125.5807 - mae: 8.5488 - val_loss: 57.9967 - val_mae: 5.5739\n",
      "Epoch 59/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.5762 - mae: 8.2508 - val_loss: 58.4536 - val_mae: 5.5411\n",
      "Epoch 60/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.6150 - mae: 8.0966 - val_loss: 55.3011 - val_mae: 5.3774\n",
      "Epoch 61/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.9321 - mae: 8.0732 - val_loss: 71.0032 - val_mae: 6.1720\n",
      "Epoch 62/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.1237 - mae: 8.2159 - val_loss: 57.5754 - val_mae: 5.4844\n",
      "Epoch 63/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.7258 - mae: 8.1440 - val_loss: 57.2714 - val_mae: 5.5655\n",
      "Epoch 64/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.9797 - mae: 8.1499 - val_loss: 56.9661 - val_mae: 5.4640\n",
      "Epoch 65/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114.8436 - mae: 8.1317 - val_loss: 61.7616 - val_mae: 5.6757\n",
      "Epoch 66/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 113.7263 - mae: 8.1083 - val_loss: 56.4958 - val_mae: 5.4552\n",
      "Epoch 67/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.7903 - mae: 7.9722 - val_loss: 55.9773 - val_mae: 5.4153\n",
      "Epoch 68/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.8589 - mae: 8.0422 - val_loss: 58.3977 - val_mae: 5.6863\n",
      "Epoch 69/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.4920 - mae: 8.0943 - val_loss: 57.5335 - val_mae: 5.4047\n",
      "Epoch 70/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.6179 - mae: 8.2846 - val_loss: 57.8820 - val_mae: 5.4968\n",
      "Epoch 71/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.0527 - mae: 8.0192 - val_loss: 55.2670 - val_mae: 5.3439\n",
      "Epoch 72/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.6575 - mae: 7.8851 - val_loss: 70.8239 - val_mae: 6.2439\n",
      "Epoch 73/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.0460 - mae: 8.1167 - val_loss: 56.4474 - val_mae: 5.4041\n",
      "Epoch 74/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.1251 - mae: 7.7232 - val_loss: 54.5607 - val_mae: 5.2473\n",
      "Epoch 75/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.3047 - mae: 7.9835 - val_loss: 57.1293 - val_mae: 5.4573\n",
      "Epoch 76/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.0808 - mae: 8.0306 - val_loss: 65.8162 - val_mae: 5.9517\n",
      "Epoch 77/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.8392 - mae: 8.1493 - val_loss: 56.4499 - val_mae: 5.4992\n",
      "Epoch 78/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.9009 - mae: 8.0044 - val_loss: 65.7100 - val_mae: 5.9852\n",
      "Epoch 79/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 107.7192 - mae: 7.9651 - val_loss: 53.7521 - val_mae: 5.2142\n",
      "Epoch 80/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.0846 - mae: 7.9949 - val_loss: 56.2750 - val_mae: 5.4183\n",
      "Epoch 81/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.6950 - mae: 7.7424 - val_loss: 55.5575 - val_mae: 5.3498\n",
      "Epoch 82/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107.7348 - mae: 7.9361 - val_loss: 55.9903 - val_mae: 5.4444\n",
      "Epoch 83/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.0911 - mae: 7.8426 - val_loss: 55.5963 - val_mae: 5.3072\n",
      "Epoch 84/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.9619 - mae: 7.9017 - val_loss: 57.4454 - val_mae: 5.4987\n",
      "Epoch 85/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.0473 - mae: 7.7706 - val_loss: 62.6333 - val_mae: 5.7810\n",
      "Epoch 86/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 101.4802 - mae: 7.5991 - val_loss: 56.0757 - val_mae: 5.3800\n",
      "Epoch 87/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.6317 - mae: 7.7656 - val_loss: 58.8532 - val_mae: 5.4320\n",
      "Epoch 88/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.3447 - mae: 7.8387 - val_loss: 76.6171 - val_mae: 6.5253\n",
      "Epoch 89/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.8400 - mae: 7.7429 - val_loss: 53.8152 - val_mae: 5.2303\n",
      "Epoch 90/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.0900 - mae: 7.6501 - val_loss: 62.4200 - val_mae: 5.6688\n",
      "Epoch 91/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.8363 - mae: 7.6477 - val_loss: 60.2030 - val_mae: 5.5357\n",
      "Epoch 92/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.2256 - mae: 7.7937 - val_loss: 63.7343 - val_mae: 6.0662\n",
      "Epoch 93/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.5073 - mae: 7.5234 - val_loss: 54.6133 - val_mae: 5.2587\n",
      "Epoch 94/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.1691 - mae: 7.8593 - val_loss: 59.5738 - val_mae: 5.6544\n",
      "Epoch 95/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.5376 - mae: 7.8696 - val_loss: 56.3899 - val_mae: 5.4596\n",
      "Epoch 96/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.2665 - mae: 7.4592 - val_loss: 60.4771 - val_mae: 5.7055\n",
      "Epoch 97/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109.9524 - mae: 7.8324 - val_loss: 59.9533 - val_mae: 5.6619\n",
      "Epoch 98/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.6116 - mae: 7.6950 - val_loss: 70.5917 - val_mae: 6.2014\n",
      "Epoch 99/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.2282 - mae: 7.7411 - val_loss: 61.0721 - val_mae: 5.6783\n",
      "Epoch 100/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.1857 - mae: 7.5330 - val_loss: 59.5049 - val_mae: 5.6217\n",
      "Epoch 101/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.3006 - mae: 7.5758 - val_loss: 58.8308 - val_mae: 5.5064\n",
      "Epoch 102/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 103.0335 - mae: 7.7368 - val_loss: 65.9686 - val_mae: 6.0335\n",
      "Epoch 103/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107.3703 - mae: 7.7289 - val_loss: 60.2222 - val_mae: 5.5464\n",
      "Epoch 104/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.5134 - mae: 7.7669 - val_loss: 53.7917 - val_mae: 5.3246\n",
      "Epoch 105/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.7607 - mae: 7.6487 - val_loss: 55.8812 - val_mae: 5.4485\n",
      "Epoch 106/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 99.3152 - mae: 7.5946 - val_loss: 53.6929 - val_mae: 5.2413\n",
      "Epoch 107/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.0314 - mae: 7.5771 - val_loss: 58.3614 - val_mae: 5.4754\n",
      "Epoch 108/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 101.5119 - mae: 7.6048 - val_loss: 57.9122 - val_mae: 5.4897\n",
      "Epoch 109/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.9604 - mae: 7.4823 - val_loss: 53.2890 - val_mae: 5.1651\n",
      "Epoch 110/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.2194 - mae: 7.7781 - val_loss: 58.0349 - val_mae: 5.6575\n",
      "Epoch 111/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.4356 - mae: 7.7405 - val_loss: 55.6675 - val_mae: 5.3801\n",
      "Epoch 112/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.5882 - mae: 7.5476 - val_loss: 61.7170 - val_mae: 5.8697\n",
      "Epoch 113/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.7176 - mae: 7.5875 - val_loss: 56.9020 - val_mae: 5.3938\n",
      "Epoch 114/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.4343 - mae: 7.6090 - val_loss: 53.8059 - val_mae: 5.2609\n",
      "Epoch 115/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.9317 - mae: 7.4648 - val_loss: 52.5108 - val_mae: 5.1376\n",
      "Epoch 116/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.2912 - mae: 7.5569 - val_loss: 52.9647 - val_mae: 5.1982\n",
      "Epoch 117/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.7419 - mae: 7.3011 - val_loss: 53.8727 - val_mae: 5.2662\n",
      "Epoch 118/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.5456 - mae: 7.5723 - val_loss: 52.3869 - val_mae: 5.1304\n",
      "Epoch 119/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.9116 - mae: 7.5412 - val_loss: 53.6496 - val_mae: 5.2054\n",
      "Epoch 120/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.0464 - mae: 7.4807 - val_loss: 54.9169 - val_mae: 5.2532\n",
      "Epoch 121/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.6016 - mae: 7.3756 - val_loss: 53.5119 - val_mae: 5.1740\n",
      "Epoch 122/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.3319 - mae: 7.4369 - val_loss: 66.2945 - val_mae: 6.1770\n",
      "Epoch 123/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.4073 - mae: 7.5223 - val_loss: 55.7255 - val_mae: 5.3843\n",
      "Epoch 124/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.8578 - mae: 7.2756 - val_loss: 55.2313 - val_mae: 5.4222\n",
      "Epoch 125/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.3140 - mae: 7.4432 - val_loss: 54.6270 - val_mae: 5.2758\n",
      "Epoch 126/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.2766 - mae: 7.3216 - val_loss: 53.9914 - val_mae: 5.2342\n",
      "Epoch 127/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.8427 - mae: 7.2915 - val_loss: 55.3505 - val_mae: 5.2888\n",
      "Epoch 128/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.6741 - mae: 7.2684 - val_loss: 64.2292 - val_mae: 5.7731\n",
      "Epoch 129/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.7225 - mae: 7.3829 - val_loss: 53.4628 - val_mae: 5.2131\n",
      "Epoch 130/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.9808 - mae: 7.2770 - val_loss: 57.8899 - val_mae: 5.4468\n",
      "Epoch 131/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.8131 - mae: 7.4513 - val_loss: 54.3528 - val_mae: 5.1667\n",
      "Epoch 132/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.5413 - mae: 7.5939 - val_loss: 54.5913 - val_mae: 5.3183\n",
      "Epoch 133/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89.8264 - mae: 7.0348 - val_loss: 61.7110 - val_mae: 5.7964\n",
      "Epoch 134/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.4200 - mae: 7.1802 - val_loss: 57.8527 - val_mae: 5.4103\n",
      "Epoch 135/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.3814 - mae: 7.3262 - val_loss: 55.6319 - val_mae: 5.2733\n",
      "Epoch 136/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.1988 - mae: 7.2986 - val_loss: 62.5053 - val_mae: 5.7345\n",
      "Epoch 137/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.0328 - mae: 7.4135 - val_loss: 58.0924 - val_mae: 5.4238\n",
      "Epoch 138/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.9732 - mae: 7.1952 - val_loss: 53.9201 - val_mae: 5.2356\n",
      "Epoch 139/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.1415 - mae: 7.4491 - val_loss: 62.0773 - val_mae: 5.6748\n",
      "Epoch 140/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.5352 - mae: 7.3724 - val_loss: 55.0771 - val_mae: 5.2355\n",
      "Epoch 141/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.7510 - mae: 7.2360 - val_loss: 56.1032 - val_mae: 5.3169\n",
      "Epoch 142/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.0643 - mae: 7.3372 - val_loss: 61.7038 - val_mae: 5.7366\n",
      "Epoch 143/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.4822 - mae: 7.2534 - val_loss: 57.1015 - val_mae: 5.4158\n",
      "Epoch 144/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.0228 - mae: 7.1833 - val_loss: 56.8893 - val_mae: 5.4003\n",
      "Epoch 145/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.1181 - mae: 7.0641 - val_loss: 56.9765 - val_mae: 5.3582\n",
      "Epoch 146/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 89.1172 - mae: 7.0061 - val_loss: 56.6750 - val_mae: 5.3498\n",
      "Epoch 147/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.2221 - mae: 7.3350 - val_loss: 58.9771 - val_mae: 5.4879\n",
      "Epoch 148/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.6727 - mae: 7.4503 - val_loss: 52.4208 - val_mae: 5.0567\n",
      "Patience 30: Early stopping occurred at epoch 147\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61.3584 - mae: 5.3521\n",
      "Patience 30: Validation MAE: 5.13\n",
      "Patience 30: Validation Loss: 52.39\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 724.5651 - mae: 18.0959 - val_loss: 146.1685 - val_mae: 10.6316\n",
      "Epoch 2/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 246.7210 - mae: 12.3039 - val_loss: 114.7420 - val_mae: 8.0550\n",
      "Epoch 3/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 214.3527 - mae: 11.3924 - val_loss: 80.9066 - val_mae: 7.0511\n",
      "Epoch 4/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 181.3015 - mae: 10.4349 - val_loss: 88.8128 - val_mae: 6.8255\n",
      "Epoch 5/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 177.6019 - mae: 10.2960 - val_loss: 69.8773 - val_mae: 6.0750\n",
      "Epoch 6/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 172.7634 - mae: 10.2479 - val_loss: 85.2547 - val_mae: 7.2636\n",
      "Epoch 7/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 162.2840 - mae: 9.8093 - val_loss: 62.9091 - val_mae: 5.7442\n",
      "Epoch 8/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 163.6155 - mae: 9.8512 - val_loss: 68.0628 - val_mae: 5.9252\n",
      "Epoch 9/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159.1473 - mae: 9.7659 - val_loss: 71.5483 - val_mae: 6.4713\n",
      "Epoch 10/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 163.5408 - mae: 9.6868 - val_loss: 63.5495 - val_mae: 5.9451\n",
      "Epoch 11/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155.4971 - mae: 9.6340 - val_loss: 78.1980 - val_mae: 6.5344\n",
      "Epoch 12/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152.1855 - mae: 9.4928 - val_loss: 76.0736 - val_mae: 6.6593\n",
      "Epoch 13/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159.1151 - mae: 9.7688 - val_loss: 60.4694 - val_mae: 5.5595\n",
      "Epoch 14/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 150.0574 - mae: 9.5808 - val_loss: 62.9040 - val_mae: 5.8553\n",
      "Epoch 15/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145.1904 - mae: 9.2433 - val_loss: 62.6004 - val_mae: 5.6436\n",
      "Epoch 16/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147.4157 - mae: 9.3996 - val_loss: 78.9738 - val_mae: 6.9727\n",
      "Epoch 17/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152.2181 - mae: 9.5253 - val_loss: 66.0288 - val_mae: 5.8511\n",
      "Epoch 18/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146.0249 - mae: 9.1803 - val_loss: 60.3067 - val_mae: 5.5001\n",
      "Epoch 19/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.5590 - mae: 9.1735 - val_loss: 73.5159 - val_mae: 6.2851\n",
      "Epoch 20/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.4054 - mae: 9.1477 - val_loss: 60.0502 - val_mae: 5.5586\n",
      "Epoch 21/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148.9230 - mae: 9.3324 - val_loss: 107.5735 - val_mae: 8.1412\n",
      "Epoch 22/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.7904 - mae: 9.1912 - val_loss: 83.1016 - val_mae: 6.7462\n",
      "Epoch 23/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146.8757 - mae: 9.1978 - val_loss: 80.0669 - val_mae: 6.5847\n",
      "Epoch 24/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139.8090 - mae: 9.0312 - val_loss: 63.0972 - val_mae: 5.6640\n",
      "Epoch 25/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141.3594 - mae: 9.1187 - val_loss: 64.7374 - val_mae: 5.8909\n",
      "Epoch 26/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143.0962 - mae: 9.1040 - val_loss: 59.0957 - val_mae: 5.5046\n",
      "Epoch 27/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.1107 - mae: 8.9340 - val_loss: 59.9499 - val_mae: 5.4736\n",
      "Epoch 28/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143.0596 - mae: 9.0711 - val_loss: 123.7163 - val_mae: 8.7749\n",
      "Epoch 29/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.0304 - mae: 9.1624 - val_loss: 63.5203 - val_mae: 5.9449\n",
      "Epoch 30/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140.6302 - mae: 9.0477 - val_loss: 58.5631 - val_mae: 5.5011\n",
      "Epoch 31/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.8324 - mae: 8.7504 - val_loss: 60.2624 - val_mae: 5.5909\n",
      "Epoch 32/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.0404 - mae: 8.8224 - val_loss: 59.4976 - val_mae: 5.5549\n",
      "Epoch 33/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.5318 - mae: 9.0584 - val_loss: 66.2747 - val_mae: 5.9541\n",
      "Epoch 34/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134.2823 - mae: 8.9429 - val_loss: 64.7607 - val_mae: 5.7129\n",
      "Epoch 35/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.3609 - mae: 9.0457 - val_loss: 61.4956 - val_mae: 5.6204\n",
      "Epoch 36/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134.5473 - mae: 8.8544 - val_loss: 75.1227 - val_mae: 6.7187\n",
      "Epoch 37/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.0807 - mae: 8.8876 - val_loss: 64.1963 - val_mae: 5.9215\n",
      "Epoch 38/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.3977 - mae: 8.6354 - val_loss: 57.8532 - val_mae: 5.4434\n",
      "Epoch 39/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.7175 - mae: 8.7164 - val_loss: 61.2657 - val_mae: 5.5985\n",
      "Epoch 40/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135.7067 - mae: 8.9051 - val_loss: 68.6021 - val_mae: 6.0428\n",
      "Epoch 41/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.6151 - mae: 8.5722 - val_loss: 58.7086 - val_mae: 5.5272\n",
      "Epoch 42/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131.8625 - mae: 8.7629 - val_loss: 56.0334 - val_mae: 5.3286\n",
      "Epoch 43/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.7545 - mae: 8.6901 - val_loss: 56.3347 - val_mae: 5.3653\n",
      "Epoch 44/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.4283 - mae: 8.6632 - val_loss: 70.5597 - val_mae: 6.0897\n",
      "Epoch 45/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.0626 - mae: 8.7139 - val_loss: 56.8043 - val_mae: 5.3776\n",
      "Epoch 46/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.6024 - mae: 8.7821 - val_loss: 56.6632 - val_mae: 5.3664\n",
      "Epoch 47/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.6129 - mae: 8.5987 - val_loss: 59.0964 - val_mae: 5.5385\n",
      "Epoch 48/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128.8279 - mae: 8.6314 - val_loss: 78.1185 - val_mae: 6.5877\n",
      "Epoch 49/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.1648 - mae: 8.5544 - val_loss: 58.9623 - val_mae: 5.5203\n",
      "Epoch 50/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.8202 - mae: 8.5908 - val_loss: 59.0887 - val_mae: 5.6204\n",
      "Epoch 51/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.4331 - mae: 8.5973 - val_loss: 59.1928 - val_mae: 5.5766\n",
      "Epoch 52/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.1978 - mae: 8.6396 - val_loss: 58.5940 - val_mae: 5.5122\n",
      "Epoch 53/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132.0358 - mae: 8.7007 - val_loss: 66.1528 - val_mae: 5.9165\n",
      "Epoch 54/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.0306 - mae: 8.3964 - val_loss: 59.7376 - val_mae: 5.5255\n",
      "Epoch 55/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120.2202 - mae: 8.4577 - val_loss: 55.1502 - val_mae: 5.2671\n",
      "Epoch 56/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.2774 - mae: 8.3917 - val_loss: 63.1373 - val_mae: 5.9373\n",
      "Epoch 57/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.3589 - mae: 8.4399 - val_loss: 61.0326 - val_mae: 5.6889\n",
      "Epoch 58/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.1123 - mae: 8.3909 - val_loss: 55.0280 - val_mae: 5.2903\n",
      "Epoch 59/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.2076 - mae: 8.3847 - val_loss: 56.5673 - val_mae: 5.4829\n",
      "Epoch 60/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.2986 - mae: 8.3337 - val_loss: 66.7858 - val_mae: 5.8923\n",
      "Epoch 61/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126.6234 - mae: 8.4756 - val_loss: 61.3097 - val_mae: 5.6334\n",
      "Epoch 62/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.9109 - mae: 8.4389 - val_loss: 64.6128 - val_mae: 5.7395\n",
      "Epoch 63/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118.2255 - mae: 8.2921 - val_loss: 65.8471 - val_mae: 5.8204\n",
      "Epoch 64/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125.7658 - mae: 8.5267 - val_loss: 54.2130 - val_mae: 5.1872\n",
      "Epoch 65/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.6388 - mae: 8.1259 - val_loss: 74.0900 - val_mae: 6.3015\n",
      "Epoch 66/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130.7431 - mae: 8.5943 - val_loss: 56.0795 - val_mae: 5.3748\n",
      "Epoch 67/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.5952 - mae: 8.2814 - val_loss: 88.0208 - val_mae: 7.1816\n",
      "Epoch 68/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.3380 - mae: 8.4882 - val_loss: 72.1469 - val_mae: 6.1233\n",
      "Epoch 69/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.2568 - mae: 8.2408 - val_loss: 54.7575 - val_mae: 5.3337\n",
      "Epoch 70/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120.8421 - mae: 8.2956 - val_loss: 60.4657 - val_mae: 5.6142\n",
      "Epoch 71/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.6786 - mae: 8.1980 - val_loss: 66.6610 - val_mae: 5.9357\n",
      "Epoch 72/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.6166 - mae: 8.2755 - val_loss: 56.4681 - val_mae: 5.4428\n",
      "Epoch 73/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.2408 - mae: 8.2684 - val_loss: 58.7650 - val_mae: 5.5068\n",
      "Epoch 74/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 118.2866 - mae: 8.2685 - val_loss: 63.0784 - val_mae: 5.7267\n",
      "Epoch 75/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123.9721 - mae: 8.3406 - val_loss: 54.4132 - val_mae: 5.2716\n",
      "Epoch 76/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.2804 - mae: 8.1464 - val_loss: 79.8562 - val_mae: 6.7959\n",
      "Epoch 77/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121.8375 - mae: 8.2846 - val_loss: 56.3809 - val_mae: 5.4300\n",
      "Epoch 78/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.4394 - mae: 8.3503 - val_loss: 53.8266 - val_mae: 5.2025\n",
      "Epoch 79/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.2739 - mae: 8.0669 - val_loss: 54.3982 - val_mae: 5.2820\n",
      "Epoch 80/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.3839 - mae: 8.0505 - val_loss: 52.9575 - val_mae: 5.1575\n",
      "Epoch 81/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 117.0011 - mae: 8.1468 - val_loss: 61.4709 - val_mae: 5.5611\n",
      "Epoch 82/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 116.7792 - mae: 8.1715 - val_loss: 54.0047 - val_mae: 5.1902\n",
      "Epoch 83/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119.8949 - mae: 8.2497 - val_loss: 73.6982 - val_mae: 6.3478\n",
      "Epoch 84/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.5092 - mae: 8.0894 - val_loss: 55.0886 - val_mae: 5.2441\n",
      "Epoch 85/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.5660 - mae: 8.0389 - val_loss: 56.4712 - val_mae: 5.3486\n",
      "Epoch 86/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.7675 - mae: 8.0703 - val_loss: 56.2189 - val_mae: 5.3976\n",
      "Epoch 87/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.9479 - mae: 8.0165 - val_loss: 55.1291 - val_mae: 5.2977\n",
      "Epoch 88/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.4973 - mae: 7.9858 - val_loss: 53.4911 - val_mae: 5.1822\n",
      "Epoch 89/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 108.4755 - mae: 7.8839 - val_loss: 56.0505 - val_mae: 5.3424\n",
      "Epoch 90/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.2813 - mae: 7.8978 - val_loss: 57.7707 - val_mae: 5.3487\n",
      "Epoch 91/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.9178 - mae: 8.1360 - val_loss: 54.5719 - val_mae: 5.2991\n",
      "Epoch 92/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.9348 - mae: 8.0259 - val_loss: 53.8775 - val_mae: 5.2525\n",
      "Epoch 93/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.8138 - mae: 8.3109 - val_loss: 62.4134 - val_mae: 5.6572\n",
      "Epoch 94/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.7271 - mae: 7.9690 - val_loss: 54.5179 - val_mae: 5.2846\n",
      "Epoch 95/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 112.7260 - mae: 8.0663 - val_loss: 59.4834 - val_mae: 5.4552\n",
      "Epoch 96/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.6671 - mae: 7.9654 - val_loss: 54.5218 - val_mae: 5.1963\n",
      "Epoch 97/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.8188 - mae: 7.8581 - val_loss: 57.1846 - val_mae: 5.3172\n",
      "Epoch 98/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 109.0329 - mae: 7.9030 - val_loss: 54.9107 - val_mae: 5.3110\n",
      "Epoch 99/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.1581 - mae: 7.9423 - val_loss: 57.8109 - val_mae: 5.4042\n",
      "Epoch 100/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.1772 - mae: 7.8066 - val_loss: 57.6878 - val_mae: 5.4748\n",
      "Patience 20: Early stopping occurred at epoch 99\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60.6259 - mae: 5.3177\n",
      "Patience 20: Validation MAE: 5.16\n",
      "Patience 20: Validation Loss: 52.96\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 854.2191 - mae: 19.2980 - val_loss: 150.8727 - val_mae: 10.0993\n",
      "Epoch 2/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 244.3123 - mae: 12.2077 - val_loss: 119.1308 - val_mae: 7.9680\n",
      "Epoch 3/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 220.0354 - mae: 11.5457 - val_loss: 87.4969 - val_mae: 6.9927\n",
      "Epoch 4/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 197.9620 - mae: 10.9807 - val_loss: 77.9898 - val_mae: 6.3703\n",
      "Epoch 5/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 184.3823 - mae: 10.4168 - val_loss: 83.6608 - val_mae: 6.6203\n",
      "Epoch 6/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 181.0856 - mae: 10.4680 - val_loss: 69.4564 - val_mae: 5.9961\n",
      "Epoch 7/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 165.1318 - mae: 9.9619 - val_loss: 66.5932 - val_mae: 5.9392\n",
      "Epoch 8/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 170.5063 - mae: 10.1920 - val_loss: 64.1129 - val_mae: 5.8590\n",
      "Epoch 9/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159.7536 - mae: 9.7278 - val_loss: 78.0803 - val_mae: 6.4519\n",
      "Epoch 10/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 162.4431 - mae: 9.7357 - val_loss: 82.9410 - val_mae: 6.6909\n",
      "Epoch 11/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 164.7270 - mae: 9.9186 - val_loss: 60.8422 - val_mae: 5.7135\n",
      "Epoch 12/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151.6315 - mae: 9.3912 - val_loss: 65.0613 - val_mae: 5.9165\n",
      "Epoch 13/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153.9139 - mae: 9.5352 - val_loss: 71.4550 - val_mae: 6.0582\n",
      "Epoch 14/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148.8948 - mae: 9.4611 - val_loss: 77.4984 - val_mae: 6.6234\n",
      "Epoch 15/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158.0938 - mae: 9.5803 - val_loss: 62.6086 - val_mae: 5.7485\n",
      "Epoch 16/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152.0185 - mae: 9.5036 - val_loss: 59.3423 - val_mae: 5.6219\n",
      "Epoch 17/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143.4801 - mae: 9.2772 - val_loss: 66.6001 - val_mae: 5.9082\n",
      "Epoch 18/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.5455 - mae: 9.1816 - val_loss: 109.8222 - val_mae: 8.3783\n",
      "Epoch 19/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.3123 - mae: 9.1727 - val_loss: 60.2021 - val_mae: 5.5477\n",
      "Epoch 20/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147.6373 - mae: 9.3487 - val_loss: 60.7843 - val_mae: 5.5874\n",
      "Epoch 21/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146.4507 - mae: 9.2742 - val_loss: 57.1061 - val_mae: 5.3802\n",
      "Epoch 22/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.1749 - mae: 9.1972 - val_loss: 60.5800 - val_mae: 5.6242\n",
      "Epoch 23/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145.4112 - mae: 9.1528 - val_loss: 60.5334 - val_mae: 5.7390\n",
      "Epoch 24/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137.2769 - mae: 8.8782 - val_loss: 66.2641 - val_mae: 5.9093\n",
      "Epoch 25/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.3996 - mae: 8.9176 - val_loss: 61.4101 - val_mae: 5.7373\n",
      "Epoch 26/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142.1525 - mae: 9.2632 - val_loss: 77.5436 - val_mae: 6.5564\n",
      "Epoch 27/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.7732 - mae: 8.8898 - val_loss: 60.0897 - val_mae: 5.5999\n",
      "Epoch 28/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133.9023 - mae: 8.8821 - val_loss: 58.7650 - val_mae: 5.5239\n",
      "Epoch 29/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140.4398 - mae: 9.0678 - val_loss: 73.0112 - val_mae: 6.2138\n",
      "Epoch 30/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.7230 - mae: 8.9654 - val_loss: 60.7566 - val_mae: 5.5897\n",
      "Epoch 31/200\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135.4560 - mae: 8.9647 - val_loss: 69.8402 - val_mae: 6.1385\n",
      "Patience 10: Early stopping occurred at epoch 30\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64.5635 - mae: 5.5494\n",
      "Patience 10: Validation MAE: 5.38\n",
      "Patience 10: Validation Loss: 57.11\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 51.5722, MAE = 5.0560, Early Stopping Occurred: True, Early Stopping Epoch: 113\n",
      "Patience 30: Loss = 52.3869, MAE = 5.1304, Early Stopping Occurred: True, Early Stopping Epoch: 147\n",
      "Patience 20: Loss = 52.9575, MAE = 5.1575, Early Stopping Occurred: True, Early Stopping Epoch: 99\n",
      "Patience 10: Loss = 57.1061, MAE = 5.3802, Early Stopping Occurred: True, Early Stopping Epoch: 30\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "bresults200 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    dbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    dbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'best_model_{patience}.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = dbp_model.fit(\n",
    "        X_train_combined, DBP_Y_train_combined,\n",
    "        epochs=200,\n",
    "        batch_size=16,\n",
    "        validation_data=(X_test_combined, DBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = dbp_model.evaluate(X_test_combined, DBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    bresults200.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    # 학습 및 검증 손실 그래프 시각화\n",
    "    # plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.title(f'Patience = {patience}')\n",
    "    # plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in bresults200:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1559.5195 - mae: 23.9160 - val_loss: 165.2595 - val_mae: 10.0580\n",
      "Epoch 2/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 302.9611 - mae: 13.6363 - val_loss: 150.1017 - val_mae: 9.1819\n",
      "Epoch 3/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 256.1908 - mae: 12.6589 - val_loss: 123.7343 - val_mae: 9.5859\n",
      "Epoch 4/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 237.8722 - mae: 12.0978 - val_loss: 98.3604 - val_mae: 8.1224\n",
      "Epoch 5/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.1699 - mae: 11.7385 - val_loss: 83.3724 - val_mae: 7.2446\n",
      "Epoch 6/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.8669 - mae: 11.0007 - val_loss: 91.5250 - val_mae: 6.9513\n",
      "Epoch 7/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.1089 - mae: 10.6783 - val_loss: 111.9173 - val_mae: 8.0540\n",
      "Epoch 8/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.2566 - mae: 10.3576 - val_loss: 62.2426 - val_mae: 5.7338\n",
      "Epoch 9/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168.6393 - mae: 9.9817 - val_loss: 60.9021 - val_mae: 5.6197\n",
      "Epoch 10/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159.0230 - mae: 9.7741 - val_loss: 61.8348 - val_mae: 5.6939\n",
      "Epoch 11/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167.2796 - mae: 9.9458 - val_loss: 60.9456 - val_mae: 5.6570\n",
      "Epoch 12/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167.0022 - mae: 9.9202 - val_loss: 61.0542 - val_mae: 5.6653\n",
      "Epoch 13/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159.4476 - mae: 9.7719 - val_loss: 73.9207 - val_mae: 6.2503\n",
      "Epoch 14/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 160.9682 - mae: 9.7939 - val_loss: 69.0064 - val_mae: 6.0068\n",
      "Epoch 15/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 169.4209 - mae: 9.9826 - val_loss: 64.1660 - val_mae: 5.9084\n",
      "Epoch 16/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164.1458 - mae: 9.9571 - val_loss: 78.8310 - val_mae: 6.6079\n",
      "Epoch 17/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159.7442 - mae: 9.7262 - val_loss: 67.3497 - val_mae: 5.9812\n",
      "Epoch 18/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159.2892 - mae: 9.7039 - val_loss: 76.9060 - val_mae: 6.3171\n",
      "Epoch 19/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155.4877 - mae: 9.6282 - val_loss: 64.1078 - val_mae: 5.7722\n",
      "Epoch 20/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155.8108 - mae: 9.5276 - val_loss: 60.8798 - val_mae: 5.6247\n",
      "Epoch 21/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.0897 - mae: 9.3784 - val_loss: 60.0468 - val_mae: 5.6424\n",
      "Epoch 22/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.0219 - mae: 9.5745 - val_loss: 58.9975 - val_mae: 5.5178\n",
      "Epoch 23/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.1711 - mae: 9.3419 - val_loss: 64.9275 - val_mae: 5.8198\n",
      "Epoch 24/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.6492 - mae: 9.4267 - val_loss: 59.7467 - val_mae: 5.5636\n",
      "Epoch 25/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148.5130 - mae: 9.2780 - val_loss: 61.7913 - val_mae: 5.5896\n",
      "Epoch 26/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156.6281 - mae: 9.6505 - val_loss: 82.4890 - val_mae: 6.7427\n",
      "Epoch 27/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157.4016 - mae: 9.6211 - val_loss: 57.5540 - val_mae: 5.4267\n",
      "Epoch 28/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.3987 - mae: 9.4235 - val_loss: 61.7184 - val_mae: 5.5879\n",
      "Epoch 29/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.7903 - mae: 9.2745 - val_loss: 68.8875 - val_mae: 6.0905\n",
      "Epoch 30/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.0163 - mae: 9.2273 - val_loss: 58.4442 - val_mae: 5.5092\n",
      "Epoch 31/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153.0859 - mae: 9.5686 - val_loss: 59.0262 - val_mae: 5.4679\n",
      "Epoch 32/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153.5904 - mae: 9.6170 - val_loss: 60.0365 - val_mae: 5.5490\n",
      "Epoch 33/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 150.5560 - mae: 9.4071 - val_loss: 57.4861 - val_mae: 5.4996\n",
      "Epoch 34/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.4681 - mae: 9.3126 - val_loss: 58.6845 - val_mae: 5.5944\n",
      "Epoch 35/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.8318 - mae: 9.2223 - val_loss: 61.0237 - val_mae: 5.6227\n",
      "Epoch 36/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.9208 - mae: 9.0562 - val_loss: 64.4465 - val_mae: 5.7361\n",
      "Epoch 37/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148.6762 - mae: 9.2882 - val_loss: 75.9367 - val_mae: 6.4051\n",
      "Epoch 38/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155.4369 - mae: 9.6281 - val_loss: 56.7553 - val_mae: 5.4765\n",
      "Epoch 39/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.9283 - mae: 9.2645 - val_loss: 73.1988 - val_mae: 6.1944\n",
      "Epoch 40/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156.6651 - mae: 9.5734 - val_loss: 63.7879 - val_mae: 5.8208\n",
      "Epoch 41/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.8168 - mae: 9.5025 - val_loss: 62.9276 - val_mae: 5.6631\n",
      "Epoch 42/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.4683 - mae: 9.2932 - val_loss: 62.8214 - val_mae: 5.6559\n",
      "Epoch 43/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.7862 - mae: 9.3768 - val_loss: 60.8451 - val_mae: 5.5852\n",
      "Epoch 44/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.3969 - mae: 9.1571 - val_loss: 57.7682 - val_mae: 5.4594\n",
      "Epoch 45/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154.5413 - mae: 9.4561 - val_loss: 55.0310 - val_mae: 5.2984\n",
      "Epoch 46/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.9342 - mae: 8.9394 - val_loss: 61.0031 - val_mae: 5.5769\n",
      "Epoch 47/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135.7019 - mae: 9.0428 - val_loss: 57.3083 - val_mae: 5.4204\n",
      "Epoch 48/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.6720 - mae: 9.1069 - val_loss: 59.1062 - val_mae: 5.5570\n",
      "Epoch 49/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.9017 - mae: 9.0890 - val_loss: 61.9990 - val_mae: 5.6451\n",
      "Epoch 50/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.5546 - mae: 9.3101 - val_loss: 76.8755 - val_mae: 6.5679\n",
      "Epoch 51/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.5197 - mae: 9.0009 - val_loss: 56.2415 - val_mae: 5.3686\n",
      "Epoch 52/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142.5072 - mae: 9.1716 - val_loss: 55.7224 - val_mae: 5.3618\n",
      "Epoch 53/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.2675 - mae: 9.0925 - val_loss: 57.7809 - val_mae: 5.4892\n",
      "Epoch 54/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.7009 - mae: 8.9940 - val_loss: 55.2337 - val_mae: 5.3768\n",
      "Epoch 55/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.2354 - mae: 9.0265 - val_loss: 65.8034 - val_mae: 5.7857\n",
      "Epoch 56/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.5803 - mae: 8.7521 - val_loss: 65.4253 - val_mae: 5.9426\n",
      "Epoch 57/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.1333 - mae: 8.9867 - val_loss: 69.7177 - val_mae: 6.0594\n",
      "Epoch 58/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.4058 - mae: 9.0078 - val_loss: 72.2363 - val_mae: 6.1270\n",
      "Epoch 59/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.6127 - mae: 8.8231 - val_loss: 85.0928 - val_mae: 7.0090\n",
      "Epoch 60/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.2090 - mae: 8.9152 - val_loss: 56.8777 - val_mae: 5.4704\n",
      "Epoch 61/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.5045 - mae: 9.1470 - val_loss: 57.5321 - val_mae: 5.4337\n",
      "Epoch 62/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.3898 - mae: 8.8757 - val_loss: 56.8794 - val_mae: 5.5105\n",
      "Epoch 63/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.2106 - mae: 9.0816 - val_loss: 59.4701 - val_mae: 5.5333\n",
      "Epoch 64/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.2657 - mae: 8.9579 - val_loss: 55.3168 - val_mae: 5.3138\n",
      "Epoch 65/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.3629 - mae: 9.1175 - val_loss: 56.8439 - val_mae: 5.3446\n",
      "Epoch 66/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.6580 - mae: 8.9641 - val_loss: 68.1733 - val_mae: 5.9958\n",
      "Epoch 67/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.8226 - mae: 8.9721 - val_loss: 54.3464 - val_mae: 5.2725\n",
      "Epoch 68/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.9895 - mae: 9.0286 - val_loss: 61.8774 - val_mae: 5.7329\n",
      "Epoch 69/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.4968 - mae: 8.7676 - val_loss: 60.7568 - val_mae: 5.6551\n",
      "Epoch 70/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.1411 - mae: 8.6949 - val_loss: 56.9411 - val_mae: 5.4998\n",
      "Epoch 71/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135.2563 - mae: 8.8203 - val_loss: 54.5568 - val_mae: 5.2902\n",
      "Epoch 72/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.1880 - mae: 8.8324 - val_loss: 55.6712 - val_mae: 5.4328\n",
      "Epoch 73/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.0415 - mae: 8.8882 - val_loss: 94.6923 - val_mae: 7.6638\n",
      "Epoch 74/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.4106 - mae: 8.7289 - val_loss: 58.8522 - val_mae: 5.5727\n",
      "Epoch 75/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.4233 - mae: 8.9120 - val_loss: 55.0836 - val_mae: 5.3411\n",
      "Epoch 76/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.7814 - mae: 8.4467 - val_loss: 65.5596 - val_mae: 5.8614\n",
      "Epoch 77/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.3233 - mae: 8.7436 - val_loss: 55.6865 - val_mae: 5.3818\n",
      "Epoch 78/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.2374 - mae: 8.6065 - val_loss: 55.0018 - val_mae: 5.2397\n",
      "Epoch 79/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.4702 - mae: 8.5980 - val_loss: 68.0972 - val_mae: 6.0526\n",
      "Epoch 80/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.7919 - mae: 8.9420 - val_loss: 60.1860 - val_mae: 5.5552\n",
      "Epoch 81/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.2062 - mae: 8.6892 - val_loss: 52.8493 - val_mae: 5.1844\n",
      "Epoch 82/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.4423 - mae: 8.5934 - val_loss: 62.0375 - val_mae: 5.6473\n",
      "Epoch 83/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.4641 - mae: 8.7123 - val_loss: 67.7543 - val_mae: 5.8866\n",
      "Epoch 84/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.2750 - mae: 8.7156 - val_loss: 55.6745 - val_mae: 5.3458\n",
      "Epoch 85/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.0533 - mae: 8.7117 - val_loss: 55.5117 - val_mae: 5.2930\n",
      "Epoch 86/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.5909 - mae: 8.6661 - val_loss: 54.2080 - val_mae: 5.3039\n",
      "Epoch 87/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.9691 - mae: 8.6844 - val_loss: 55.2626 - val_mae: 5.3118\n",
      "Epoch 88/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.4125 - mae: 8.7212 - val_loss: 55.7018 - val_mae: 5.3730\n",
      "Epoch 89/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.6026 - mae: 8.6925 - val_loss: 54.1138 - val_mae: 5.2733\n",
      "Epoch 90/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.0143 - mae: 8.7047 - val_loss: 56.9313 - val_mae: 5.3637\n",
      "Epoch 91/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.3098 - mae: 8.4953 - val_loss: 54.8121 - val_mae: 5.2503\n",
      "Epoch 92/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.4066 - mae: 8.4810 - val_loss: 56.9458 - val_mae: 5.4790\n",
      "Epoch 93/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.0874 - mae: 8.5310 - val_loss: 53.5307 - val_mae: 5.2201\n",
      "Epoch 94/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.4290 - mae: 8.5283 - val_loss: 53.6094 - val_mae: 5.2488\n",
      "Epoch 95/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.0687 - mae: 8.3324 - val_loss: 55.8350 - val_mae: 5.3650\n",
      "Epoch 96/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.5430 - mae: 8.5186 - val_loss: 54.9803 - val_mae: 5.4284\n",
      "Epoch 97/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.1084 - mae: 8.4904 - val_loss: 57.3505 - val_mae: 5.6264\n",
      "Epoch 98/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.0036 - mae: 8.4808 - val_loss: 56.5828 - val_mae: 5.4039\n",
      "Epoch 99/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.8355 - mae: 8.5770 - val_loss: 55.6635 - val_mae: 5.3130\n",
      "Epoch 100/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 123.6809 - mae: 8.4201 - val_loss: 55.2578 - val_mae: 5.3267\n",
      "Epoch 101/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123.6841 - mae: 8.5265 - val_loss: 54.1173 - val_mae: 5.3141\n",
      "Epoch 102/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.1637 - mae: 8.5346 - val_loss: 54.9139 - val_mae: 5.2673\n",
      "Epoch 103/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.7193 - mae: 8.3934 - val_loss: 57.3607 - val_mae: 5.3888\n",
      "Epoch 104/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.4530 - mae: 8.6814 - val_loss: 55.8919 - val_mae: 5.3518\n",
      "Epoch 105/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.3632 - mae: 8.4518 - val_loss: 79.2861 - val_mae: 6.7598\n",
      "Epoch 106/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.9516 - mae: 8.3078 - val_loss: 56.7195 - val_mae: 5.5230\n",
      "Epoch 107/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.2813 - mae: 8.5057 - val_loss: 55.2004 - val_mae: 5.2424\n",
      "Epoch 108/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.0386 - mae: 8.3201 - val_loss: 54.8873 - val_mae: 5.2766\n",
      "Epoch 109/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.0133 - mae: 8.2342 - val_loss: 53.8009 - val_mae: 5.2095\n",
      "Epoch 110/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.9110 - mae: 8.3998 - val_loss: 56.4351 - val_mae: 5.4338\n",
      "Epoch 111/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.6152 - mae: 8.4846 - val_loss: 54.4347 - val_mae: 5.1948\n",
      "Epoch 112/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.4285 - mae: 8.3011 - val_loss: 57.6977 - val_mae: 5.3598\n",
      "Epoch 113/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.5266 - mae: 8.2232 - val_loss: 53.2237 - val_mae: 5.1981\n",
      "Epoch 114/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.8177 - mae: 8.4220 - val_loss: 55.9108 - val_mae: 5.4146\n",
      "Epoch 115/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.6311 - mae: 8.1562 - val_loss: 53.2374 - val_mae: 5.1770\n",
      "Epoch 116/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 115.5154 - mae: 8.1613 - val_loss: 51.8470 - val_mae: 5.0955\n",
      "Epoch 117/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.1454 - mae: 8.4384 - val_loss: 51.5882 - val_mae: 5.1240\n",
      "Epoch 118/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.3824 - mae: 8.0632 - val_loss: 60.9933 - val_mae: 5.5296\n",
      "Epoch 119/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.6573 - mae: 8.2091 - val_loss: 55.3221 - val_mae: 5.3304\n",
      "Epoch 120/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.6620 - mae: 8.1536 - val_loss: 54.5990 - val_mae: 5.2418\n",
      "Epoch 121/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 113.5542 - mae: 8.0585 - val_loss: 55.4822 - val_mae: 5.2229\n",
      "Epoch 122/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 118.1402 - mae: 8.3052 - val_loss: 55.4488 - val_mae: 5.3032\n",
      "Epoch 123/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 112.2279 - mae: 8.0257 - val_loss: 50.8069 - val_mae: 5.0273\n",
      "Epoch 124/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.9245 - mae: 8.1070 - val_loss: 52.8573 - val_mae: 5.2084\n",
      "Epoch 125/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.4921 - mae: 8.1945 - val_loss: 52.2278 - val_mae: 5.1660\n",
      "Epoch 126/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.2234 - mae: 8.0653 - val_loss: 51.8489 - val_mae: 5.1281\n",
      "Epoch 127/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109.8679 - mae: 7.9732 - val_loss: 52.3138 - val_mae: 5.1438\n",
      "Epoch 128/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.8876 - mae: 8.0110 - val_loss: 52.0773 - val_mae: 5.1117\n",
      "Epoch 129/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.3197 - mae: 8.3549 - val_loss: 50.6211 - val_mae: 5.0247\n",
      "Epoch 130/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.7605 - mae: 8.1013 - val_loss: 50.5648 - val_mae: 4.9649\n",
      "Epoch 131/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.9724 - mae: 8.0628 - val_loss: 58.0327 - val_mae: 5.4981\n",
      "Epoch 132/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114.0855 - mae: 8.0175 - val_loss: 63.2827 - val_mae: 5.7766\n",
      "Epoch 133/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.4064 - mae: 8.0884 - val_loss: 55.7204 - val_mae: 5.3275\n",
      "Epoch 134/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.3567 - mae: 8.0770 - val_loss: 52.0071 - val_mae: 5.1118\n",
      "Epoch 135/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.8618 - mae: 7.9559 - val_loss: 50.9806 - val_mae: 5.0271\n",
      "Epoch 136/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.7718 - mae: 8.0284 - val_loss: 53.3473 - val_mae: 5.2956\n",
      "Epoch 137/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.1246 - mae: 8.0521 - val_loss: 53.2516 - val_mae: 5.2212\n",
      "Epoch 138/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.8053 - mae: 8.0752 - val_loss: 54.4796 - val_mae: 5.3217\n",
      "Epoch 139/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.8611 - mae: 8.0030 - val_loss: 54.2046 - val_mae: 5.3299\n",
      "Epoch 140/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 105.9427 - mae: 7.8528 - val_loss: 51.8434 - val_mae: 5.1803\n",
      "Epoch 141/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.2415 - mae: 7.7723 - val_loss: 51.4711 - val_mae: 5.0864\n",
      "Epoch 142/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 106.6279 - mae: 7.8234 - val_loss: 56.4655 - val_mae: 5.4207\n",
      "Epoch 143/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 115.5874 - mae: 8.1285 - val_loss: 63.1866 - val_mae: 5.7835\n",
      "Epoch 144/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 106.5005 - mae: 7.8227 - val_loss: 50.0163 - val_mae: 4.9940\n",
      "Epoch 145/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 101.8727 - mae: 7.7104 - val_loss: 54.5809 - val_mae: 5.2905\n",
      "Epoch 146/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.9614 - mae: 8.0428 - val_loss: 50.9178 - val_mae: 5.0659\n",
      "Epoch 147/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.1417 - mae: 7.7082 - val_loss: 51.1006 - val_mae: 5.0536\n",
      "Epoch 148/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107.9703 - mae: 7.8426 - val_loss: 66.1065 - val_mae: 6.0033\n",
      "Epoch 149/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.6143 - mae: 7.9619 - val_loss: 56.5165 - val_mae: 5.4961\n",
      "Epoch 150/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.6730 - mae: 7.7827 - val_loss: 50.3564 - val_mae: 5.0243\n",
      "Epoch 151/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.2896 - mae: 7.8064 - val_loss: 51.4531 - val_mae: 5.1074\n",
      "Epoch 152/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.2125 - mae: 7.9454 - val_loss: 55.8590 - val_mae: 5.3320\n",
      "Epoch 153/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 107.4726 - mae: 7.8788 - val_loss: 55.6174 - val_mae: 5.3063\n",
      "Epoch 154/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.4590 - mae: 7.7590 - val_loss: 54.1947 - val_mae: 5.2390\n",
      "Epoch 155/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.4960 - mae: 7.7526 - val_loss: 51.8715 - val_mae: 5.1020\n",
      "Epoch 156/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.7734 - mae: 7.6909 - val_loss: 50.4574 - val_mae: 5.0369\n",
      "Epoch 157/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.8962 - mae: 8.0504 - val_loss: 50.0755 - val_mae: 4.9868\n",
      "Epoch 158/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107.3784 - mae: 7.8616 - val_loss: 54.2570 - val_mae: 5.2597\n",
      "Epoch 159/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.4316 - mae: 7.7497 - val_loss: 57.1335 - val_mae: 5.4182\n",
      "Epoch 160/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 106.6846 - mae: 7.8013 - val_loss: 52.7711 - val_mae: 5.1331\n",
      "Epoch 161/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 105.7622 - mae: 7.7097 - val_loss: 53.1139 - val_mae: 5.2019\n",
      "Epoch 162/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.5821 - mae: 7.6983 - val_loss: 52.0909 - val_mae: 5.1518\n",
      "Epoch 163/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 103.4997 - mae: 7.6240 - val_loss: 58.1109 - val_mae: 5.6100\n",
      "Epoch 164/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.7249 - mae: 7.8471 - val_loss: 52.3401 - val_mae: 5.1533\n",
      "Epoch 165/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.6118 - mae: 7.7089 - val_loss: 51.4869 - val_mae: 5.0584\n",
      "Epoch 166/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.7314 - mae: 7.6987 - val_loss: 50.5066 - val_mae: 5.0093\n",
      "Epoch 167/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 101.4298 - mae: 7.6273 - val_loss: 51.0361 - val_mae: 5.0608\n",
      "Epoch 168/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 102.6736 - mae: 7.6092 - val_loss: 57.0717 - val_mae: 5.4167\n",
      "Epoch 169/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 102.9079 - mae: 7.6538 - val_loss: 50.3595 - val_mae: 5.0019\n",
      "Epoch 170/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.7528 - mae: 7.8117 - val_loss: 49.6947 - val_mae: 4.9654\n",
      "Epoch 171/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 100.8335 - mae: 7.5775 - val_loss: 57.3977 - val_mae: 5.5612\n",
      "Epoch 172/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 106.7340 - mae: 7.6650 - val_loss: 52.1896 - val_mae: 5.1378\n",
      "Epoch 173/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 103.6662 - mae: 7.6877 - val_loss: 53.0425 - val_mae: 5.2017\n",
      "Epoch 174/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.6060 - mae: 7.7141 - val_loss: 64.7945 - val_mae: 5.9881\n",
      "Epoch 175/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.4655 - mae: 7.7960 - val_loss: 56.4626 - val_mae: 5.4281\n",
      "Epoch 176/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 101.2400 - mae: 7.6033 - val_loss: 53.1676 - val_mae: 5.2130\n",
      "Epoch 177/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 101.7535 - mae: 7.4326 - val_loss: 53.9034 - val_mae: 5.4403\n",
      "Epoch 178/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 98.4308 - mae: 7.4585 - val_loss: 58.2375 - val_mae: 5.3880\n",
      "Epoch 179/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 100.9996 - mae: 7.5622 - val_loss: 51.7271 - val_mae: 5.1195\n",
      "Epoch 180/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 102.8773 - mae: 7.6546 - val_loss: 53.2008 - val_mae: 5.1828\n",
      "Epoch 181/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 96.9061 - mae: 7.4316 - val_loss: 52.9253 - val_mae: 5.1700\n",
      "Epoch 182/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.4293 - mae: 7.7712 - val_loss: 56.2838 - val_mae: 5.4473\n",
      "Epoch 183/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 105.9873 - mae: 7.7351 - val_loss: 55.3163 - val_mae: 5.3111\n",
      "Epoch 184/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 100.3553 - mae: 7.5836 - val_loss: 49.9058 - val_mae: 4.9847\n",
      "Epoch 185/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 97.9986 - mae: 7.4872 - val_loss: 49.6162 - val_mae: 4.9872\n",
      "Epoch 186/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 98.6379 - mae: 7.4953 - val_loss: 56.9387 - val_mae: 5.3948\n",
      "Epoch 187/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.2140 - mae: 7.5411 - val_loss: 54.3282 - val_mae: 5.2669\n",
      "Epoch 188/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 103.3272 - mae: 7.5968 - val_loss: 56.0584 - val_mae: 5.2799\n",
      "Epoch 189/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 98.8373 - mae: 7.4842 - val_loss: 52.7435 - val_mae: 5.1394\n",
      "Epoch 190/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 102.1740 - mae: 7.5670 - val_loss: 52.7150 - val_mae: 5.0958\n",
      "Epoch 191/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 96.4625 - mae: 7.4014 - val_loss: 61.4669 - val_mae: 5.6766\n",
      "Epoch 192/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 100.2430 - mae: 7.5062 - val_loss: 54.5824 - val_mae: 5.2997\n",
      "Epoch 193/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 99.2211 - mae: 7.5811 - val_loss: 52.4635 - val_mae: 5.1614\n",
      "Epoch 194/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 100.4436 - mae: 7.4681 - val_loss: 51.4601 - val_mae: 5.0998\n",
      "Epoch 195/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 98.8477 - mae: 7.4820 - val_loss: 51.8700 - val_mae: 5.2506\n",
      "Epoch 196/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 97.9780 - mae: 7.5221 - val_loss: 58.7860 - val_mae: 5.4687\n",
      "Epoch 197/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100.3489 - mae: 7.4560 - val_loss: 49.6646 - val_mae: 4.9744\n",
      "Epoch 198/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 99.8311 - mae: 7.5031 - val_loss: 50.5583 - val_mae: 4.9861\n",
      "Epoch 199/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 101.8821 - mae: 7.6349 - val_loss: 49.1604 - val_mae: 4.9449\n",
      "Epoch 200/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 96.7632 - mae: 7.2951 - val_loss: 62.4817 - val_mae: 5.7118\n",
      "Patience 40: Early stopping did not occur\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56.7635 - mae: 5.1256\n",
      "Patience 40: Validation MAE: 4.94\n",
      "Patience 40: Validation Loss: 49.16\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 841.2840 - mae: 20.8017 - val_loss: 179.8831 - val_mae: 10.4485\n",
      "Epoch 2/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 284.2435 - mae: 13.2994 - val_loss: 148.9584 - val_mae: 10.7636\n",
      "Epoch 3/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 266.9995 - mae: 12.8904 - val_loss: 120.8144 - val_mae: 9.3625\n",
      "Epoch 4/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 245.9055 - mae: 12.2562 - val_loss: 115.5574 - val_mae: 7.7945\n",
      "Epoch 5/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.5804 - mae: 11.2943 - val_loss: 136.4020 - val_mae: 8.8354\n",
      "Epoch 6/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 206.4999 - mae: 11.0886 - val_loss: 75.6761 - val_mae: 6.2730\n",
      "Epoch 7/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 179.5320 - mae: 10.3622 - val_loss: 70.8791 - val_mae: 6.0944\n",
      "Epoch 8/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 169.8615 - mae: 10.1182 - val_loss: 67.6509 - val_mae: 6.1482\n",
      "Epoch 9/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 165.1913 - mae: 10.0318 - val_loss: 62.0125 - val_mae: 5.7152\n",
      "Epoch 10/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.6390 - mae: 10.3798 - val_loss: 79.4943 - val_mae: 6.4158\n",
      "Epoch 11/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.4185 - mae: 10.2739 - val_loss: 64.8177 - val_mae: 5.8225\n",
      "Epoch 12/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172.2330 - mae: 10.1047 - val_loss: 65.2838 - val_mae: 5.9361\n",
      "Epoch 13/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 166.8764 - mae: 9.9486 - val_loss: 61.6223 - val_mae: 5.6505\n",
      "Epoch 14/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 160.2210 - mae: 9.8194 - val_loss: 63.5479 - val_mae: 5.7125\n",
      "Epoch 15/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 169.7801 - mae: 10.0290 - val_loss: 65.7135 - val_mae: 5.9532\n",
      "Epoch 16/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159.8560 - mae: 9.7093 - val_loss: 68.4892 - val_mae: 5.9060\n",
      "Epoch 17/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 159.2529 - mae: 9.7450 - val_loss: 59.1094 - val_mae: 5.4897\n",
      "Epoch 18/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 166.9072 - mae: 10.0131 - val_loss: 66.2803 - val_mae: 6.1175\n",
      "Epoch 19/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165.2427 - mae: 9.7593 - val_loss: 72.7641 - val_mae: 6.3864\n",
      "Epoch 20/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164.7978 - mae: 9.8708 - val_loss: 68.6242 - val_mae: 6.2677\n",
      "Epoch 21/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.9922 - mae: 9.3353 - val_loss: 63.1432 - val_mae: 5.8811\n",
      "Epoch 22/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163.0099 - mae: 9.8448 - val_loss: 62.6077 - val_mae: 5.7425\n",
      "Epoch 23/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.2565 - mae: 9.3883 - val_loss: 66.3897 - val_mae: 5.8812\n",
      "Epoch 24/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.3125 - mae: 9.4606 - val_loss: 75.6035 - val_mae: 6.3491\n",
      "Epoch 25/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147.7511 - mae: 9.3277 - val_loss: 58.5785 - val_mae: 5.4787\n",
      "Epoch 26/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.8221 - mae: 9.2499 - val_loss: 64.1679 - val_mae: 5.7726\n",
      "Epoch 27/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.8335 - mae: 9.4619 - val_loss: 62.9741 - val_mae: 5.7184\n",
      "Epoch 28/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 153.3665 - mae: 9.4952 - val_loss: 66.6755 - val_mae: 5.9335\n",
      "Epoch 29/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.9456 - mae: 9.3844 - val_loss: 58.4755 - val_mae: 5.4512\n",
      "Epoch 30/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.6517 - mae: 9.5202 - val_loss: 73.1162 - val_mae: 6.2510\n",
      "Epoch 31/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142.9549 - mae: 9.2110 - val_loss: 60.9801 - val_mae: 5.6500\n",
      "Epoch 32/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.0334 - mae: 9.3202 - val_loss: 64.1674 - val_mae: 6.0415\n",
      "Epoch 33/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158.1142 - mae: 9.6216 - val_loss: 70.2377 - val_mae: 6.0685\n",
      "Epoch 34/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.9036 - mae: 9.0808 - val_loss: 58.4423 - val_mae: 5.4947\n",
      "Epoch 35/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.9814 - mae: 9.4355 - val_loss: 63.8441 - val_mae: 5.8747\n",
      "Epoch 36/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.2649 - mae: 9.3882 - val_loss: 67.9899 - val_mae: 5.9412\n",
      "Epoch 37/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.6196 - mae: 9.3009 - val_loss: 61.8134 - val_mae: 5.9332\n",
      "Epoch 38/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148.2287 - mae: 9.3287 - val_loss: 71.2216 - val_mae: 6.0795\n",
      "Epoch 39/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.1589 - mae: 9.3290 - val_loss: 69.7339 - val_mae: 6.0850\n",
      "Epoch 40/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.1087 - mae: 9.2306 - val_loss: 57.3236 - val_mae: 5.4837\n",
      "Epoch 41/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.0068 - mae: 9.1375 - val_loss: 85.7051 - val_mae: 6.9859\n",
      "Epoch 42/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.9830 - mae: 9.2676 - val_loss: 64.6077 - val_mae: 5.7973\n",
      "Epoch 43/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.0665 - mae: 8.9702 - val_loss: 66.1641 - val_mae: 5.9373\n",
      "Epoch 44/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.0264 - mae: 8.8031 - val_loss: 59.0500 - val_mae: 5.5439\n",
      "Epoch 45/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.0989 - mae: 9.2111 - val_loss: 65.2003 - val_mae: 5.8273\n",
      "Epoch 46/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.5772 - mae: 9.0115 - val_loss: 69.9017 - val_mae: 6.1676\n",
      "Epoch 47/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.1720 - mae: 9.1509 - val_loss: 71.7196 - val_mae: 6.1169\n",
      "Epoch 48/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.4567 - mae: 8.9315 - val_loss: 113.6150 - val_mae: 8.4522\n",
      "Epoch 49/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.7094 - mae: 9.0659 - val_loss: 58.9668 - val_mae: 5.6674\n",
      "Epoch 50/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 143.7045 - mae: 9.2483 - val_loss: 61.9346 - val_mae: 5.6384\n",
      "Epoch 51/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.3511 - mae: 8.8809 - val_loss: 62.0984 - val_mae: 5.7046\n",
      "Epoch 52/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.3825 - mae: 8.9327 - val_loss: 58.5095 - val_mae: 5.4983\n",
      "Epoch 53/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.3662 - mae: 9.0803 - val_loss: 77.8766 - val_mae: 6.4064\n",
      "Epoch 54/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 135.7736 - mae: 8.8645 - val_loss: 58.0989 - val_mae: 5.4608\n",
      "Epoch 55/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.8104 - mae: 8.7703 - val_loss: 68.5735 - val_mae: 6.0572\n",
      "Epoch 56/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.5018 - mae: 9.0353 - val_loss: 57.4854 - val_mae: 5.4394\n",
      "Epoch 57/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.2446 - mae: 8.7997 - val_loss: 94.8322 - val_mae: 7.6399\n",
      "Epoch 58/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.6307 - mae: 9.1089 - val_loss: 69.9026 - val_mae: 6.0132\n",
      "Epoch 59/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.5861 - mae: 8.8775 - val_loss: 70.9033 - val_mae: 6.1595\n",
      "Epoch 60/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 130.2498 - mae: 8.7855 - val_loss: 57.2462 - val_mae: 5.5484\n",
      "Epoch 61/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.0345 - mae: 8.9181 - val_loss: 58.0753 - val_mae: 5.5456\n",
      "Epoch 62/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148.0854 - mae: 9.2474 - val_loss: 58.1964 - val_mae: 5.5414\n",
      "Epoch 63/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.7065 - mae: 8.9375 - val_loss: 72.7528 - val_mae: 6.3062\n",
      "Epoch 64/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.7473 - mae: 8.7539 - val_loss: 55.6070 - val_mae: 5.3482\n",
      "Epoch 65/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.8052 - mae: 8.9514 - val_loss: 56.9636 - val_mae: 5.4068\n",
      "Epoch 66/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.9478 - mae: 8.9061 - val_loss: 58.4765 - val_mae: 5.4671\n",
      "Epoch 67/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.0712 - mae: 8.6044 - val_loss: 56.1881 - val_mae: 5.4211\n",
      "Epoch 68/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.5002 - mae: 8.6957 - val_loss: 56.5724 - val_mae: 5.4781\n",
      "Epoch 69/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.8486 - mae: 8.6642 - val_loss: 63.9278 - val_mae: 5.8328\n",
      "Epoch 70/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.4227 - mae: 8.6776 - val_loss: 60.9789 - val_mae: 5.6308\n",
      "Epoch 71/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.4051 - mae: 8.5791 - val_loss: 63.8556 - val_mae: 6.1100\n",
      "Epoch 72/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.7084 - mae: 8.6741 - val_loss: 57.5706 - val_mae: 5.4533\n",
      "Epoch 73/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 125.9107 - mae: 8.6115 - val_loss: 58.3497 - val_mae: 5.4919\n",
      "Epoch 74/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.0542 - mae: 8.4712 - val_loss: 62.2226 - val_mae: 5.8229\n",
      "Epoch 75/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.4910 - mae: 8.5574 - val_loss: 56.9479 - val_mae: 5.4265\n",
      "Epoch 76/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 132.9148 - mae: 8.7268 - val_loss: 59.1367 - val_mae: 5.5670\n",
      "Epoch 77/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 130.9055 - mae: 8.7582 - val_loss: 55.8030 - val_mae: 5.3325\n",
      "Epoch 78/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124.8087 - mae: 8.5414 - val_loss: 54.7692 - val_mae: 5.2790\n",
      "Epoch 79/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.4357 - mae: 8.5590 - val_loss: 59.2881 - val_mae: 5.5324\n",
      "Epoch 80/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.9141 - mae: 8.6669 - val_loss: 56.1388 - val_mae: 5.4180\n",
      "Epoch 81/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.0175 - mae: 8.7628 - val_loss: 56.6718 - val_mae: 5.4808\n",
      "Epoch 82/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.4211 - mae: 8.5083 - val_loss: 64.5390 - val_mae: 5.7586\n",
      "Epoch 83/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.9749 - mae: 8.6232 - val_loss: 59.8239 - val_mae: 5.7992\n",
      "Epoch 84/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.9318 - mae: 8.4437 - val_loss: 55.3176 - val_mae: 5.3066\n",
      "Epoch 85/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.1521 - mae: 8.6138 - val_loss: 55.8944 - val_mae: 5.4277\n",
      "Epoch 86/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.1953 - mae: 8.6831 - val_loss: 56.4797 - val_mae: 5.3835\n",
      "Epoch 87/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.0733 - mae: 8.5218 - val_loss: 59.4577 - val_mae: 5.5336\n",
      "Epoch 88/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.8397 - mae: 8.2812 - val_loss: 63.7579 - val_mae: 5.6712\n",
      "Epoch 89/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 122.7256 - mae: 8.4924 - val_loss: 57.4855 - val_mae: 5.4603\n",
      "Epoch 90/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.5752 - mae: 8.4963 - val_loss: 61.9347 - val_mae: 5.9583\n",
      "Epoch 91/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.7469 - mae: 8.3497 - val_loss: 54.3880 - val_mae: 5.2709\n",
      "Epoch 92/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.1712 - mae: 8.4030 - val_loss: 66.8286 - val_mae: 5.9940\n",
      "Epoch 93/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.1871 - mae: 8.5381 - val_loss: 60.0077 - val_mae: 5.5536\n",
      "Epoch 94/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.9933 - mae: 8.5752 - val_loss: 56.9294 - val_mae: 5.4411\n",
      "Epoch 95/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.9806 - mae: 8.5207 - val_loss: 56.8363 - val_mae: 5.3768\n",
      "Epoch 96/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.7836 - mae: 8.3274 - val_loss: 62.8086 - val_mae: 5.7791\n",
      "Epoch 97/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.0004 - mae: 8.4126 - val_loss: 55.5116 - val_mae: 5.3392\n",
      "Epoch 98/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.8103 - mae: 8.5154 - val_loss: 59.3313 - val_mae: 5.5525\n",
      "Epoch 99/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.9881 - mae: 8.4226 - val_loss: 56.5071 - val_mae: 5.3290\n",
      "Epoch 100/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.1218 - mae: 8.2686 - val_loss: 54.1667 - val_mae: 5.3281\n",
      "Epoch 101/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.8450 - mae: 8.3558 - val_loss: 53.6676 - val_mae: 5.2436\n",
      "Epoch 102/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.3713 - mae: 8.2070 - val_loss: 58.0569 - val_mae: 5.4214\n",
      "Epoch 103/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.0493 - mae: 8.3386 - val_loss: 58.8475 - val_mae: 5.7025\n",
      "Epoch 104/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.6216 - mae: 8.6280 - val_loss: 57.6057 - val_mae: 5.4032\n",
      "Epoch 105/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.9194 - mae: 8.1642 - val_loss: 54.7666 - val_mae: 5.2828\n",
      "Epoch 106/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.9173 - mae: 8.3084 - val_loss: 56.6065 - val_mae: 5.4249\n",
      "Epoch 107/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.3405 - mae: 8.3093 - val_loss: 58.2680 - val_mae: 5.5333\n",
      "Epoch 108/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.4866 - mae: 8.2568 - val_loss: 54.2474 - val_mae: 5.3522\n",
      "Epoch 109/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.2046 - mae: 8.3551 - val_loss: 55.7279 - val_mae: 5.3700\n",
      "Epoch 110/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 121.3910 - mae: 8.3479 - val_loss: 54.5258 - val_mae: 5.2498\n",
      "Epoch 111/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 114.1654 - mae: 8.2030 - val_loss: 54.4193 - val_mae: 5.2862\n",
      "Epoch 112/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.3439 - mae: 8.3383 - val_loss: 87.9156 - val_mae: 7.2242\n",
      "Epoch 113/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 118.2218 - mae: 8.3066 - val_loss: 54.3378 - val_mae: 5.2650\n",
      "Epoch 114/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 116.2710 - mae: 8.2006 - val_loss: 54.2736 - val_mae: 5.2825\n",
      "Epoch 115/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 111.1203 - mae: 7.9616 - val_loss: 55.8140 - val_mae: 5.4996\n",
      "Epoch 116/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.7070 - mae: 8.2882 - val_loss: 57.8677 - val_mae: 5.6113\n",
      "Epoch 117/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.6539 - mae: 7.9739 - val_loss: 56.4268 - val_mae: 5.3870\n",
      "Epoch 118/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 114.4594 - mae: 8.2075 - val_loss: 59.2658 - val_mae: 5.5478\n",
      "Epoch 119/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 116.5592 - mae: 8.2072 - val_loss: 53.3887 - val_mae: 5.2566\n",
      "Epoch 120/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.4345 - mae: 8.2483 - val_loss: 60.5155 - val_mae: 5.6529\n",
      "Epoch 121/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.4519 - mae: 8.2328 - val_loss: 55.3403 - val_mae: 5.3607\n",
      "Epoch 122/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.0511 - mae: 8.0803 - val_loss: 59.2717 - val_mae: 5.5130\n",
      "Epoch 123/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.1822 - mae: 8.2328 - val_loss: 60.6062 - val_mae: 5.6878\n",
      "Epoch 124/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.3269 - mae: 8.3591 - val_loss: 54.4782 - val_mae: 5.2747\n",
      "Epoch 125/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 112.1455 - mae: 8.1802 - val_loss: 59.5512 - val_mae: 5.5626\n",
      "Epoch 126/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.9129 - mae: 8.0059 - val_loss: 58.1895 - val_mae: 5.4650\n",
      "Epoch 127/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.5049 - mae: 8.2494 - val_loss: 69.2378 - val_mae: 6.1500\n",
      "Epoch 128/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.2102 - mae: 7.8591 - val_loss: 55.4257 - val_mae: 5.3272\n",
      "Epoch 129/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 110.5018 - mae: 8.0333 - val_loss: 53.3213 - val_mae: 5.2162\n",
      "Epoch 130/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.4266 - mae: 8.3086 - val_loss: 53.6863 - val_mae: 5.3303\n",
      "Epoch 131/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.0054 - mae: 8.2077 - val_loss: 54.3994 - val_mae: 5.2469\n",
      "Epoch 132/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.3848 - mae: 8.0076 - val_loss: 52.1515 - val_mae: 5.1085\n",
      "Epoch 133/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109.8285 - mae: 7.9277 - val_loss: 53.7100 - val_mae: 5.2646\n",
      "Epoch 134/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.9777 - mae: 7.9015 - val_loss: 55.0435 - val_mae: 5.2994\n",
      "Epoch 135/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.4218 - mae: 8.3206 - val_loss: 52.1567 - val_mae: 5.1013\n",
      "Epoch 136/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.2226 - mae: 8.0805 - val_loss: 56.3863 - val_mae: 5.3733\n",
      "Epoch 137/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 113.3772 - mae: 8.0601 - val_loss: 55.2204 - val_mae: 5.2911\n",
      "Epoch 138/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.5075 - mae: 8.1255 - val_loss: 68.9892 - val_mae: 5.8969\n",
      "Epoch 139/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.8297 - mae: 8.0258 - val_loss: 57.6043 - val_mae: 5.4374\n",
      "Epoch 140/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.4819 - mae: 8.1855 - val_loss: 54.0383 - val_mae: 5.2688\n",
      "Epoch 141/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.6767 - mae: 8.0962 - val_loss: 53.7638 - val_mae: 5.1597\n",
      "Epoch 142/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.2134 - mae: 7.7113 - val_loss: 59.5514 - val_mae: 5.5936\n",
      "Epoch 143/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 109.2671 - mae: 8.0028 - val_loss: 54.2128 - val_mae: 5.2042\n",
      "Epoch 144/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.7869 - mae: 7.9485 - val_loss: 58.9672 - val_mae: 5.6766\n",
      "Epoch 145/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108.9573 - mae: 7.8953 - val_loss: 58.2960 - val_mae: 5.4778\n",
      "Epoch 146/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.4500 - mae: 8.1821 - val_loss: 55.3675 - val_mae: 5.3286\n",
      "Epoch 147/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.0706 - mae: 8.4139 - val_loss: 67.3778 - val_mae: 5.9100\n",
      "Epoch 148/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 107.4089 - mae: 7.8514 - val_loss: 61.4019 - val_mae: 5.5225\n",
      "Epoch 149/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.7690 - mae: 7.7473 - val_loss: 58.6122 - val_mae: 5.4409\n",
      "Epoch 150/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.5617 - mae: 7.8775 - val_loss: 54.0114 - val_mae: 5.1869\n",
      "Epoch 151/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.1989 - mae: 7.9717 - val_loss: 53.2093 - val_mae: 5.1048\n",
      "Epoch 152/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.3528 - mae: 7.9314 - val_loss: 53.2616 - val_mae: 5.2317\n",
      "Epoch 153/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107.0453 - mae: 7.8998 - val_loss: 53.2865 - val_mae: 5.1331\n",
      "Epoch 154/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.7298 - mae: 7.7427 - val_loss: 54.9335 - val_mae: 5.2367\n",
      "Epoch 155/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 106.1530 - mae: 7.7471 - val_loss: 57.9338 - val_mae: 5.5094\n",
      "Epoch 156/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 101.7070 - mae: 7.5804 - val_loss: 57.1903 - val_mae: 5.5776\n",
      "Epoch 157/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.2534 - mae: 7.9213 - val_loss: 57.2002 - val_mae: 5.3683\n",
      "Epoch 158/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 106.0896 - mae: 7.7687 - val_loss: 63.9816 - val_mae: 5.8236\n",
      "Epoch 159/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 105.4856 - mae: 7.7481 - val_loss: 55.3636 - val_mae: 5.3581\n",
      "Epoch 160/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 108.2560 - mae: 7.8276 - val_loss: 65.8312 - val_mae: 5.9132\n",
      "Epoch 161/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.3359 - mae: 7.7169 - val_loss: 52.2757 - val_mae: 5.1681\n",
      "Epoch 162/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.6464 - mae: 7.6870 - val_loss: 52.3867 - val_mae: 5.1458\n",
      "Patience 30: Early stopping occurred at epoch 161\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59.1370 - mae: 5.2442\n",
      "Patience 30: Validation MAE: 5.11\n",
      "Patience 30: Validation Loss: 52.15\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1263.2937 - mae: 24.7421 - val_loss: 145.8226 - val_mae: 10.1571\n",
      "Epoch 2/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 268.4148 - mae: 12.9482 - val_loss: 125.0967 - val_mae: 8.1791\n",
      "Epoch 3/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 242.1644 - mae: 12.2010 - val_loss: 151.2601 - val_mae: 9.1003\n",
      "Epoch 4/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 211.8770 - mae: 11.3283 - val_loss: 93.3576 - val_mae: 7.7491\n",
      "Epoch 5/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 188.9830 - mae: 10.6332 - val_loss: 80.7435 - val_mae: 6.7034\n",
      "Epoch 6/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 192.6537 - mae: 10.7109 - val_loss: 74.4649 - val_mae: 6.2113\n",
      "Epoch 7/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 177.0678 - mae: 10.3150 - val_loss: 68.4589 - val_mae: 6.0276\n",
      "Epoch 8/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 174.2556 - mae: 10.1317 - val_loss: 89.5770 - val_mae: 6.9143\n",
      "Epoch 9/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174.5675 - mae: 10.2005 - val_loss: 95.8676 - val_mae: 7.4408\n",
      "Epoch 10/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 169.3235 - mae: 10.1577 - val_loss: 64.8029 - val_mae: 5.8904\n",
      "Epoch 11/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 165.5288 - mae: 9.8951 - val_loss: 70.0640 - val_mae: 6.0197\n",
      "Epoch 12/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168.8159 - mae: 10.0542 - val_loss: 76.7841 - val_mae: 6.3626\n",
      "Epoch 13/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 169.6815 - mae: 10.0276 - val_loss: 62.9827 - val_mae: 5.7497\n",
      "Epoch 14/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 174.8988 - mae: 10.2653 - val_loss: 61.4240 - val_mae: 5.6004\n",
      "Epoch 15/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 155.5295 - mae: 9.7130 - val_loss: 68.4872 - val_mae: 6.2947\n",
      "Epoch 16/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 158.6525 - mae: 9.6667 - val_loss: 61.3419 - val_mae: 5.5992\n",
      "Epoch 17/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 161.1177 - mae: 9.6780 - val_loss: 70.7774 - val_mae: 6.0783\n",
      "Epoch 18/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159.6273 - mae: 9.7771 - val_loss: 66.5890 - val_mae: 5.8512\n",
      "Epoch 19/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 166.7999 - mae: 9.9605 - val_loss: 72.4217 - val_mae: 6.1293\n",
      "Epoch 20/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158.2460 - mae: 9.6005 - val_loss: 66.3405 - val_mae: 5.8177\n",
      "Epoch 21/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162.4696 - mae: 9.7906 - val_loss: 65.4118 - val_mae: 5.8345\n",
      "Epoch 22/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158.9176 - mae: 9.6827 - val_loss: 73.4401 - val_mae: 6.2722\n",
      "Epoch 23/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 155.3326 - mae: 9.6465 - val_loss: 62.7029 - val_mae: 5.7442\n",
      "Epoch 24/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 156.2767 - mae: 9.7178 - val_loss: 60.2242 - val_mae: 5.6364\n",
      "Epoch 25/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 158.5983 - mae: 9.6607 - val_loss: 61.2765 - val_mae: 5.6417\n",
      "Epoch 26/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 156.5913 - mae: 9.5760 - val_loss: 64.4568 - val_mae: 5.7625\n",
      "Epoch 27/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154.9962 - mae: 9.5410 - val_loss: 63.1684 - val_mae: 5.7117\n",
      "Epoch 28/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.7588 - mae: 9.4516 - val_loss: 66.2395 - val_mae: 5.8994\n",
      "Epoch 29/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.8611 - mae: 9.4191 - val_loss: 105.2396 - val_mae: 7.8930\n",
      "Epoch 30/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 149.3060 - mae: 9.3335 - val_loss: 63.9006 - val_mae: 6.0240\n",
      "Epoch 31/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.8739 - mae: 9.5153 - val_loss: 58.3997 - val_mae: 5.5298\n",
      "Epoch 32/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148.4155 - mae: 9.3277 - val_loss: 68.4200 - val_mae: 5.9774\n",
      "Epoch 33/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.5204 - mae: 9.4558 - val_loss: 69.8613 - val_mae: 6.4041\n",
      "Epoch 34/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.6520 - mae: 9.5661 - val_loss: 59.9828 - val_mae: 5.6453\n",
      "Epoch 35/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.8023 - mae: 9.2893 - val_loss: 64.0813 - val_mae: 5.7769\n",
      "Epoch 36/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.7426 - mae: 9.1266 - val_loss: 63.3006 - val_mae: 5.7233\n",
      "Epoch 37/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.2369 - mae: 9.4480 - val_loss: 65.2206 - val_mae: 5.8516\n",
      "Epoch 38/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147.0452 - mae: 9.3590 - val_loss: 68.7014 - val_mae: 6.0765\n",
      "Epoch 39/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.3697 - mae: 9.1738 - val_loss: 62.1770 - val_mae: 5.7159\n",
      "Epoch 40/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.8686 - mae: 9.2185 - val_loss: 57.5099 - val_mae: 5.4522\n",
      "Epoch 41/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 147.1156 - mae: 9.2956 - val_loss: 61.4444 - val_mae: 5.6334\n",
      "Epoch 42/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.2687 - mae: 9.3366 - val_loss: 58.5463 - val_mae: 5.4227\n",
      "Epoch 43/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148.3136 - mae: 9.2434 - val_loss: 74.1126 - val_mae: 6.3877\n",
      "Epoch 44/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.7143 - mae: 9.5135 - val_loss: 61.7962 - val_mae: 5.8620\n",
      "Epoch 45/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 151.1425 - mae: 9.5054 - val_loss: 63.1822 - val_mae: 5.7566\n",
      "Epoch 46/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.3003 - mae: 9.2553 - val_loss: 61.3829 - val_mae: 5.6511\n",
      "Epoch 47/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 152.2468 - mae: 9.5053 - val_loss: 57.5033 - val_mae: 5.4780\n",
      "Epoch 48/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.2327 - mae: 9.3031 - val_loss: 59.7609 - val_mae: 5.6210\n",
      "Epoch 49/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 145.5452 - mae: 9.2330 - val_loss: 62.7325 - val_mae: 5.9394\n",
      "Epoch 50/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148.5830 - mae: 9.3793 - val_loss: 58.6387 - val_mae: 5.5431\n",
      "Epoch 51/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.2332 - mae: 9.1611 - val_loss: 63.2558 - val_mae: 5.7628\n",
      "Epoch 52/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 146.4057 - mae: 9.2394 - val_loss: 68.4035 - val_mae: 6.0685\n",
      "Epoch 53/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.0246 - mae: 9.2370 - val_loss: 61.8784 - val_mae: 5.7141\n",
      "Epoch 54/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145.3854 - mae: 9.2668 - val_loss: 57.3541 - val_mae: 5.4409\n",
      "Epoch 55/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.4840 - mae: 9.0923 - val_loss: 57.0174 - val_mae: 5.4600\n",
      "Epoch 56/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148.9067 - mae: 9.4055 - val_loss: 67.0064 - val_mae: 5.9465\n",
      "Epoch 57/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.6432 - mae: 8.9159 - val_loss: 60.2826 - val_mae: 5.6568\n",
      "Epoch 58/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.8106 - mae: 8.9494 - val_loss: 60.5683 - val_mae: 5.5722\n",
      "Epoch 59/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.8445 - mae: 9.3491 - val_loss: 60.0877 - val_mae: 5.5949\n",
      "Epoch 60/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.0794 - mae: 9.1502 - val_loss: 60.8980 - val_mae: 5.6385\n",
      "Epoch 61/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 143.1952 - mae: 9.1608 - val_loss: 56.8471 - val_mae: 5.3896\n",
      "Epoch 62/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.3705 - mae: 9.0109 - val_loss: 56.9522 - val_mae: 5.4417\n",
      "Epoch 63/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 144.7153 - mae: 9.1632 - val_loss: 63.2698 - val_mae: 5.9569\n",
      "Epoch 64/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.6053 - mae: 9.1584 - val_loss: 59.1133 - val_mae: 5.5159\n",
      "Epoch 65/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135.7583 - mae: 8.9231 - val_loss: 57.1772 - val_mae: 5.4206\n",
      "Epoch 66/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.2754 - mae: 9.0095 - val_loss: 60.5001 - val_mae: 5.6296\n",
      "Epoch 67/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.9070 - mae: 8.9949 - val_loss: 56.8963 - val_mae: 5.4564\n",
      "Epoch 68/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.5728 - mae: 9.2334 - val_loss: 64.3209 - val_mae: 5.8711\n",
      "Epoch 69/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.0720 - mae: 9.0276 - val_loss: 60.5407 - val_mae: 5.5703\n",
      "Epoch 70/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.3416 - mae: 8.8017 - val_loss: 55.0328 - val_mae: 5.3006\n",
      "Epoch 71/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.2885 - mae: 8.9359 - val_loss: 59.2785 - val_mae: 5.5288\n",
      "Epoch 72/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 142.9594 - mae: 9.1513 - val_loss: 56.3832 - val_mae: 5.3664\n",
      "Epoch 73/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.1156 - mae: 8.9377 - val_loss: 57.2554 - val_mae: 5.5176\n",
      "Epoch 74/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.2125 - mae: 8.7796 - val_loss: 71.3940 - val_mae: 6.2164\n",
      "Epoch 75/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.3613 - mae: 9.0160 - val_loss: 63.2575 - val_mae: 5.7777\n",
      "Epoch 76/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.3577 - mae: 8.9900 - val_loss: 69.1497 - val_mae: 6.1360\n",
      "Epoch 77/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139.8079 - mae: 9.0443 - val_loss: 59.3214 - val_mae: 5.6436\n",
      "Epoch 78/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.5621 - mae: 8.7925 - val_loss: 63.3504 - val_mae: 5.8126\n",
      "Epoch 79/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.7566 - mae: 8.8054 - val_loss: 62.5304 - val_mae: 5.6905\n",
      "Epoch 80/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135.0444 - mae: 8.9282 - val_loss: 58.1516 - val_mae: 5.4743\n",
      "Epoch 81/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.2819 - mae: 8.6784 - val_loss: 56.6329 - val_mae: 5.3575\n",
      "Epoch 82/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.3342 - mae: 8.7433 - val_loss: 58.0201 - val_mae: 5.5145\n",
      "Epoch 83/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.8388 - mae: 8.7789 - val_loss: 57.5296 - val_mae: 5.4394\n",
      "Epoch 84/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.0976 - mae: 8.5814 - val_loss: 55.0123 - val_mae: 5.2883\n",
      "Epoch 85/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.3688 - mae: 8.8767 - val_loss: 67.6447 - val_mae: 6.0832\n",
      "Epoch 86/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127.4312 - mae: 8.6483 - val_loss: 57.9196 - val_mae: 5.4762\n",
      "Epoch 87/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.9317 - mae: 8.7758 - val_loss: 57.0048 - val_mae: 5.4136\n",
      "Epoch 88/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 126.1122 - mae: 8.6500 - val_loss: 73.8424 - val_mae: 6.2571\n",
      "Epoch 89/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.7169 - mae: 8.4961 - val_loss: 55.5745 - val_mae: 5.3677\n",
      "Epoch 90/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.4409 - mae: 8.9969 - val_loss: 54.3877 - val_mae: 5.3248\n",
      "Epoch 91/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135.0524 - mae: 8.7585 - val_loss: 61.4053 - val_mae: 5.6192\n",
      "Epoch 92/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 128.8276 - mae: 8.5401 - val_loss: 58.3735 - val_mae: 5.5346\n",
      "Epoch 93/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.9962 - mae: 8.7125 - val_loss: 70.1307 - val_mae: 6.1922\n",
      "Epoch 94/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 132.7752 - mae: 8.8884 - val_loss: 65.6295 - val_mae: 5.9757\n",
      "Epoch 95/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.5673 - mae: 8.4938 - val_loss: 57.2396 - val_mae: 5.4373\n",
      "Epoch 96/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133.3602 - mae: 8.8596 - val_loss: 58.0673 - val_mae: 5.4769\n",
      "Epoch 97/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.2823 - mae: 8.7608 - val_loss: 62.2622 - val_mae: 5.7643\n",
      "Epoch 98/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.9077 - mae: 8.2757 - val_loss: 57.5003 - val_mae: 5.5025\n",
      "Epoch 99/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.3435 - mae: 8.8596 - val_loss: 54.4875 - val_mae: 5.2501\n",
      "Epoch 100/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.4527 - mae: 8.6224 - val_loss: 55.8793 - val_mae: 5.3509\n",
      "Epoch 101/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.6118 - mae: 8.5828 - val_loss: 55.5961 - val_mae: 5.4367\n",
      "Epoch 102/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.1806 - mae: 8.7955 - val_loss: 55.4868 - val_mae: 5.3371\n",
      "Epoch 103/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.7365 - mae: 8.7347 - val_loss: 53.2336 - val_mae: 5.2543\n",
      "Epoch 104/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.9793 - mae: 8.7020 - val_loss: 57.6524 - val_mae: 5.3954\n",
      "Epoch 105/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.2475 - mae: 8.6232 - val_loss: 54.6806 - val_mae: 5.3604\n",
      "Epoch 106/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.4653 - mae: 8.2884 - val_loss: 57.4719 - val_mae: 5.5243\n",
      "Epoch 107/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.2682 - mae: 8.6591 - val_loss: 63.3777 - val_mae: 5.7107\n",
      "Epoch 108/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.4096 - mae: 8.7159 - val_loss: 55.4287 - val_mae: 5.3165\n",
      "Epoch 109/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.3093 - mae: 8.6732 - val_loss: 54.2335 - val_mae: 5.2973\n",
      "Epoch 110/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 130.5222 - mae: 8.6913 - val_loss: 58.6987 - val_mae: 5.7965\n",
      "Epoch 111/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 117.9806 - mae: 8.4394 - val_loss: 56.2465 - val_mae: 5.4173\n",
      "Epoch 112/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.2412 - mae: 8.4199 - val_loss: 54.8646 - val_mae: 5.3032\n",
      "Epoch 113/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.6969 - mae: 8.5481 - val_loss: 63.6859 - val_mae: 5.7078\n",
      "Epoch 114/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.6724 - mae: 8.4627 - val_loss: 54.4402 - val_mae: 5.1897\n",
      "Epoch 115/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.2452 - mae: 8.7484 - val_loss: 55.9234 - val_mae: 5.2852\n",
      "Epoch 116/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.6609 - mae: 8.4964 - val_loss: 75.5630 - val_mae: 6.4742\n",
      "Epoch 117/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.6835 - mae: 8.5285 - val_loss: 53.8340 - val_mae: 5.2695\n",
      "Epoch 118/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 121.0846 - mae: 8.3284 - val_loss: 56.6766 - val_mae: 5.5233\n",
      "Epoch 119/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.1586 - mae: 8.3982 - val_loss: 58.5253 - val_mae: 5.5840\n",
      "Epoch 120/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 126.0091 - mae: 8.4753 - val_loss: 56.7602 - val_mae: 5.4699\n",
      "Epoch 121/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.6284 - mae: 8.5228 - val_loss: 53.4202 - val_mae: 5.2462\n",
      "Epoch 122/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 119.3544 - mae: 8.3057 - val_loss: 56.0409 - val_mae: 5.4215\n",
      "Epoch 123/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.0019 - mae: 8.3205 - val_loss: 53.4462 - val_mae: 5.1553\n",
      "Patience 20: Early stopping occurred at epoch 122\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60.4130 - mae: 5.3932\n",
      "Patience 20: Validation MAE: 5.25\n",
      "Patience 20: Validation Loss: 53.23\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/Documents/BCI_LAB/Implement/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 700.7244 - mae: 18.7408 - val_loss: 143.2317 - val_mae: 10.1211\n",
      "Epoch 2/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 237.4663 - mae: 12.1625 - val_loss: 114.7844 - val_mae: 8.9423\n",
      "Epoch 3/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 212.2097 - mae: 11.3274 - val_loss: 94.6128 - val_mae: 7.7300\n",
      "Epoch 4/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 177.8317 - mae: 10.4517 - val_loss: 85.3628 - val_mae: 7.3344\n",
      "Epoch 5/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 174.7520 - mae: 10.2026 - val_loss: 70.5664 - val_mae: 6.1933\n",
      "Epoch 6/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180.5501 - mae: 10.3296 - val_loss: 100.3624 - val_mae: 7.5640\n",
      "Epoch 7/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 166.5864 - mae: 9.9810 - val_loss: 71.4845 - val_mae: 6.1300\n",
      "Epoch 8/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 157.8520 - mae: 9.7391 - val_loss: 66.7336 - val_mae: 5.9987\n",
      "Epoch 9/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 163.2685 - mae: 9.8276 - val_loss: 65.4325 - val_mae: 5.9515\n",
      "Epoch 10/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.7291 - mae: 9.3154 - val_loss: 130.7504 - val_mae: 9.2083\n",
      "Epoch 11/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159.6095 - mae: 9.6865 - val_loss: 66.9398 - val_mae: 5.9875\n",
      "Epoch 12/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152.8693 - mae: 9.5169 - val_loss: 74.7007 - val_mae: 6.2805\n",
      "Epoch 13/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 153.6180 - mae: 9.6403 - val_loss: 68.3336 - val_mae: 5.9379\n",
      "Epoch 14/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155.0486 - mae: 9.4784 - val_loss: 74.9927 - val_mae: 6.2969\n",
      "Epoch 15/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 156.6075 - mae: 9.6402 - val_loss: 62.0247 - val_mae: 5.8072\n",
      "Epoch 16/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.6651 - mae: 9.3176 - val_loss: 63.9146 - val_mae: 5.8463\n",
      "Epoch 17/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 139.8328 - mae: 9.0868 - val_loss: 68.8271 - val_mae: 6.3445\n",
      "Epoch 18/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 141.4053 - mae: 9.1313 - val_loss: 59.9468 - val_mae: 5.5678\n",
      "Epoch 19/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.7732 - mae: 9.1048 - val_loss: 69.0118 - val_mae: 6.0281\n",
      "Epoch 20/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 142.8334 - mae: 9.1686 - val_loss: 73.9027 - val_mae: 6.3400\n",
      "Epoch 21/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143.0341 - mae: 9.2058 - val_loss: 63.6180 - val_mae: 5.7577\n",
      "Epoch 22/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.1134 - mae: 9.1194 - val_loss: 70.2878 - val_mae: 6.0580\n",
      "Epoch 23/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 143.6888 - mae: 9.1978 - val_loss: 59.2926 - val_mae: 5.5153\n",
      "Epoch 24/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.7944 - mae: 8.9204 - val_loss: 70.4208 - val_mae: 6.5074\n",
      "Epoch 25/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141.7017 - mae: 9.1389 - val_loss: 82.3921 - val_mae: 6.8496\n",
      "Epoch 26/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.8136 - mae: 8.9624 - val_loss: 59.9418 - val_mae: 5.6095\n",
      "Epoch 27/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132.8394 - mae: 8.8276 - val_loss: 70.0417 - val_mae: 6.0876\n",
      "Epoch 28/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 138.1849 - mae: 9.0295 - val_loss: 61.2740 - val_mae: 5.6992\n",
      "Epoch 29/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.3456 - mae: 8.9900 - val_loss: 64.1403 - val_mae: 5.7113\n",
      "Epoch 30/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 131.6371 - mae: 8.7534 - val_loss: 58.3552 - val_mae: 5.4865\n",
      "Epoch 31/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138.7717 - mae: 8.9461 - val_loss: 62.5528 - val_mae: 5.6643\n",
      "Epoch 32/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 133.9714 - mae: 8.8616 - val_loss: 62.2618 - val_mae: 5.6764\n",
      "Epoch 33/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.6625 - mae: 8.9723 - val_loss: 59.4367 - val_mae: 5.5511\n",
      "Epoch 34/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 131.3238 - mae: 8.8160 - val_loss: 64.6123 - val_mae: 5.7185\n",
      "Epoch 35/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.0861 - mae: 8.8819 - val_loss: 62.8030 - val_mae: 5.7306\n",
      "Epoch 36/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137.5457 - mae: 9.0116 - val_loss: 56.3271 - val_mae: 5.3640\n",
      "Epoch 37/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 134.8990 - mae: 8.8622 - val_loss: 61.4551 - val_mae: 5.6214\n",
      "Epoch 38/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 135.4890 - mae: 8.8557 - val_loss: 72.5702 - val_mae: 6.3246\n",
      "Epoch 39/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 136.8584 - mae: 8.8321 - val_loss: 65.3664 - val_mae: 5.7868\n",
      "Epoch 40/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138.5237 - mae: 8.9430 - val_loss: 58.6861 - val_mae: 5.5764\n",
      "Epoch 41/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 135.9786 - mae: 8.9217 - val_loss: 67.6234 - val_mae: 6.0032\n",
      "Epoch 42/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 132.6596 - mae: 8.8225 - val_loss: 59.8406 - val_mae: 5.6579\n",
      "Epoch 43/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 129.8084 - mae: 8.7605 - val_loss: 61.2408 - val_mae: 5.6737\n",
      "Epoch 44/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.0894 - mae: 8.6497 - val_loss: 58.5223 - val_mae: 5.4421\n",
      "Epoch 45/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 120.5421 - mae: 8.4128 - val_loss: 55.8708 - val_mae: 5.3361\n",
      "Epoch 46/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 128.6678 - mae: 8.6449 - val_loss: 60.3769 - val_mae: 5.5520\n",
      "Epoch 47/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 140.4281 - mae: 8.9125 - val_loss: 60.1355 - val_mae: 5.5256\n",
      "Epoch 48/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.9453 - mae: 8.3744 - val_loss: 79.2106 - val_mae: 6.7217\n",
      "Epoch 49/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.9175 - mae: 8.4204 - val_loss: 64.9024 - val_mae: 5.8027\n",
      "Epoch 50/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 124.5156 - mae: 8.5184 - val_loss: 58.2908 - val_mae: 5.4758\n",
      "Epoch 51/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.2919 - mae: 8.4430 - val_loss: 63.2813 - val_mae: 5.6597\n",
      "Epoch 52/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 125.6090 - mae: 8.5924 - val_loss: 56.5797 - val_mae: 5.3783\n",
      "Epoch 53/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127.5038 - mae: 8.5406 - val_loss: 58.7475 - val_mae: 5.5467\n",
      "Epoch 54/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 123.1611 - mae: 8.4766 - val_loss: 59.4018 - val_mae: 5.6588\n",
      "Epoch 55/200\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.8474 - mae: 8.3506 - val_loss: 63.4028 - val_mae: 6.0909\n",
      "Patience 10: Early stopping occurred at epoch 54\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64.4999 - mae: 5.5848\n",
      "Patience 10: Validation MAE: 5.34\n",
      "Patience 10: Validation Loss: 55.87\n",
      "\n",
      "Summary of Results:\n",
      "Patience 40: Loss = 49.1604, MAE = 4.9449, Early Stopping Occurred: False, Early Stopping Epoch: None\n",
      "Patience 30: Loss = 52.1515, MAE = 5.1085, Early Stopping Occurred: True, Early Stopping Epoch: 161\n",
      "Patience 20: Loss = 53.2336, MAE = 5.2543, Early Stopping Occurred: True, Early Stopping Epoch: 122\n",
      "Patience 10: Loss = 55.8708, MAE = 5.3361, Early Stopping Occurred: True, Early Stopping Epoch: 54\n"
     ]
    }
   ],
   "source": [
    "# Patience 값 리스트\n",
    "patience_values = [40, 30, 20, 10]\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "bresults200_1 = []\n",
    "\n",
    "for patience in patience_values:\n",
    "    # 1D CNN 모델 정의 (회귀용)\n",
    "    dbp_model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1)  # 회귀 문제이므로 활성화 함수 없음\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    dbp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f'best_model_{patience}.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = dbp_model.fit(\n",
    "        X_train_combined, DBP_Y_train_combined,\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_combined, DBP_Y_test_combined),\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    # Early stopping 여부와 발생한 epoch 저장\n",
    "    early_stopping_occurred = early_stopping.stopped_epoch > 0\n",
    "    early_stopping_epoch = early_stopping.stopped_epoch if early_stopping_occurred else None\n",
    "\n",
    "    # Early stopping 여부 확인 및 출력\n",
    "    if early_stopping_occurred:\n",
    "        print(f\"Patience {patience}: Early stopping occurred at epoch {early_stopping_epoch}\")\n",
    "    else:\n",
    "        print(f\"Patience {patience}: Early stopping did not occur\")\n",
    "\n",
    "    # 검증 데이터로 모델 평가\n",
    "    val_loss, val_mae = dbp_model.evaluate(X_test_combined, DBP_Y_test_combined)\n",
    "    print(f\"Patience {patience}: Validation MAE: {val_mae:.2f}\")\n",
    "    print(f\"Patience {patience}: Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    bresults200_1.append({\n",
    "        'patience': patience,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mae': val_mae,\n",
    "        'early_stopping_occurred': early_stopping_occurred,\n",
    "        'early_stopping_epoch': early_stopping_epoch\n",
    "    })\n",
    "\n",
    "    # 학습 및 검증 손실 그래프 시각화\n",
    "    # plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.title(f'Patience = {patience}')\n",
    "    # plt.show()\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"\\nSummary of Results:\")\n",
    "for result in bresults200_1:\n",
    "    print(f\"Patience {result['patience']}: Loss = {result['val_loss']:.4f}, MAE = {result['val_mae']:.4f}, \"\n",
    "          f\"Early Stopping Occurred: {result['early_stopping_occurred']}, \"\n",
    "          f\"Early Stopping Epoch: {result['early_stopping_epoch'] if result['early_stopping_occurred'] is not None else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
